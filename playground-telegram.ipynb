{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:25: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the params file\n",
      "Input encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Input decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "Output encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Output decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3673: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 202, 256)     25088       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 202, 128)     12544       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 202, 256)     525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 202, 256)     263168      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 202, 202)     0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 202, 202)     0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 202, 256)     0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 202, 512)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 202, 128)     65664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 202, 98)      12642       time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 904,418\n",
      "Trainable params: 904,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Hi! My PID is 5817\n"
     ]
    }
   ],
   "source": [
    "import tmqa33 as graphqa\n",
    "import convex as cx\n",
    "import requests\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import requests\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "\n",
    "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, StringCommandHandler\n",
    "from telegram import ChatAction\n",
    "from telegram.error import (TelegramError, Unauthorized, BadRequest, \n",
    "                            TimedOut, ChatMigrated, NetworkError)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "#from deepcorrect import DeepCorrect\n",
    "#corrector = DeepCorrect('data/deep_punct/deeppunct_params_en', 'data/deep_punct/deeppunct_checkpoint_wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sentence = corrector.correct(\"Who is the wife of Barack Obama?\")\n",
    "#test_sentence = test_sentence[0][\"sequence\"]\n",
    "#print(\"test_sentence\",test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "telegram_bot_token = \"1047656481:AAEDKO5iey_TKr3nxW40PgZ6s0aY7WMnS7U\"\n",
    "telegram_chat_id = 18369237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(message, telegram_chat_id):\n",
    "    requests.post(\"https://api.telegram.org/bot\" + str(telegram_bot_token) + \"/sendMessage?chat_id=\"+str(telegram_chat_id)+\"&text=\"+message).json()\n",
    "\n",
    "send_message(\n",
    "    \"Bot restarted\", \n",
    "    telegram_chat_id\n",
    ")\n",
    "#def get_updates():\n",
    "#    updates = requests.post(\"https://api.telegram.org/bot\" + str(telegram_bot_token) + \"/getUpdates\").json()\n",
    "#    return updates\n",
    "#\n",
    "#def send_typing(telegram_chat_id):\n",
    "#    requests.post(\"https://api.telegram.org/bot\" + str(telegram_bot_token) + \"/sendChatAction?chat_id=\"+str(telegram_chat_id)+\"&action=typing\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url():\n",
    "    contents = requests.get('https://random.dog/woof.json').json()    \n",
    "    url = contents['url']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_url():\n",
    "    allowed_extension = ['jpg','jpeg','png']\n",
    "    file_extension = ''\n",
    "    while file_extension not in allowed_extension:\n",
    "        url = get_url()\n",
    "        file_extension = re.search(\"([^.]*)$\",url).group(1).lower()\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dog(bot, update):\n",
    "    url = get_image_url()\n",
    "    chat_id = update.message.chat_id\n",
    "    bot.send_photo(chat_id=chat_id, photo=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='Hi!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=update.message.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_platypus(question):\n",
    "    headers = {'Accept': 'application/json','Accept-Language': 'en',}\n",
    "    params = (('q', question),('lang', 'en'))\n",
    "\n",
    "    response = requests.get('https://qa.askplatyp.us/v0/ask', headers=headers, params=params)\n",
    "    if response:\n",
    "        if type(response.json()['member']) is list:\n",
    "            #print(response.json()['member'][0]['result'])\n",
    "            if response.json()['member'] != []:\n",
    "                if '@id' in (json.dumps(response.json()['member'][0]['result'])):\n",
    "                    ps_result = (json.dumps(response.json()['member'][0]['result']['@id']))\n",
    "                else: return False\n",
    "            else: return False\n",
    "        else:\n",
    "            try:\n",
    "                if '@id' in (json.dumps(response.json()['member']['result'])):\n",
    "                    ps_result = (json.dumps(response.json()[\"member\"]['result']['@id']))\n",
    "                else: return False\n",
    "            except:\n",
    "                return False\n",
    "    else: return False\n",
    "    ps_result = ps_result[4:-1]\n",
    "    #print(result[:1])\n",
    "    if ps_result[:1] != 'P' and ps_result[:1] != 'Q':\n",
    "        return False\n",
    "    return ps_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_ask_platypus(bot, update, args):\n",
    "    question = \" \".join(args)\n",
    "    logger.info(\"Processing Platypus question: \"+ str(question))\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Platypus -> Thinking about: \"+question)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    answer = ask_platypus(question)\n",
    "    if answer:\n",
    "        top_1 = str(tmqa1.get_wd_label(answer))\n",
    "        logger.info(\"Top1 for Platypus question: \" + str(question) + \" --> \" + str(top_1))\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=top_1)\n",
    "    else:\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=\"I don't know\")\n",
    "        logger.info(\"Top1 for Convex question: \" + str(question) + \" --> I don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_qanswer(question):\n",
    "    data = {'query': question,'lang': 'en','kb': 'wikidata'}\n",
    "    headers = {\"Authorization\":\"Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiIzNDIiLCJpYXQiOjE1NzkyNTYxNDQsImV4cCI6MTU3OTg2MDk0NH0.YPFBZ-Xc8OI7eeTTkQaVT5a-CA5VONiCr_VIViG3t8tjVv7eRKgz_X_1KWDnly_F08rLXwpPcDUMBt8_M8-S8w\"}\n",
    "    query = requests.post('http://qanswer-core1.univ-st-etienne.fr/api/gerbil', data=data, headers=headers)\n",
    "    if not query:\n",
    "        return False\n",
    "    if (query.json()['questions'][0]['question']['answers']) == None:\n",
    "        return False\n",
    "    try:\n",
    "        response = (json.loads(query.json()\n",
    "                .get(\"questions\")[0]\n",
    "                .get(\"question\")\n",
    "                .get(\"answers\")\n",
    "                .replace('\\n', ''))\n",
    "         .get(\"results\").get(\"bindings\"))\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    if response:\n",
    "        return response[0].get(\"o1\").get(\"value\")[len(\"http://www.wikidata.org/entity/\"):] if response[0].get(\"o1\") is not None else False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_ask_qanswer(bot, update, args):\n",
    "    question = \" \".join(args)\n",
    "    logger.info(\"Processing qAnswer question: \" + str(question))\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"qAnswer -> Thinking about: \"+question)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    answer = ask_qanswer(question)\n",
    "    if answer:\n",
    "        top_1 = str(tmqa1.get_wd_label(answer))\n",
    "        logger.info(\"Top1 for qAnswer question: \" + str(question) + \" --> \" + str(top_1))\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=top_1)\n",
    "    else:\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=\"I don't know\")\n",
    "        logger.info(\"Top1 for Convex question: \" + str(question) + \" --> I don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_convex(question):\n",
    "    cx_result = cx.answer_complete_question(question, cx.tagmeToken)['answers'][0]['answer']\n",
    "    try:\n",
    "        if not cx_result:\n",
    "            return cx_result\n",
    "        if cx_result[:1] != 'P' and cx_result[:1] != 'Q':\n",
    "            return False\n",
    "        return cx_result\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_ask_convex(bot, update, args):\n",
    "    question = \" \".join(args)\n",
    "    logger.info(\"Processing Convex question: \"+ str(question))\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Convex -> Thinking about: \"+question)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    answer = ask_qanswer(question)\n",
    "    if answer:\n",
    "        top_1 = str(tmqa1.get_wd_label(answer))\n",
    "        logger.info(\"Top1 for Convex question: \" + str(question) + \" --> \" + str(top_1))\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=top_1)\n",
    "    else:\n",
    "        logger.info(\"Top1 for Convex question: \" + str(question) + \" --> I don't know\")\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=\"I don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help(bot, update):\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='IMPORTANT: GraphQA is long, a response takes in average 3 minutes.')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='ask GraphQA: type question in the chat')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='ask GraphQA with a subgraph: /graph [question]')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='ask Platypus: /platypus [question]')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='ask qAnswer: /qanswer [question]')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='ask Convex: /convex [question]')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='By default the bot will not add addictional facts about the answer, to turn it ON: /fun')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='To turn OFF additional facts about the answer: /serious')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='By default the bot is not keeping the context, to turn ON the context: /context')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='To turn OFF the context holder: /nocontext')\n",
    "    bot.send_message(chat_id=update.message.chat_id, text='To clear the context: /clear')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "def error_callback(bot, update, error):\n",
    "    try:\n",
    "        raise error\n",
    "    except Unauthorized:\n",
    "        error_info =\"Error -> Unauthorized: removed update.message.chat_id from conversation list\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except BadRequest:\n",
    "        error_info = \"Error -> BadRequest: malformed requests\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except TimedOut:\n",
    "        error_info = \"Error -> TimedOut: slow connection problems\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except NetworkError:\n",
    "        error_info = \"Error -> NetworkError: connection problems\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except ChatMigrated as e:\n",
    "        error_info = \"Error -> ChatMigrated: the chat_id of a group has changed, use e.new_chat_id instead\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except TelegramError:\n",
    "        error_info = \"Error -> TelegramError: telegram related errors\"\n",
    "        logger.info(error_info)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    except:\n",
    "        error_info = \"Your question generated an error, please reformulate or remove special characters.\"\n",
    "        logger.info(\"Error -> \"+error_info)\n",
    "        logger.info(traceback.format_exc())\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=error_info)\n",
    "    \n",
    "        \n",
    "    #logger.info(\"Error: \" + str(update.message.text))\n",
    "    #logger.warning('Update \"%s\" caused error \"%s\"', bot, update.error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_graphqa_graph(bot, update, args):\n",
    "    question = \" \".join(args)\n",
    "    logger.info(\"Processing TM2 Graph question: \" + str(question))\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Graphic TMqa_1 -> Thinking about: \"+question)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    \n",
    "    q_nlp = tmqa1.get_nlp(question)\n",
    "    q_themes = tmqa1.get_themes(q_nlp, top_k=3)\n",
    "    q_themes_enhanced = tmqa1.get_enhanced_themes(q_themes, top_k=3)\n",
    "    q_predicates = tmqa1.get_predicates(q_nlp, top_k=3)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    if q_predicates:\n",
    "        if not q_predicates[0][1]: q_predicates = tmqa1.get_predicates_online(q_nlp, top_k=3)\n",
    "    q_focused_parts = tmqa1.get_focused_parts(q_nlp, top_k=3)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    graph, predicates_dict = tmqa1.build_graph(q_nlp, q_themes, q_themes_enhanced, q_predicates, deep_k=10)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    paths_keywords = tmqa1.find_paths_keywords(graph, q_nlp, q_themes, q_themes_enhanced, q_predicates, q_focused_parts)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    path_nodes = tmqa1.find_path_nodes_from_graph_2(graph, paths_keywords, threshold=0.9, thres_inter=0.2, top_k=3, top_performance=50,min_paths=3000)\n",
    "    paths_nodes_filtered = tmqa1.paths_nodes_filter(path_nodes)\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    hypothesises = tmqa1.get_hypothesises(q_nlp, paths_keywords, paths_nodes_filtered)\n",
    "    \n",
    "    tmqa1.save_cache_data()\n",
    "    \n",
    "    if hypothesises: answer = hypothesises\n",
    "    else: answer = False\n",
    "\n",
    "    if answer:\n",
    "        top_1 = \"Top 1: \"+str(tmqa1.get_wd_label(answer[0][0]))+\" (\"+str(answer[0][0])+\")\"\n",
    "        top_n = \"Top n: \"+str([(tmqa1.get_wd_label(h[0]), h[0], h[1]) for i,h in enumerate(answer)])\n",
    "        answer_title = str(\"Question: \\\"\" + str(question) + \"\\\" --> \" + str(top_1))\n",
    "        logger.info(answer_title)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=top_1)\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=top_n)\n",
    "    else:\n",
    "        answer_title = str(\"Question: \\\"\" + str(question) + \"\\\" --> NO ANSWER\")\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=\"I don't know\")\n",
    "        logger.info(\"Top1 for Convex question: \" + str(question) + \" --> I don't know\")\n",
    "    \n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    fig = plt.figure(figsize=(14,14))\n",
    "    ax = plt.subplot(111)\n",
    "    ax.set_title(answer_title, fontsize=10)\n",
    "    #pos = nx.spring_layout(graph)\n",
    "    labels, colors = tmqa1.get_elements_from_graph(graph)\n",
    "    nx.draw(graph, node_size=30, node_color=colors, font_size=10, font_weight='bold', with_labels=True, labels=labels)\n",
    "    plt.tight_layout()\n",
    "    file_name = str(\"tmqa1_graphs_imgs/\"+str(question)+\".png\")\n",
    "    plt.savefig(file_name, format=\"PNG\", dpi = 300)\n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "    bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "    bot.send_photo(chat_id=update.message.chat_id, photo=open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_context(bot, update, chat_data):\n",
    "    chat_data[\"context_answer\"] = False\n",
    "    chat_data[\"context_graph\"] = False\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Your context has been cleared.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bot_reset(bot, update, chat_data):\n",
    "    chat_data.clear()\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"You have been reset. Maybe you were looking for /clear ?\")\n",
    "    set_default_chat_data(bot, update, chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_default_chat_data(bot, update, chat_data):\n",
    "    logger.info(\"New user detected, building default profile for: \"+str(update.message.chat_id))\n",
    "    question = update.message.text\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Hello \"+str(update.message.from_user.username)+\n",
    "                     \"! Welcome to GraphQA's Telegram bot\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Take a look at the help command to get started: /help\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"For your information: \"+\n",
    "                     \"When you are typing in the chat without a specific command GraphQA will answer your question.\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Additionally: \"+\n",
    "                     \"GraphQA is using the Wikidata Knowledge Graph to answer your question. \"+\n",
    "                     \"Meaning that the answer must be in Wikidata.org.\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text= \"GraphQA do not handle reasoning. \"\n",
    "                     \"You must ask questions that are answerable by a single response. \"+\n",
    "                     \"e.g. Who is the wife of Barack Obama? or Which actor voiced the Unicorn in The Last Unicorn?\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Finally: Multi answers are not well supported: \"+\n",
    "                     \"e.g. Name a person who died from bleeding.\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"TIP: Try to be as careful as possible with your spelling \"+\n",
    "                     \"for better results.\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"TIP: Handles questions types: Person, Location, Date/Time \"+\n",
    "                     \"Cause, and Quantity.\")\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"Last info: GraphQA may take a long time to answer, \"+\n",
    "                     \"in average 3 minutes. So Please be patient, and don't spam as another users could be using the bot at the same time.\")\n",
    "    \n",
    "    chat_data[\"context_answer\"] = False\n",
    "    chat_data[\"context_graph\"] = False\n",
    "    chat_data[\"hold_context\"] = False\n",
    "    chat_data[\"k_chatty\"] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(bot, update, chat_data):\n",
    "    question_test = \"Who is the wife of Barack Obama?\"\n",
    "    print(\"question_test\",type(question_test),question_test)\n",
    "    #question_test = graphqa.get_nlp(question_test, autocorrect=True)\n",
    "    question_test = corrector.correct(question_test)\n",
    "    question_test = question_test[0][\"sequence\"]\n",
    "\n",
    "    print(\"question_test\",question_test)\n",
    "    #answer = graphqa.get_full_answer(\"Who is the wife of Barack Obama?\",\n",
    "    #                                 answer_context=False, context_graph=False,\n",
    "    #                                 k_chatty=0,\n",
    "    #                                 verbose=True\n",
    "    #                                )\n",
    "    #print(\"answer\",answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_typing(bot,update):\n",
    "    t = threading.currentThread()\n",
    "    while getattr(t, \"still_computing\", True):\n",
    "        print(\"in wait loop\")\n",
    "        bot.send_chat_action(chat_id=update.message.chat_id, action=ChatAction.TYPING)\n",
    "        time.sleep(10)\n",
    "    print(\"Stopping as you wish.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_graphqa(bot, update, chat_data):\n",
    "    if \"hold_context\" not in chat_data: set_default_chat_data(bot, update, chat_data)\n",
    "    \n",
    "    question = str(update.message.text)\n",
    "    logger.info(str(update.message.from_user.username)+\" -> Processing GraphQA question: \" + question)\n",
    "    bot.send_message(chat_id=update.message.chat_id, text=\"GraphQA -> Thinking about (avg. 3 mins): \"+question)\n",
    "    \n",
    "    hold_context = chat_data[\"hold_context\"]\n",
    "    context_answer = chat_data[\"context_answer\"]\n",
    "    context_graph = chat_data[\"context_graph\"]\n",
    "    k_chatty = chat_data[\"k_chatty\"]\n",
    "    \n",
    "    \n",
    "    t = threading.Thread(target=is_typing, args=(bot,update))\n",
    "    t.start()\n",
    "    \n",
    "    #question = \"Who is the wife of Barack Obama?\"\n",
    "    #question = graphqa.get_nlp(question, autocorrect=False)\n",
    "    #print(\"question\",type(question),question)\n",
    "    answer = graphqa.get_full_answer(question,\n",
    "                                     answer_context=context_answer, context_graph=context_graph,\n",
    "                                     k_chatty=k_chatty, g_autocorrect=False,\n",
    "                                     verbose=True, timer=True, show_graph=True\n",
    "                                    )\n",
    "    answer_sentence, context_answer, context_graph = answer\n",
    "    \n",
    "    t.still_computing = False\n",
    "    t.join()\n",
    "    \n",
    "    if hold_context:\n",
    "        update.chat_data[\"context_answer\"] = context_answer\n",
    "        update.chat_data[\"context_graph\"] = context_graph\n",
    "    \n",
    "    if answer_sentence:\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=answer_sentence)\n",
    "        logger.info(\"GraphQA answer for: \" + str(question) + \" --> \" + answer_sentence)\n",
    "    else:\n",
    "        bot.send_message(chat_id=update.message.chat_id, text=\"I don't know\")\n",
    "        logger.info(\"GraphQA answer for: \" + str(question) + \" --> I don't know\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#question_test = \"Who is the wife of Barack Obama?\"\n",
    "#print(\"question_test\",type(question_test),question_test)\n",
    "#question_test = graphqa.get_nlp(question_test, autocorrect=True)\n",
    "#print(\"question_test\",question_test)\n",
    "#answer = graphqa.get_full_answer(\"Who is the wife of Barack Obama?\",\n",
    "#                                     answer_context=False, context_graph=False,\n",
    "#                                     k_chatty=0,\n",
    "#                                     verbose=True\n",
    "#                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = Updater(telegram_bot_token)\n",
    "dp = updater.dispatcher\n",
    "\n",
    "dp.add_handler(CommandHandler('dog',dog))\n",
    "dp.add_handler(CommandHandler('help',help))\n",
    "dp.add_handler(CommandHandler(\"platypus\", bot_ask_platypus, pass_args=True, pass_chat_data=True))\n",
    "dp.add_handler(CommandHandler(\"convex\", bot_ask_convex, pass_args=True, pass_chat_data=True))\n",
    "dp.add_handler(CommandHandler(\"qanswer\", bot_ask_qanswer, pass_args=True, pass_chat_data=True))\n",
    "dp.add_handler(CommandHandler(\"graph\", ask_graphqa_graph, pass_args=True, pass_chat_data=True))\n",
    "dp.add_handler(CommandHandler(\"reset\", bot_reset, pass_chat_data=True))\n",
    "dp.add_handler(CommandHandler(\"test\", test, pass_chat_data=True))\n",
    "#dp.add_handler(CommandHandler(\"fun\", bot_fun, pass_chat_data=True))\n",
    "#dp.add_handler(CommandHandler(\"serious\", bot_serious, pass_chat_data=True))\n",
    "#dp.add_handler(CommandHandler(\"context\", bot_context, pass_chat_data=True))\n",
    "#dp.add_handler(CommandHandler(\"nocontext\", bot_nocontext, pass_chat_data=True))\n",
    "#dp.add_handler(CommandHandler(\"clear\", bot_clear, pass_chat_data=True))\n",
    "dp.add_handler(MessageHandler(Filters.text, ask_graphqa, pass_chat_data=True))\n",
    "\n",
    "dp.add_error_handler(error_callback)\n",
    "updater.start_polling()\n",
    "updater.idle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qa]",
   "language": "python",
   "name": "conda-env-qa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
