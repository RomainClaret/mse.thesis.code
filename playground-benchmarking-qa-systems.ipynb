{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:25: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the params file\n",
      "Input encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Input decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "Output encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Output decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3673: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 202, 256)     25088       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 202, 128)     12544       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 202, 256)     525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 202, 256)     263168      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 202, 202)     0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 202, 202)     0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 202, 256)     0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 202, 512)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 202, 128)     65664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 202, 98)      12642       time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 904,418\n",
      "Trainable params: 904,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "#import convex as cx\n",
    "import tmqa3 as tmqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_test = open(\"/data/users/romain.claret/tm/wikidata-simplequestions/annotated_wd_data_test.txt\",'r')\n",
    "#out_test = f_test.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(df, filename):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    filename = \"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/\"+filename+'.pickle.bz2'\n",
    "    #df.summary = df.summary.map(sanitize_str)\n",
    "    print(\"Done!\",filename)\n",
    "    return df.to_pickle(filename, compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang: en, fr, de, it, es, zh\n",
    "#kb: dbpedia, wikidata, dblp, freebase\n",
    "def ask_qanswer(question):\n",
    "    data = {'query': question,'lang': 'en','kb': 'wikidata'}\n",
    "    query = requests.post('http://qanswer-core1.univ-st-etienne.fr/api/gerbil', data=data)\n",
    "    if not query:\n",
    "        return False\n",
    "    if (query.json()['questions'][0]['question']['answers']) == None:\n",
    "        return False\n",
    "    #if (query.json()['questions'][0]['question']['answers'].replace('\\n', '')) == None:\n",
    "    #    return False\n",
    "    #print(query.json()['questions'][0]['question']['answers'].replace('\\n', '').get(\"results\"))\n",
    "    try:\n",
    "        response = (json.loads(query.json()\n",
    "                .get(\"questions\")[0]\n",
    "                .get(\"question\")\n",
    "                .get(\"answers\")\n",
    "                .replace('\\n', ''))\n",
    "         .get(\"results\").get(\"bindings\"))\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    if response:\n",
    "        return response[0].get(\"o1\").get(\"value\")[len(\"http://www.wikidata.org/entity/\"):] if response[0].get(\"o1\") is not None else False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#ask_qanswer(\"Who is the wife of Barack Obama\")\n",
    "#ask_qanwser(\"Which equestrian was born in dublin?\")\n",
    "#ask_qanswer(\"what is the main language spoken in a ghentar si muore facile\")\n",
    "#ask_qanswer(\"was the film helpmates in color or black-and-white?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_platypus(question):\n",
    "    headers = {'Accept': 'application/json','Accept-Language': 'en',}\n",
    "    params = (('q', question),('lang', 'en'))\n",
    "\n",
    "    response = requests.get('https://qa.askplatyp.us/v0/ask', headers=headers, params=params)\n",
    "    if response:\n",
    "        if type(response.json()['member']) is list:\n",
    "            #print(response.json()['member'][0]['result'])\n",
    "            if response.json()['member'] != []:\n",
    "                if '@id' in (json.dumps(response.json()['member'][0]['result'])):\n",
    "                    ps_result = (json.dumps(response.json()['member'][0]['result']['@id']))\n",
    "                else: return False\n",
    "            else: return False\n",
    "        else:\n",
    "            try:\n",
    "                if '@id' in (json.dumps(response.json()['member']['result'])):\n",
    "                    ps_result = (json.dumps(response.json()[\"member\"]['result']['@id']))\n",
    "                else: return False\n",
    "            except:\n",
    "                return False\n",
    "    else: return False\n",
    "    ps_result = ps_result[4:-1]\n",
    "    #print(result[:1])\n",
    "    if ps_result[:1] != 'P' and ps_result[:1] != 'Q':\n",
    "        return False\n",
    "    return ps_result\n",
    "#ask_platypus(\"Which genre of album is harder.....faster?\")\n",
    "#ask_platypus(\"how does engelbert zaschka identify\")\n",
    "#ask_platypus(\"Which Swiss conductor's cause of death is myoc...\")\n",
    "#ask_platypus(\"where was padraic mcguinness's place of death\")\n",
    "#ask_platypus(\"was the film helpmates in color or black-and-white?\")\n",
    "#ask_platypus(\"Who created the show life on earth\")\n",
    "#ask_platypus(\"Who is the wife of Barack Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_convex(question):\n",
    "    cx_result = cx.answer_complete_question(question, cx.tagmeToken)['answers'][0]['answer']\n",
    "    #print(cx_result)\n",
    "    #answer = str(cx.wd.wikidata_id_to_label(result['answers'][0]['answer']))\n",
    "    try:\n",
    "        if not cx_result:\n",
    "            return cx_result\n",
    "        if cx_result[:1] != 'P' and cx_result[:1] != 'Q':\n",
    "            return False\n",
    "        return cx_result\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#ask_convex(\"Which actor voiced the Unicorn in The Last Unicorn?\")\n",
    "#ask_convex(\"Which genre of album is harder.....faster?\")\n",
    "#ask_convex(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#ask_convex(\"Who is the wife of Barack Obama\")\n",
    "#ask_convex(\"100% senorita is a television show in what language?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_tmqa(question, verbose=False, timer=False, show_graph=False, cores=tmqa.mp.cpu_count(), banning_str=False):\n",
    "    tmqa_result = tmqa.answer_question(question, verbose=verbose, timer=timer, show_graph=show_graph, cores=cores, banning_str=banning_str)\n",
    "    #print(tmqa_result)\n",
    "    if not tmqa_result:\n",
    "        return tmqa_result\n",
    "    #if tmqa_result[]\n",
    "    #if tmqa_result[0][0][:1] != 'P' and tmqa_result[0][0][:1] != 'Q':\n",
    "    #    return False\n",
    "    return tmqa_result[0]\n",
    "\n",
    "#answer = ask_tmqa_1(\"Which actor voiced the Unicorn in The Last Unicorn?\", verbose=True)\n",
    "#answer = ask_tmqa_1(\"what's akbar tandjung's ethnicity\", verbose=True)\n",
    "#ask_tmqa_1(\"Which genre of album is harder.....faster?\")\n",
    "#ask_tmqa_1(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#answer = ask_tmqa(\"Who is the wife of Barack Obama\")\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate qanswer\n",
    "#arguments[0] Subject\n",
    "#arguments[1] Predicate\n",
    "#arguments[2] Object\n",
    "#arguments[3] question\n",
    "\n",
    "#HEADERS = ['question', 'source', 'qanswer', 'platypus', 'convex', 'tmqa']\n",
    "#df = pd.DataFrame(columns=HEADERS)\n",
    "\n",
    "#start_time = time.time()\n",
    "#out_test_len = len(out_test)\n",
    "##print(out_test_len)\n",
    "#for i, line in enumerate(out_test):\n",
    "#    arguments = line.split(\"\\t\")\n",
    "#    print(\"\\r\\t>>> Processing {}/{}: {}\".format(i,out_test_len,arguments[3][:-1]), end='                                  ')\n",
    "#    if i < len(df):\n",
    "#        continue\n",
    "#    result_qanswer = ask_qanswer(arguments[3][:-1])\n",
    "#    result_platypus = ask_platypus(arguments[3][:-1])\n",
    "#    result_convex = ask_convex(arguments[3][:-1])\n",
    "#    #result_tmqa = ask_tmqa(arguments[3][:-1])[1]\n",
    "#    print(\"\\n\",i, \"-> qAnswer\", result_qanswer) if result_qanswer == arguments[2] else False\n",
    "#    print(\"\\n\",i, \"-> Platypus\", result_platypus) if result_platypus == arguments[2] else False\n",
    "#    print(\"\\n\",i, \"-> Convex\", result_convex) if result_convex == arguments[2] else False\n",
    "#    #print(\"\\n\",i, \"-> TMqa\", result_tmqa) if result_tmqa == arguments[2] else False\n",
    "#    df = df.append({\"question\":arguments[3][:-1], 'source':arguments[2], 'qanswer':result_qanswer, 'platypus':result_platypus, 'convex':result_convex, 'tmqa1':result_tmqa}, ignore_index=True)\n",
    "#\n",
    "#end_time = time.time()\n",
    "#print(\"->\\tRunning time is {}s\".format(round(end_time-start_time,2)))\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "#pickle_data(df_loaded, \"benchmarking-qanswer-platypus-convex-graphqa-from-0-to-\"+str(len(df_loaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "#df_loaded = pd.read_pickle(\"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-9961.pickle.bz2\")\n",
    "\n",
    "#/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-5.pickle.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['qanswer'][34] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_loaded['tm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded.rename({'mine':'tm1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['tm1_top4'] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded[['question','source','qanswer','platypus','convex','tm1','tm1_time','tm1_top2','tm1_top3','tm1_top4','tm1_top5','tm1_topall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING QAGraph\n",
    "\n",
    "df_loaded = pd.read_pickle(\"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-534.pickle.bz2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question      object\n",
      "source        object\n",
      "qanswer       object\n",
      "platypus      object\n",
      "convex        object\n",
      "tm1           object\n",
      "tm1_time      object\n",
      "tm1_top2      object\n",
      "tm1_top3      object\n",
      "tm1_top4      object\n",
      "tm1_top5      object\n",
      "tm1_topall    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_loaded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535/9961 which type of people does roberto benigni belong to -> source: Q50001\n",
      "User input: which type of people does roberto benigni belong to\n",
      "--> Auto correcting question in progress...\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "-> Auto corrected q_nlp: Which type of people does Roberto Benigni belong to \n",
      "-> q_themes: ([(Roberto Benigni, ['Q23301']), (people, ['Q2472587', 'Q33659']), (Type, ['Q3707858', 'Q7860632']), (People, ['Q769695', 'Q11887416']), (type, ['Q21146257', 'Q1325930'])], [Which type of people does Roberto])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: type\n",
      "behold: get_most_similar started with: do\n",
      "behold: get_most_similar started with: belong\n",
      "-> q_predicates: [(does, []), (belong, []), (type, ['P427']), (people, ['P172', 'P1315'])]\n",
      "-> q_predicates \tRunning time is 16.46s\n",
      "-> q_focused_parts: [(type, ['Q21146257', 'Q1325930']), (people, ['Q2472587', 'Q33659'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 29.5s\n",
      "-->  140 nodes and 134 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 140 nodes and 134 edges\n",
      "-> predicates_dict: {'P155': 1, 'P373': 1, 'P108': 2, 'P279': 5, 'P800': 2, 'P123': 1, 'P1433': 1, 'P407': 2, 'P973': 1, 'P3437': 1, 'P1686': 2, 'P805': 2, 'P1411': 3, 'P1343': 1, 'P166': 6, 'P495': 2, 'P361': 1, 'P585': 3, 'P364': 1, 'P156': 1, 'P735': 1, 'P31': 9, 'P571': 1, 'P2002': 1, 'P3744': 1, 'P910': 3, 'P360': 3, 'P734': 1, 'P4810': 4, 'P175': 2, 'P136': 1, 'P172': 1}\n",
      "-> paths_keywords: (['type', 'people', 'belong', 'roberto benigni'], {}, [Which])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 12\n",
      "->Computing possible paths \tRunning time is 19.57s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 8\n",
      "->\tRunning time is 2.99s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1860', 0.7412373812196494]]\n",
      "->Computing hypothesises \tRunning time is 5.28s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 0\n",
      "->\tRunning time is 3.01s\n",
      "--> len(cleared_golden_paths): 0\n",
      "->\tTotal Running time is 79.43s\n",
      "\n",
      "->\tRunning time is 79.64s\n",
      "False ---> result_tmqa: Q50001\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-535.pickle.bz2\n",
      "question      which type of people does roberto benigni belo...\n",
      "source                                                   Q50001\n",
      "qanswer                                                   False\n",
      "platypus                                                  False\n",
      "convex                                                    False\n",
      "tm1                                                     [Q1860]\n",
      "tm1_time                                                  79.64\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 535, dtype: object\n",
      "\n",
      "\n",
      "536/9961 which film did christopher mcquarrie write -> source: Q27513\n",
      "User input: which film did christopher mcquarrie write\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which film did Christopher McQuarrie write \n",
      "-> q_themes: ([(Christopher McQuarrie, ['Q337658']), (Film, ['Q11424', 'Q1414297'])], [Which film, Which film did Christopher])\n",
      "-> q_themes_enhanced: [('film', ['Q11424'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (write, ['P1412']), (film, ['P57'])]\n",
      "-> q_predicates \tRunning time is 7.72s\n",
      "-> q_focused_parts: [(film, ['Q11424'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.96s\n",
      "-->  45 nodes and 44 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 45 nodes and 44 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 45 nodes or 44 edges was below the limit of 100\n",
      "->New graph \tRunning time is 12.15s\n",
      "-->  59 nodes and 58 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 59 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 59 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 12.12s\n",
      "-->  72 nodes and 72 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 72 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 72 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 12.29s\n",
      "-->  77 nodes and 78 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 77 nodes and 78 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 77 nodes or 78 edges was below the limit of 100\n",
      "->New graph \tRunning time is 12.13s\n",
      "-->  78 nodes and 80 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 78 nodes and 80 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 78 nodes or 80 edges was below the limit of 100\n",
      "->New graph \tRunning time is 12.2s\n",
      "-->  85 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 85 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 85 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 13.01s\n",
      "-->  87 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 87 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 87 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 13.32s\n",
      "-->  94 nodes and 98 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 94 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 13.33s\n",
      "-->  97 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 97 nodes and 102 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 97 nodes or 102 edges was below the limit of 100\n",
      "->New graph \tRunning time is 13.83s\n",
      "-->  101 nodes and 106 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 101 nodes and 106 edges\n",
      "-> predicates_dict: {'P136': 7, 'P106': 3, 'P31': 2, 'P1040': 1, 'P166': 3, 'P2031': 1, 'P1686': 1, 'P805': 1, 'P1411': 1, 'P344': 1, 'P57': 6, 'P364': 2, 'P518': 1, 'P735': 1, 'P58': 10, 'P19': 1, 'P1559': 1, 'P734': 1, 'P569': 2, 'P495': 1, 'P577': 1, 'P462': 2, 'P27': 1, 'P3744': 1, 'P2002': 1}\n",
      "-> paths_keywords: (['film', 'christopher mcquarrie'], {'stated in': [stated in, ['P248']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']], 'director': [director, ['P57']]}, [Which])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 372\n",
      "->Computing possible paths \tRunning time is 10.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 372\n",
      "->\tRunning time is 3.16s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q575443', 16.069122385351296], ['Q1693691', 2.699521967266823], ['Q1356213', 1.9511704003418615], ['Q17548046', 1.8956396261465318], ['Q29261993', 1.853702245637511], ['Q590252', -0.29823563958389476]]\n",
      "->Computing hypothesises \tRunning time is 19.07s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 16\n",
      "->\tRunning time is 7.51s\n",
      "--> len(cleared_golden_paths): 8\n",
      "---> First path: ['Q575443', 'P57', 'Q1414297', 'P136', 'Q130232']\n",
      "->\tTotal Running time is 176.67s\n",
      "\n",
      "->\tRunning time is 176.89s\n",
      "False ---> result_tmqa: Q27513\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-536.pickle.bz2\n",
      "question             which film did christopher mcquarrie write\n",
      "source                                                   Q27513\n",
      "qanswer                                                 Q186424\n",
      "platypus                                                  False\n",
      "convex                                                  Q188473\n",
      "tm1           [Q575443, Q1693691, Q1356213, Q17548046, Q2926...\n",
      "tm1_time                                                 176.89\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 536, dtype: object\n",
      "\n",
      "\n",
      "537/9961 who is signed with myspace records -> source: Q1371975\n",
      "User input: who is signed with myspace records\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: Who is signed with MySpace records \n",
      "-> q_themes: ([(MySpace, ['Q40629', 'Q18612105']), (MySpace records, ['Q2040546'])], [be sign])\n",
      "-> q_themes_enhanced: [('sign', ['Q1193832']), ('Sign', ['Q11246169']), ('Myspace', ['P3265'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: record\n",
      "-> q_predicates: [(be, ['P31']), (signed, ['P1412']), (records, [])]\n",
      "-> q_predicates \tRunning time is 34.81s\n",
      "-> q_focused_parts: [(MySpace records, ['Q2040546'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.82s\n",
      "-->  88 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 4 ... Previously: 88 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 17.09s\n",
      "-->  90 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 90 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 90 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 17.71s\n",
      "-->  95 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 95 nodes and 96 edges\n",
      "---> Rebuilding the graph with k_deep 6 ... Previously: 95 nodes or 96 edges was below the limit of 100\n",
      "->New graph \tRunning time is 18.44s\n",
      "-->  100 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 100 nodes and 102 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 100 nodes or 102 edges was below the limit of 100\n",
      "->New graph \tRunning time is 18.51s\n",
      "-->  111 nodes and 114 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 111 nodes and 114 edges\n",
      "-> predicates_dict: {'P3744': 1, 'P2002': 1, 'P2003': 1, 'P373': 1, 'P155': 4, 'P156': 4, 'P264': 8, 'P1476': 1, 'P805': 1, 'P1343': 1, 'P953': 1, 'P585': 1, 'P1661': 1, 'P407': 1, 'P571': 2, 'P580': 1, 'P582': 1, 'P749': 2, 'P921': 1, 'P31': 6, 'P642': 2, 'P361': 2, 'P577': 2, 'P136': 1, 'P279': 1, 'P17': 1, 'P856': 2, 'P553': 1, 'P127': 1, 'P112': 2, 'P275': 1, 'P433': 1}\n",
      "-> paths_keywords: (['myspace records', 'signed', 'myspace'], {'instance of': [instance of, ['P31']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']], 'Myspace ID': [Myspace ID, ['P3265']], 'Myspace': [Myspace ID, ['P3265']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 164\n",
      "->Computing possible paths \tRunning time is 20.78s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 160\n",
      "->\tRunning time is 3.33s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q3220391', 4.1916579755795285], ['Q18127', 0.6463146772652102], ['Q11246169', 0.5926570952476558], ['Q134556', 0.5926570952476558], ['Q4830453', 0.5736653120459924], ['Q1193832', 0.5225972591153939], ['Q151885', 0.5225972591153939], ['Q1860', 0.456169108013501], ['Q838795', 0.43579934205087345], ['2005-01-01T00:00:00Z', 0.2003964339826144], ['2003-01-01T00:00:00Z', 0.13520546002428108]]\n",
      "->Computing hypothesises \tRunning time is 35.58s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 6\n",
      "->\tRunning time is 6.53s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q151885', 'P31', 'Q1193832', 'P642', 'Q395']\n",
      "->\tTotal Running time is 191.83s\n",
      "\n",
      "->\tRunning time is 192.11s\n",
      "False ---> result_tmqa: Q1371975\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-537.pickle.bz2\n",
      "question                     who is signed with myspace records\n",
      "source                                                 Q1371975\n",
      "qanswer                 ki/Special:FilePath/Myspacelogo2013.svg\n",
      "platypus                                                  False\n",
      "convex                                                    False\n",
      "tm1           [Q151885, Q3220391, Q18127, Q11246169, Q134556...\n",
      "tm1_time                                                 192.11\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 537, dtype: object\n",
      "\n",
      "\n",
      "538/9961 What is scott walker's profession? -> source: Q3282637\n",
      "User input: What is scott walker's profession?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Scott Walker profession \n",
      "-> q_themes: ([(Scott Walker, ['Q488603', 'Q553254']), (walker, ['Q1158605', 'Q7962191']), (Walker, ['Q14238805', 'Q16194928']), (profession, ['Q28640', 'Q2907853']), (Profession, ['Q7247911', 'Q15402063'])], [Scott Walker profession, Walker Profession, Profession Walker, is Scott, Scott Walker Profession, scott walker profession])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (profession, ['P1327'])]\n",
      "-> q_predicates \tRunning time is 12.0s\n",
      "-> q_focused_parts: [(profession, ['Q28640', 'Q2907853']), (Scott Walker, ['Q488603', 'Q553254'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.6s\n",
      "-->  112 nodes and 110 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 112 nodes and 110 edges\n",
      "-> predicates_dict: {'P155': 1, 'P31': 12, 'P206': 1, 'P585': 2, 'P1810': 2, 'P2868': 1, 'P580': 4, 'P407': 1, 'P527': 1, 'P131': 1, 'P735': 3, 'P582': 2, 'P69': 2, 'P793': 3, 'P27': 3, 'P512': 1, 'P39': 2, 'P577': 1, 'P264': 1, 'P17': 2, 'P106': 1, 'P625': 1, 'P495': 2, 'P462': 1, 'P3744': 1, 'P2002': 1, 'P373': 1, 'P1545': 1}\n",
      "-> paths_keywords: (['profession', 'scott walker', 'walker'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 80\n",
      "->Computing possible paths \tRunning time is 19.18s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 76\n",
      "->\tRunning time is 2.97s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q30', 2.5608116095526947], ['Q145', 2.5456845873646765], ['Q5', 0.946831918232029], ['Q2260734', 0.6465040746269226]]\n",
      "->Computing hypothesises \tRunning time is 19.66s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 0\n",
      "->\tRunning time is 6.86s\n",
      "--> len(cleared_golden_paths): 0\n",
      "->\tTotal Running time is 81.83s\n",
      "\n",
      "->\tRunning time is 82.06s\n",
      "False ---> result_tmqa: Q3282637\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-538.pickle.bz2\n",
      "question                What is scott walker's profession?\n",
      "source                                            Q3282637\n",
      "qanswer                                             Q82955\n",
      "platypus                                             False\n",
      "convex        Q553254-fae29a96-450f-5262-a02c-e14fb50130b1\n",
      "tm1                              [Q30, Q145, Q5, Q2260734]\n",
      "tm1_time                                             82.06\n",
      "tm1_top2                                             False\n",
      "tm1_top3                                             False\n",
      "tm1_top4                                             False\n",
      "tm1_top5                                             False\n",
      "tm1_topall                                           False\n",
      "Name: 538, dtype: object\n",
      "\n",
      "\n",
      "539/9961 what film is produced by dreamworks? -> source: Q921985\n",
      "User input: what film is produced by dreamworks?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What film is produced by dreamworks \n",
      "-> q_themes: ([(Dreamworks, ['Q192557', 'Q5306254']), (Film, ['Q11424', 'Q1414297'])], [What film])\n",
      "-> q_themes_enhanced: [('film', ['Q11424'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (produced, ['P162', 'P2849']), (film, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.64s\n",
      "-> q_focused_parts: [(film, ['Q11424'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.6s\n",
      "-->  37 nodes and 36 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 37 nodes and 36 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 37 nodes or 36 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.58s\n",
      "-->  47 nodes and 46 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 47 nodes and 46 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 47 nodes or 46 edges was below the limit of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 15.13s\n",
      "-->  55 nodes and 54 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 55 nodes and 54 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 55 nodes or 54 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.58s\n",
      "-->  61 nodes and 60 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 61 nodes and 60 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 61 nodes or 60 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.21s\n",
      "-->  73 nodes and 72 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 73 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 73 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.1s\n",
      "-->  83 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 83 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 83 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.18s\n",
      "-->  87 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 87 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 87 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.25s\n",
      "-->  93 nodes and 92 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 93 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 16 ... Previously: 93 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.43s\n",
      "-->  96 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 96 nodes and 96 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 96 nodes or 96 edges was below the limit of 100\n",
      "->New graph \tRunning time is 14.07s\n",
      "-->  104 nodes and 104 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 104 edges\n",
      "-> predicates_dict: {'P136': 3, 'P31': 3, 'P1040': 1, 'P518': 1, 'P364': 2, 'P1056': 1, 'P571': 1, 'P272': 15, 'P452': 1, 'P344': 1, 'P1454': 1, 'P57': 1, 'P577': 1, 'P495': 1, 'P58': 1, 'P463': 1, 'P910': 1, 'P162': 2, 'P156': 1, 'P17': 1, 'P856': 1, 'P462': 2, 'P161': 3, 'P159': 1, 'P155': 1, 'P169': 1, 'P749': 1, 'P112': 1, 'P2047': 1}\n",
      "-> paths_keywords: (['film', 'produced', 'dreamworks'], {'instance of': [instance of, ['P31']], 'producer': [producer, ['P162']], 'produced by': [produced by, ['P2849']], 'director': [director, ['P57']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 180\n",
      "->Computing possible paths \tRunning time is 9.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 146\n",
      "->\tRunning time is 2.96s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q575443', 12.811766427534492], ['Q726294', 2.6081269229587662], ['Q335508', 2.4520486323669917]]\n",
      "->Computing hypothesises \tRunning time is 7.99s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 26\n",
      "->\tRunning time is 5.32s\n",
      "--> len(cleared_golden_paths): 16\n",
      "---> First path: ['Q575443', 'P57', 'Q1414297', 'P495', 'Q30', 'P17', 'Q192557', 'P162', 'Q335508']\n",
      "->\tTotal Running time is 179.48s\n",
      "\n",
      "->\tRunning time is 179.69s\n",
      "False ---> result_tmqa: Q921985\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-539.pickle.bz2\n",
      "question      what film is produced by dreamworks?\n",
      "source                                     Q921985\n",
      "qanswer                                      False\n",
      "platypus                                     False\n",
      "convex                                     Q335508\n",
      "tm1                    [Q575443, Q726294, Q335508]\n",
      "tm1_time                                    179.69\n",
      "tm1_top2                                     False\n",
      "tm1_top3                                     False\n",
      "tm1_top4                                     False\n",
      "tm1_top5                                     False\n",
      "tm1_topall                                   False\n",
      "Name: 539, dtype: object\n",
      "\n",
      "\n",
      "540/9961 Name a screenwriter. -> source: Q271554\n",
      "User input: Name a screenwriter.\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name a screenwriter \n",
      "-> q_themes: ([(screenwriter, ['Q28389', 'P58'])], [a screenwriter, Name A Screenwriter, Name screenwriter])\n",
      "-> q_themes_enhanced: [('A Name', ['Q19023699'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Name, ['P735', 'P1448']), (screenwriter, ['P58'])]\n",
      "-> q_predicates \tRunning time is 4.63s\n",
      "-> q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 15.49s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "-> predicates_dict: {}\n",
      "-> paths_keywords: (['screenwriter'], {'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'screenwriter': [screenwriter, ['P58']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 12.71s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.3s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "User input: Name a screenwriter.\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name a screenwriter \n",
      "-> q_themes: ([(screenwriter, ['Q28389', 'P58'])], [a screenwriter, Name A Screenwriter, Name screenwriter])\n",
      "-> q_themes_enhanced: [('A Name', ['Q19023699'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Name, ['P735', 'P1448']), (screenwriter, ['P58'])]\n",
      "-> q_predicates \tRunning time is 2.88s\n",
      "-> q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.41s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "-> predicates_dict: {}\n",
      "-> paths_keywords: (['screenwriter'], {'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'screenwriter': [screenwriter, ['P58']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 13.03s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.06s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 38.05s\n",
      "\n",
      "->\tTotal Running time is 76.29s\n",
      "\n",
      "->\tRunning time is 76.5s\n",
      "False ---> result_tmqa: Q271554\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-540.pickle.bz2\n",
      "question      Name a screenwriter.\n",
      "source                     Q271554\n",
      "qanswer                      False\n",
      "platypus                     False\n",
      "convex                    Q2962849\n",
      "tm1                          False\n",
      "tm1_time                      76.5\n",
      "tm1_top2                     False\n",
      "tm1_top3                     False\n",
      "tm1_top4                     False\n",
      "tm1_top5                     False\n",
      "tm1_topall                   False\n",
      "Name: 540, dtype: object\n",
      "\n",
      "\n",
      "541/9961 which genre does every avenue work under -> source: Q837837\n",
      "User input: which genre does every avenue work under\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which genre does every avenue work under \n",
      "-> q_themes: ([(avenue, ['Q207934', 'Q7543083']), (Genre, ['Q483394', 'Q5533543']), (genre, ['P136'])], [Which genre, every avenue work])\n",
      "-> q_themes_enhanced: [('work', ['Q16532276']), ('Every Avenue', ['Q201918']), ('Avenue', ['Q17492558']), ('Work', ['Q15762114'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "behold: get_most_similar started with: avenue\n",
      "behold: get_most_similar started with: work\n",
      "-> q_predicates: [(does, []), (genre, ['P136']), (avenue, []), (work, ['P937'])]\n",
      "-> q_predicates \tRunning time is 63.71s\n",
      "-> q_focused_parts: [(genre, ['P136'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 75.12s\n",
      "-->  105 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 105 nodes and 102 edges\n",
      "-> predicates_dict: {'P136': 5, 'P180': 6, 'P1433': 1, 'P935': 1, 'P642': 1, 'P31': 5, 'P175': 3, 'P407': 1, 'P518': 1, 'P186': 2, 'P805': 1, 'P1343': 1, 'P360': 3, 'P527': 1, 'P131': 1, 'P571': 2, 'P1813': 1, 'P971': 2, 'P1963': 1, 'P495': 2, 'P910': 1, 'P373': 3, 'P170': 1, 'P217': 1, 'P279': 1, 'P195': 1, 'P276': 1, 'P921': 1}\n",
      "-> paths_keywords: (['genre', 'work', 'avenue'], {'genre': [genre, ['P136']], 'work location': [work location, ['P937']]}, [Which])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 40\n",
      "->Computing possible paths \tRunning time is 20.24s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 28\n",
      "->\tRunning time is 3.14s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q4104520', 34.011905819715935], ['Q4413495', 33.94951304395374], ['Q4150965', 33.84162601673425], ['Q201918', 2.7377328903656957], ['Q11366', 2.7377328903656957]]\n",
      "->Computing hypothesises \tRunning time is 7.46s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 3.45s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q4104520', 'P136', 'Q483394', 'P642', 'Q17537576']\n",
      "->\tTotal Running time is 175.8s\n",
      "\n",
      "->\tRunning time is 176.01s\n",
      "False ---> result_tmqa: Q837837\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-541.pickle.bz2\n",
      "question             which genre does every avenue work under\n",
      "source                                                Q837837\n",
      "qanswer                                                 False\n",
      "platypus                                                False\n",
      "convex                                                 Q11366\n",
      "tm1           [Q4104520, Q4413495, Q4150965, Q201918, Q11366]\n",
      "tm1_time                                               176.01\n",
      "tm1_top2                                                False\n",
      "tm1_top3                                                False\n",
      "tm1_top4                                                False\n",
      "tm1_top5                                                False\n",
      "tm1_topall                                              False\n",
      "Name: 541, dtype: object\n",
      "\n",
      "\n",
      "542/9961 what is the occupation of mine mutlu -> source: Q33999\n",
      "User input: what is the occupation of mine mutlu\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the occupation of Mine Mutlu \n",
      "-> q_themes: ([(the occupation, ['Q55382177', 'Q10381667']), (Mine Mutlu, ['Q6585199']), (occupation, ['Q12737077', 'Q10687729'])], [is the occupation of Mine])\n",
      "-> q_themes_enhanced: [('Be Mine', ['Q16256269']), ('The Occupation', ['Q10381667']), ('The Mine', ['Q19896219']), ('Occupation', ['Q15703263'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 6.83s\n",
      "-> q_focused_parts: [(the occupation, ['Q55382177', 'Q10381667']), (Mine Mutlu, ['Q6585199'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 40.6s\n",
      "-->  2207 nodes and 2202 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 2207 nodes and 2202 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 2207 nodes or 2202 edges was above the limit of 350\n",
      "---> Too many nodes, statistically it's not worth the run. Cancelling question, it probably require reasoning.\n",
      "\n",
      "->\tRunning time is 90.59s\n",
      "False ---> result_tmqa: Q33999\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-542.pickle.bz2\n",
      "question      what is the occupation of mine mutlu\n",
      "source                                      Q33999\n",
      "qanswer                                     Q33999\n",
      "platypus                                     False\n",
      "convex                                    Q2309784\n",
      "tm1                                          False\n",
      "tm1_time                                     90.59\n",
      "tm1_top2                                     False\n",
      "tm1_top3                                     False\n",
      "tm1_top4                                     False\n",
      "tm1_top5                                     False\n",
      "tm1_topall                                   False\n",
      "Name: 542, dtype: object\n",
      "\n",
      "\n",
      "543/9961 Which gender is antonio pagudo? -> source: Q6581097\n",
      "User input: Which gender is antonio pagudo?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which gender is antonio pagudo \n",
      "-> q_themes: ([(antonio pagudo, ['Q8201549']), (Gender, ['Q48277', 'Q19122628']), (gender, ['Q5531000'])], [pagudo, Pagudo])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (gender, ['P21'])]\n",
      "-> q_predicates \tRunning time is 6.69s\n",
      "-> q_focused_parts: [(gender, ['Q5531000'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 10.59s\n",
      "-->  54 nodes and 52 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 54 nodes and 52 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 54 nodes or 52 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.7s\n",
      "-->  64 nodes and 62 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 64 nodes and 62 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 64 nodes or 62 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.73s\n",
      "-->  84 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 8 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.69s\n",
      "-->  88 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.75s\n",
      "-->  95 nodes and 94 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 95 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 95 nodes or 94 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.88s\n",
      "-->  99 nodes and 98 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 99 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 99 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 10.47s\n",
      "-->  105 nodes and 104 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 105 nodes and 104 edges\n",
      "-> predicates_dict: {'P304': 1, 'P958': 1, 'P1343': 1, 'P373': 1, 'P101': 6, 'P969': 1, 'P1552': 3, 'P21': 1, 'P527': 1, 'P131': 1, 'P735': 1, 'P19': 1, 'P31': 10, 'P1412': 1, 'P642': 1, 'P569': 1, 'P27': 1, 'P17': 1, 'P910': 1, 'P276': 1, 'P2578': 2, 'P971': 2, 'P921': 4, 'P625': 1, 'P2579': 1, 'P106': 1, 'P281': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['gender', 'antonio pagudo'], {}, [Which])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 130\n",
      "->Computing possible paths \tRunning time is 9.46s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 104\n",
      "->\tRunning time is 3.0s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q11681123', 1.4547885501911297], ['Q6581097', 1.2948233342086677], ['Q1383258', 0.981447970427995]]\n",
      "->Computing hypothesises \tRunning time is 4.93s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 14\n",
      "->\tRunning time is 6.46s\n",
      "--> len(cleared_golden_paths): 7\n",
      "---> First path: ['Q11681123', 'P921', 'Q48277', 'P31', 'Q6581097', 'P21', 'Q8201549', 'P735', 'Q7141520']\n",
      "->\tTotal Running time is 107.95s\n",
      "\n",
      "->\tRunning time is 108.17s\n",
      "False ---> result_tmqa: Q6581097\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-543.pickle.bz2\n",
      "question      Which gender is antonio pagudo?\n",
      "source                               Q6581097\n",
      "qanswer                              Q6581097\n",
      "platypus                                False\n",
      "convex                                  False\n",
      "tm1           [Q11681123, Q6581097, Q1383258]\n",
      "tm1_time                               108.17\n",
      "tm1_top2                                False\n",
      "tm1_top3                                False\n",
      "tm1_top4                                False\n",
      "tm1_top5                                False\n",
      "tm1_topall                              False\n",
      "Name: 543, dtype: object\n",
      "\n",
      "\n",
      "544/9961 What language is the film love hurts in  -> source: Q1860\n",
      "User input: What language is the film love hurts in \n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What language is the film love hurts in \n",
      "-> q_themes: ([(language, ['Q315', 'Q34770']), (Language, ['Q1302060', 'Q12134540']), (the film, ['Q25302710', 'Q3520871']), (love, ['Q316', 'Q15616682'])], [the film love, The Film Love, film love])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes_enhanced: [('The Film', ['Q16679544']), ('The Love', ['Q11250791']), ('Film', ['Q25302710']), ('Love', ['Q1014414'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: love\n",
      "behold: get_most_similar started with: hurt\n",
      "-> q_predicates: [(be, ['P31']), (hurts, []), (language, ['P1412', 'P364']), (film, ['P57']), (love, [])]\n",
      "-> q_predicates \tRunning time is 73.68s\n",
      "-> q_focused_parts: [(language, ['Q315', 'Q34770'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 29.93s\n",
      "-->  178 nodes and 172 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 178 nodes and 172 edges\n",
      "-> predicates_dict: {'P527': 1, 'P31': 30, 'P1013': 3, 'P155': 2, 'P156': 2, 'P175': 1, 'P2354': 1, 'P364': 1, 'P805': 1, 'P1343': 1, 'P735': 1, 'P509': 2, 'P1424': 1, 'P813': 1, 'P973': 1, 'P1709': 1, 'P1245': 1, 'P361': 4, 'P282': 1, 'P1535': 1, 'P279': 1, 'P577': 1, 'P2633': 1, 'P264': 3, 'P3744': 1, 'P2002': 1, 'P136': 11, 'P495': 2, 'P910': 1, 'P856': 2, 'P676': 1, 'P462': 1, 'P1479': 1, 'P5008': 1, 'P1269': 1}\n",
      "-> paths_keywords: (['language', 'hurts', 'the film', 'love'], {'instance of': [instance of, ['P31']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']], 'original language of work': [original language of work, ['P364']], 'director': [director, ['P57']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 966\n",
      "->Computing possible paths \tRunning time is 12.68s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 780\n",
      "->\tRunning time is 3.27s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1568', 1.9508253122778445], ['Q55558911', 1.5374105528006048], ['Q55651630', 1.2223645065331008], ['Q28923954', 1.133154922135887], ['Q13748797', 1.0689699926960816], ['Q2449994', 1.0198883044116194], ['Q16748888', 1.005107238257506], ['Q9415', 0.9644652916181146], ['Q482994', 0.7586371328028186], ['Q56462089', 0.7527942361209153], ['Q11250791', 0.7174402375444225], ['Q215380', 0.7174402375444225], ['Q5638398', 0.5439456602101419], ['Q54879035', 0.5181893153303305], ['Q35602', 0.3587283796507097], ['Q945748', 0.2865649385158637], ['Q810378', 0.2767748378724391], ['Q7288630', 0.24796414201860897], ['Q2479725', 0.21909063171803553], ['Q1519764', 0.21909063171803553], ['Q56071730', 0.20493415458751513]]\n",
      "->Computing hypothesises \tRunning time is 99.05s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 30.68s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q1568', 'P364', 'Q25302710', 'P31', 'Q11424']\n",
      "->\tTotal Running time is 251.88s\n",
      "\n",
      "->\tRunning time is 252.09s\n",
      "False ---> result_tmqa: Q1860\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-544.pickle.bz2\n",
      "question               What language is the film love hurts in \n",
      "source                                                    Q1860\n",
      "qanswer                                                  Q37073\n",
      "platypus                                                  False\n",
      "convex                                                    Q1860\n",
      "tm1           [Q1568, Q55558911, Q55651630, Q28923954, Q1374...\n",
      "tm1_time                                                 252.09\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 544, dtype: object\n",
      "\n",
      "\n",
      "545/9961 what was richard haldane, 1st viscount haldanes place of death -> source: Q758623\n",
      "User input: what was richard haldane, 1st viscount haldanes place of death\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was Richard Haldane 1st Viscount Haldanes Place of Death \n",
      "-> q_themes: ([(Haldane, ['Q21449630', 'Q1903723']), (Death, ['Q4', 'Q161936']), (Place of Death, ['Q18658526'])], [Richard Haldane 1st Viscount Haldanes Place, Haldane 1st Viscount, Viscount Haldanes, Haldanes Place, richard haldane 1st viscount haldanes place])\n",
      "-> q_themes_enhanced: [('1st', ['Q12470229']), ('Viscount', ['Q1137051']), ('viscount', ['Q185902']), ('place', ['Q1794067']), ('place of death', ['P20'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: 1st\n",
      "-> q_predicates: [(be, ['P31']), (1st, []), (Death, ['P570', 'P20'])]\n",
      "-> q_predicates \tRunning time is 46.13s\n",
      "-> q_focused_parts: [(Place, ['Q29468697', 'Q11239637', 'Q5482205']), (Haldane, ['Q21449630', 'Q1903723']), (1st, ['Q18695647', 'Q12470229']), (Viscount, ['Q1213619', 'Q1137051']), (Richard, ['Q1046096', 'Q10862233', 'Q1249148', 'Q1402996']), (Death, ['Q4', 'Q161936'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.37s\n",
      "-->  685 nodes and 684 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 685 nodes and 684 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 685 nodes or 684 edges was above the limit of 350\n",
      "-> predicates_dict: {'P2670': 2, 'P642': 2, 'P279': 2, 'P1557': 1, 'P373': 1, 'P19': 1, 'P1542': 2, 'P1013': 3, 'P31': 289, 'P805': 4, 'P1343': 4, 'P360': 2, 'P828': 1, 'P1963': 1, 'P1536': 2, 'P921': 2, 'P910': 1, 'P734': 2, 'P606': 1, 'P39': 1, 'P156': 1, 'P175': 1, 'P137': 1, 'P798': 1}\n",
      "-> paths_keywords: (['place', 'haldane', '1st', 'viscount', 'richard', 'death', 'place of death', 'francis place', '3972 richard', 'richard zimmermann'], {'instance of': [instance of, ['P31']], 'date of death': [date of death, ['P570']], 'place of death': [place of death, ['P20']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 48972\n",
      "->Computing possible paths \tRunning time is 48.1s\n",
      "---> Too many paths, statistically it's not worth the run. Cancelling question, it probably require reasoning.\n",
      "\n",
      "->\tRunning time is 202.0s\n",
      "False ---> result_tmqa: Q758623\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-545.pickle.bz2\n",
      "question      what was richard haldane, 1st viscount haldane...\n",
      "source                                                  Q758623\n",
      "qanswer                                                 Q758623\n",
      "platypus                                                  False\n",
      "convex                                                  Q758623\n",
      "tm1                                                       False\n",
      "tm1_time                                                    202\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 545, dtype: object\n",
      "\n",
      "\n",
      "546/9961 who was the child of nefertari -> source: Q460946\n",
      "User input: who was the child of nefertari\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the child of nefertari \n",
      "-> q_themes: ([(the child, ['Q466024', 'Q3441905']), (The Child, ['Q20277876', 'Q1169286']), (Nefertari, ['Q540222', 'Q1218432']), (child, ['Q7569', 'Q23038905'])], [nefertari])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (child, ['P40', 'P22'])]\n",
      "-> q_predicates \tRunning time is 7.54s\n",
      "-> q_focused_parts: [(the child, ['Q466024', 'Q3441905'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 47.64s\n",
      "-->  114 nodes and 116 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 95 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 4 ... Previously: 95 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 48.26s\n",
      "-->  131 nodes and 136 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 108 nodes and 114 edges\n",
      "-> predicates_dict: {'P40': 1, 'P935': 1, 'P101': 1, 'P106': 1, 'P144': 1, 'P1445': 1, 'P155': 1, 'P1478': 1, 'P805': 1, 'P1343': 1, 'P518': 1, 'P186': 2, 'P585': 1, 'P166': 1, 'P407': 3, 'P856': 2, 'P156': 1, 'P1191': 1, 'P571': 1, 'P20': 1, 'P291': 4, 'P577': 4, 'P22': 1, 'P364': 2, 'P580': 1, 'P195': 1, 'P31': 6, 'P1476': 1, 'P26': 1, 'P4895': 1, 'P840': 1, 'P97': 1, 'P910': 1, 'P2360': 3, 'P1434': 1, 'P453': 4, 'P161': 4, 'P1981': 1, 'P217': 1, 'P276': 1, 'P2747': 1, 'P462': 1, 'P1545': 1, 'P4908': 1}\n",
      "-> paths_keywords: (['the child', 'child', 'nefertari'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 1542\n",
      "->Computing possible paths \tRunning time is 24.33s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 1164\n",
      "->\tRunning time is 3.08s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q5287', 4.936739324284452], ['Q158052', 1.1266725452098396], ['Q11424', 0.9479735287534822], ['Q1860', 0.8643445971230035], ['1988-11-21T00:00:00Z', 0.7477694094463193], ['2005-01-01T00:00:00Z', 0.419676383891622], ['Q101583', -0.18187212039333625]]\n",
      "->Computing hypothesises \tRunning time is 29.72s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 7\n",
      "->\tRunning time is 14.62s\n",
      "--> len(cleared_golden_paths): 4\n",
      "---> First path: ['Q5287', 'P407', 'Q466024', 'P585', '2005-01-01T00:00:00Z']\n",
      "->\tTotal Running time is 177.74s\n",
      "\n",
      "->\tRunning time is 177.96s\n",
      "False ---> result_tmqa: Q460946\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-546.pickle.bz2\n",
      "question                         who was the child of nefertari\n",
      "source                                                  Q460946\n",
      "qanswer                                                Q1035391\n",
      "platypus                                                  False\n",
      "convex                                                  Q460176\n",
      "tm1           [Q5287, Q158052, Q11424, Q1860, 1988-11-21T00:...\n",
      "tm1_time                                                 177.96\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 546, dtype: object\n",
      "\n",
      "\n",
      "547/9961 what kind of music is the album intercontinental -> source: Q8341\n",
      "User input: what kind of music is the album intercontinental\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of music is the album intercontinental \n",
      "-> q_themes: ([(music, ['Q638', 'Q19820041']), (the album, ['Q343265', 'Q1965559']), (Music, ['Q11232372', 'Q11232362']), (kind, ['Q16871404'])], [The Album Intercontinental])\n",
      "-> q_themes_enhanced: [('Album', ['Q10404408']), ('Intercontinental', ['Q19891948']), ('The Album', ['Q1965559'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: kind\n",
      "behold: get_most_similar started with: album\n",
      "behold: get_most_similar started with: intercontinental\n",
      "-> q_predicates: [(be, ['P31']), (kind, []), (music, ['P136']), (album, []), (intercontinental, [])]\n",
      "-> q_predicates \tRunning time is 71.88s\n",
      "-> q_focused_parts: [(kind, ['Q16871404']), (music, ['Q638', 'Q19820041'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 49.43s\n",
      "-->  453 nodes and 448 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 425 nodes and 422 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 425 nodes or 422 edges was above the limit of 350\n",
      "-> predicates_dict: {'P1013': 1, 'P1810': 1, 'P4900': 1, 'P156': 2, 'P31': 82, 'P361': 1, 'P155': 1, 'P136': 93, 'P805': 4, 'P1343': 4, 'P108': 1, 'P360': 1, 'P3744': 1, 'P407': 2, 'P3984': 1, 'P5102': 1, 'P1552': 1, 'P137': 1, 'P131': 1, 'P264': 3, 'P175': 4, 'P17': 1, 'P1619': 1, 'P1705': 1, 'P3879': 1, 'P282': 1}\n",
      "-> paths_keywords: (['kind', 'music', 'the album'], {'instance of': [instance of, ['P31']], 'genre': [genre, ['P136']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 10556\n",
      "->Computing possible paths \tRunning time is 17.1s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 9924\n",
      "->\tRunning time is 18.07s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q51526364', 7.241235675467092], ['Q7438811', 5.818876747182983], ['Q37925959', 5.581527591473711], ['Q7722301', 5.579863779459586], ['Q1640319', 4.926101933954074], ['Q1032592', 4.908724780035315], ['Q21330317', 4.293614478486547], ['Q131578', 4.107310342516751], ['Q7000725', 3.599454532281809], ['Q6010', 2.381632675552633], ['Q537222', 1.078854955009554], ['Q11590731', 0.8972908651675483], ['Q1988097', 0.8972908651675483], ['Q6164975', -0.23748922151109975], ['Q1314519', -0.2541099077944305]]\n",
      "->Computing hypothesises \tRunning time is 51.63s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 158\n",
      "->\tRunning time is 73.06s\n",
      "--> len(cleared_golden_paths): 79\n",
      "---> First path: ['Q51526364', 'P136', 'Q638', 'P31', 'Q16894106']\n",
      "->\tTotal Running time is 335.73s\n",
      "\n",
      "->\tRunning time is 335.97s\n",
      "False ---> result_tmqa: Q8341\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-547.pickle.bz2\n",
      "question       what kind of music is the album intercontinental\n",
      "source                                                    Q8341\n",
      "qanswer                                                   False\n",
      "platypus                                                  False\n",
      "convex                                                Q10532577\n",
      "tm1           [Q51526364, Q7438811, Q37925959, Q7722301, Q16...\n",
      "tm1_time                                                 335.97\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 547, dtype: object\n",
      "\n",
      "\n",
      "548/9961 What time zone is lillestrøm located in -> source: Q25989\n",
      "User input: What time zone is lillestrøm located in\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What time zone is lillestrom located in \n",
      "-> q_themes: ([(Lillestrøm, ['Q934871']), (Time Zone, ['Q12143', 'Q187116'])], [What time zone, lillestrøm, Lillestrom])\n",
      "-> q_themes_enhanced: [('time zone', ['P421']), ('time', ['Q11471']), ('zone', ['P3610']), ('Time zone', ['P421'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (located, ['P276', 'P131']), (time, ['P585', 'P421']), (zone, ['P3610'])]\n",
      "-> q_predicates \tRunning time is 7.85s\n",
      "-> q_focused_parts: [(time, ['Q11471', 'Q14333806', 'P585', 'P421'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 38.97s\n",
      "-->  243 nodes and 242 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 243 nodes and 242 edges\n",
      "-> predicates_dict: {'P1963': 2, 'P131': 7, 'P373': 1, 'P360': 3, 'P805': 1, 'P1343': 2, 'P159': 3, 'P958': 1, 'P407': 1, 'P527': 3, 'P19': 3, 'P1464': 1, 'P361': 2, 'P2354': 1, 'P31': 76, 'P1792': 1, 'P642': 1, 'P279': 1, 'P1444': 2, 'P2044': 1, 'P921': 4, 'P1482': 1, 'P404': 1, 'P1036': 1, 'P437': 1}\n",
      "-> paths_keywords: (['time', 'located', 'lillestrøm', 'time zone'], {'instance of': [instance of, ['P31']], 'located in': [located in, ['P276']], 'is in the administrative unit': [is in the administrative unit, ['P131']], 'point in time': [point in time, ['P585']], 'time zone': [located in time zone, ['P421']], 'fare zone': [fare zone, ['P3610']], 'located in time zone': [located in time zone, ['P421']], 'zone': [fare zone, ['P3610']], 'Time zone': [located in time zone, ['P421']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 2936\n",
      "->Computing possible paths \tRunning time is 23.57s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 2051\n",
      "->\tRunning time is 3.64s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q876791', 19.63818761565172], ['Q1037544', 18.867924528301888], ['Q941023', 5.828980565268052], ['Q3134980', 5.824694854481783], ['Q847142', 5.8026087303079], ['Q2085376', 5.7990307309168845], ['Q4816926', 5.768332249872059], ['Q1773949', 5.764078244766354], ['Q190252', 5.761014368044072], ['Q1773995', 5.7573685731336095], ['Q2234548', 5.751994627281425], ['Q1322118', 5.628859167355453], ['Q2356448', 5.628470255956481], ['Q2347353', 5.6229562742257215], ['Q2620414', 5.614067700836679], ['Q30259450', 2.885698299940332], ['Q30259555', 1.6283642446335207], ['Q21168029', 1.5957247065784523], ['Q20828350', 1.2246692599843474], ['Q2166209', 1.1790887399502252], ['Q2583609', 1.1684975772729929], ['Q30192', 1.1637404986281445], ['Q20988530', 1.1628666218950525], ['Q25989', 1.1543794351861945], ['Q2392297', 1.1298395214243828], ['Q3238805', 1.0726823335876499], ['Q2598703', 1.0662290550752807], ['Q2420151', 1.011174157861914], ['Q18355572', 0.9260609361686358], ['Q8740348', 0.8595247082668139], ['Q2724190', 0.8477328487453036], ['Q3208688', 0.8394820121204534], ['Q22676729', 0.8188262815732832], ['Q2280365', 0.8176837109614838], ['Q1087393', 0.7715722371466175], ['Q20757515', 0.7104614308635264], ['Q486972', 0.702708864794115], ['Q16888326', 0.6969438788539886], ['Q30016705', 0.6513826701084229], ['Q10298312', 0.5453727666568967], ['Q27963524', 0.5090225289094522], ['Q57871', 0.0], ['Q6978054', 0.0]]\n",
      "->Computing hypothesises \tRunning time is 294.39s\n",
      "-> Computing golden paths...\n"
     ]
    }
   ],
   "source": [
    "banning_str = False#[[\"ř\",\"r\"],[\"ø\",\"o\"]]\n",
    "\n",
    "df_loaded_len = len(df_loaded)\n",
    "for i, question in enumerate(df_loaded['question']):\n",
    "    if i >= 535:\n",
    "        source = str(df_loaded['source'][i])\n",
    "        print(str(i)+\"/\"+str(df_loaded_len),question,\"-> source:\",source)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result_tmqa = ask_tmqa(question, verbose=True, timer=True, banning_str=banning_str)\n",
    "        \n",
    "        if result_tmqa:\n",
    "            df_loaded['tm1'][i] = result_tmqa[0]\n",
    "            if source in result_tmqa[:2]:\n",
    "                df_loaded['tm1_top2'][i] = True\n",
    "            if source in result_tmqa[:3]:\n",
    "                df_loaded['tm1_top3'][i] = True\n",
    "            if source in result_tmqa[:4]:\n",
    "                df_loaded['tm1_top4'][i] = True\n",
    "            if source in result_tmqa[:5]:\n",
    "                df_loaded['tm1_top5'][i] = True\n",
    "            if source in result_tmqa:\n",
    "                df_loaded['tm1_topall'][i] = True\n",
    "        else:\n",
    "            df_loaded['tm1'][i] = False\n",
    "        end_time = time.time()\n",
    "        df_loaded['tm1_time'][i] = round(end_time-start_time,2)\n",
    "        print(\"->\\tRunning time is {}s\".format(round(end_time-start_time,2)))\n",
    "        print(str(str(df_loaded['tm1'][i])==str(source)),\"---> result_tmqa:\",str(source))\n",
    "        \n",
    "        pickle_data(df_loaded, \"benchmarking-qanswer-platypus-convex-graphqa-from-0-to-\"+str(i))\n",
    "        \n",
    "        print(df_loaded.loc[i,:])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_loaded.copy()\n",
    "#df = df.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = 150\n",
    "df_len = len(df)\n",
    "df_qanswer_max = df[(df.index<=max_row) & (df.qanswer == df.source)]\n",
    "df_qanswer_max_len = len(df_qanswer_max)\n",
    "\n",
    "df_platypus_max = df[(df.index<=max_row) & (df.platypus == df.source)]\n",
    "df_platypus_max_len = len(df_platypus_max)\n",
    "\n",
    "df_convex_max = df[(df.index<=max_row) & (df.convex == df.source)]\n",
    "df_convex_max_len = len(df_convex_max)\n",
    "\n",
    "df_tm1_max = df[(df.index<=max_row) & (df.tm1 == df.source)]\n",
    "df_tm1_max_len = len(df_tm1_max)\n",
    "\n",
    "df_tm1_max_top2 = df[(df.index<=max_row) & (df.tm1_top2 == True)]\n",
    "df_tm1_max_top2_len = len(df_tm1_max_top2)\n",
    "\n",
    "df_tm1_max_top3 = df[(df.index<=max_row) & (df.tm1_top3 == True)]\n",
    "df_tm1_max_top3_len = len(df_tm1_max_top3)\n",
    "\n",
    "df_tm1_max_top4 = df[(df.index<=max_row) & (df.tm1_top4 == True)]\n",
    "df_tm1_max_top4_len = len(df_tm1_max_top4)\n",
    "\n",
    "df_tm1_max_top5 = df[(df.index<=max_row) & (df.tm1_top5 == True)]\n",
    "df_tm1_max_top5_len = len(df_tm1_max_top5)\n",
    "\n",
    "df_tm1_max_topall = df[(df.index<=max_row) & (df.tm1_topall == True)]\n",
    "df_tm1_max_topall_len = len(df_tm1_max_topall)\n",
    "\n",
    "print(\"qanswer:\", df_qanswer_max_len,df_qanswer_max_len/max_row)\n",
    "print(\"platypus:\", df_platypus_max_len, df_platypus_max_len/max_row)\n",
    "print(\"convex:\", df_convex_max_len, df_convex_max_len/max_row)\n",
    "print(\"tm1:\", df_tm1_max_len, df_tm1_max_len/max_row)\n",
    "print(\"tm1_top2:\", df_tm1_max_top2_len, df_tm1_max_top2_len/max_row)\n",
    "print(\"tm1_top3:\", df_tm1_max_top3_len, df_tm1_max_top3_len/max_row)\n",
    "print(\"tm1_top4:\", df_tm1_max_top4_len, df_tm1_max_top4_len/max_row)\n",
    "print(\"tm1_top5:\", df_tm1_max_top5_len, df_tm1_max_top5_len/max_row)\n",
    "print(\"tm1_topall:\", df_tm1_max_topall_len, df_tm1_max_topall_len/max_row)\n",
    "\n",
    "#df[ & (df.qanswer == df.source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"qanswer:\",len(df[df.qanswer == df.source]),len(df[df.qanswer == df.source])/len(df))\n",
    "print(\"platypus:\",len(df[df.platypus == df.source]),len(df[df.platypus == df.source])/len(df))\n",
    "print(\"convex:\",len(df[df.convex == df.source]),len(df[df.convex == df.source])/len(df))\n",
    "print(\"tm1:\",len(df[df.tm1 == df.source]),len(df[df.tm1 == df.source])/len(df))\n",
    "print(\"tm1_top2:\",len(df[df.tm1_top2 == True]),len(df[df.tm1_top2 == True])/len(df))\n",
    "print(\"tm1_top3:\",len(df[df.tm1_top3 == True]),len(df[df.tm1_top3 == True])/len(df))\n",
    "print(\"tm1_top4:\",len(df[df.tm1_top4 == True]),len(df[df.tm1_top4 == True])/len(df))\n",
    "print(\"tm1_top5:\",len(df[df.tm1_top5 == True]),len(df[df.tm1_top5 == True])/len(df))\n",
    "print(\"tm1_topall:\",len(df[df.tm1_topall == True]),len(df[df.tm1_topall == True])/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tm1_top2 = df.tm1_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qa]",
   "language": "python",
   "name": "conda-env-qa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
