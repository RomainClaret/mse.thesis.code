{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:25: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the params file\n",
      "Input encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Input decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "Output encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Output decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3673: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 202, 256)     25088       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 202, 128)     12544       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 202, 256)     525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 202, 256)     263168      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 202, 202)     0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 202, 202)     0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 202, 256)     0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 202, 512)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 202, 128)     65664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 202, 98)      12642       time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 904,418\n",
      "Trainable params: 904,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Hi! My PID is 29880\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import convex as cx\n",
    "import tmqa35 as tmqa\n",
    "import importlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(tmqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_test = open(\"/data/users/romain.claret/tm/wikidata-simplequestions/annotated_wd_data_test.txt\",'r')\n",
    "#out_test = f_test.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(df, filename):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    filename = \"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/\"+filename+'.pickle.bz2'\n",
    "    #df.summary = df.summary.map(sanitize_str)\n",
    "    print(\"Done!\",filename)\n",
    "    return df.to_pickle(filename, compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang: en, fr, de, it, es, zh\n",
    "#kb: dbpedia, wikidata, dblp, freebase\n",
    "def ask_qanswer(question):\n",
    "    data = {'query': question,'lang': 'en','kb': 'wikidata'}\n",
    "    query = requests.post('http://qanswer-core1.univ-st-etienne.fr/api/gerbil', data=data)\n",
    "    if not query:\n",
    "        return False\n",
    "    if (query.json()['questions'][0]['question']['answers']) == None:\n",
    "        return False\n",
    "    #if (query.json()['questions'][0]['question']['answers'].replace('\\n', '')) == None:\n",
    "    #    return False\n",
    "    #print(query.json()['questions'][0]['question']['answers'].replace('\\n', '').get(\"results\"))\n",
    "    try:\n",
    "        response = (json.loads(query.json()\n",
    "                .get(\"questions\")[0]\n",
    "                .get(\"question\")\n",
    "                .get(\"answers\")\n",
    "                .replace('\\n', ''))\n",
    "         .get(\"results\").get(\"bindings\"))\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "    if response:\n",
    "        return response[0].get(\"o1\").get(\"value\")[len(\"http://www.wikidata.org/entity/\"):] if response[0].get(\"o1\") is not None else False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#ask_qanswer(\"Who is the wife of Barack Obama\")\n",
    "#ask_qanwser(\"Which equestrian was born in dublin?\")\n",
    "#ask_qanswer(\"what is the main language spoken in a ghentar si muore facile\")\n",
    "#ask_qanswer(\"was the film helpmates in color or black-and-white?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_platypus(question):\n",
    "    headers = {'Accept': 'application/json','Accept-Language': 'en',}\n",
    "    params = (('q', question),('lang', 'en'))\n",
    "\n",
    "    response = requests.get('https://qa.askplatyp.us/v0/ask', headers=headers, params=params)\n",
    "    if response:\n",
    "        if type(response.json()['member']) is list:\n",
    "            #print(response.json()['member'][0]['result'])\n",
    "            if response.json()['member'] != []:\n",
    "                if '@id' in (json.dumps(response.json()['member'][0]['result'])):\n",
    "                    ps_result = (json.dumps(response.json()['member'][0]['result']['@id']))\n",
    "                else: return False\n",
    "            else: return False\n",
    "        else:\n",
    "            try:\n",
    "                if '@id' in (json.dumps(response.json()['member']['result'])):\n",
    "                    ps_result = (json.dumps(response.json()[\"member\"]['result']['@id']))\n",
    "                else: return False\n",
    "            except:\n",
    "                return False\n",
    "    else: return False\n",
    "    ps_result = ps_result[4:-1]\n",
    "    #print(result[:1])\n",
    "    if ps_result[:1] != 'P' and ps_result[:1] != 'Q':\n",
    "        return False\n",
    "    return ps_result\n",
    "#ask_platypus(\"Which genre of album is harder.....faster?\")\n",
    "#ask_platypus(\"how does engelbert zaschka identify\")\n",
    "#ask_platypus(\"Which Swiss conductor's cause of death is myoc...\")\n",
    "#ask_platypus(\"where was padraic mcguinness's place of death\")\n",
    "#ask_platypus(\"was the film helpmates in color or black-and-white?\")\n",
    "#ask_platypus(\"Who created the show life on earth\")\n",
    "#ask_platypus(\"Who is the wife of Barack Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_convex(question):\n",
    "    cx_result = cx.answer_complete_question(question, cx.tagmeToken)['answers'][0]['answer']\n",
    "    #print(cx_result)\n",
    "    #answer = str(cx.wd.wikidata_id_to_label(result['answers'][0]['answer']))\n",
    "    try:\n",
    "        if not cx_result:\n",
    "            return cx_result\n",
    "        if cx_result[:1] != 'P' and cx_result[:1] != 'Q':\n",
    "            return False\n",
    "        return cx_result\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#ask_convex(\"Which actor voiced the Unicorn in The Last Unicorn?\")\n",
    "#ask_convex(\"Which genre of album is harder.....faster?\")\n",
    "#ask_convex(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#ask_convex(\"Who is the wife of Barack Obama\")\n",
    "#ask_convex(\"100% senorita is a television show in what language?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_tmqa(question, verbose=False, timer=False, show_graph=False, cores=tmqa.mp.cpu_count(), banning_str=False):\n",
    "    tmqa_result = tmqa.answer_question(question, verbose=verbose, timer=timer, show_graph=show_graph, cores=cores, banning_str=banning_str)\n",
    "    #print(tmqa_result)\n",
    "    if not tmqa_result:\n",
    "        return tmqa_result\n",
    "    if tmqa_result == (False,False):\n",
    "        return False\n",
    "    #if tmqa_result[]\n",
    "    #if tmqa_result[0][0][:1] != 'P' and tmqa_result[0][0][:1] != 'Q':\n",
    "    #    return False\n",
    "    return tmqa_result[0][0]\n",
    "\n",
    "#answer = ask_tmqa_1(\"Which actor voiced the Unicorn in The Last Unicorn?\", verbose=True)\n",
    "#answer = ask_tmqa_1(\"what's akbar tandjung's ethnicity\", verbose=True)\n",
    "#ask_tmqa_1(\"Which genre of album is harder.....faster?\")\n",
    "#ask_tmqa_1(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#answer = ask_tmqa(\"Who is the wife of Barack Obama\")\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate qanswer\n",
    "#arguments[0] Subject\n",
    "#arguments[1] Predicate\n",
    "#arguments[2] Object\n",
    "#arguments[3] question\n",
    "\n",
    "#HEADERS = ['question', 'source', 'qanswer', 'platypus', 'convex', 'tmqa']\n",
    "#df = pd.DataFrame(columns=HEADERS)\n",
    "\n",
    "#start_time = time.time()\n",
    "#out_test_len = len(out_test)\n",
    "##print(out_test_len)\n",
    "#for i, line in enumerate(out_test):\n",
    "#    arguments = line.split(\"\\t\")\n",
    "#    print(\"\\r\\t>>> Processing {}/{}: {}\".format(i,out_test_len,arguments[3][:-1]), end='                                  ')\n",
    "#    if i < len(df):\n",
    "#        continue\n",
    "#    result_qanswer = ask_qanswer(arguments[3][:-1])\n",
    "#    result_platypus = ask_platypus(arguments[3][:-1])\n",
    "#    result_convex = ask_convex(arguments[3][:-1])\n",
    "#    #result_tmqa = ask_tmqa(arguments[3][:-1])[1]\n",
    "#    print(\"\\n\",i, \"-> qAnswer\", result_qanswer) if result_qanswer == arguments[2] else False\n",
    "#    print(\"\\n\",i, \"-> Platypus\", result_platypus) if result_platypus == arguments[2] else False\n",
    "#    print(\"\\n\",i, \"-> Convex\", result_convex) if result_convex == arguments[2] else False\n",
    "#    #print(\"\\n\",i, \"-> TMqa\", result_tmqa) if result_tmqa == arguments[2] else False\n",
    "#    df = df.append({\"question\":arguments[3][:-1], 'source':arguments[2], 'qanswer':result_qanswer, 'platypus':result_platypus, 'convex':result_convex, 'tmqa1':result_tmqa}, ignore_index=True)\n",
    "#\n",
    "#end_time = time.time()\n",
    "#print(\"->\\tRunning time is {}s\".format(round(end_time-start_time,2)))\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "#pickle_data(df_loaded, \"benchmarking-qanswer-platypus-convex-graphqa-from-0-to-\"+str(len(df_loaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "#df_loaded = pd.read_pickle(\"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-9961.pickle.bz2\")\n",
    "\n",
    "#/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-5.pickle.bz2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['qanswer'][34] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_loaded['tm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded.rename({'mine':'tm1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['tm1_top4'] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded[['question','source','qanswer','platypus','convex','tm1','tm1_time','tm1_top2','tm1_top3','tm1_top4','tm1_top5','tm1_topall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING QAGraph\n",
    "\n",
    "df_loaded = pd.read_pickle(\"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-6455.pickle.bz2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question      object\n",
      "source        object\n",
      "qanswer       object\n",
      "platypus      object\n",
      "convex        object\n",
      "tm1           object\n",
      "tm1_time      object\n",
      "tm1_top2      object\n",
      "tm1_top3      object\n",
      "tm1_top4      object\n",
      "tm1_top5      object\n",
      "tm1_topall    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_loaded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is  2020-03-09 19:43:01.136405\n",
      "6457/9961 what is a game with single_player as its gameplay mode -> source: Q7602433\n",
      "User input: what is a game with single_player as its gameplay mode\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is a game with single player as its gameplay mode \n",
      "-> q_themes: ([(a game, ['Q4646897']), (game, ['Q11410', 'Q15079592'])], [its gameplay mode, single_player, Single_player, Its Gameplay Mode, gameplay mode, its Gameplay Mode])\n",
      "-> q_themes_enhanced: [('gameplay', ['P404']), ('mode', ['Q188224']), ('Gameplay', ['Q2720327']), ('Mode', ['Q11883080'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: single\n",
      "behold: get_most_similar started with: player\n",
      "-> q_predicates: [(be, ['P31']), (game, ['P1350']), (single, ['P555']), (player, ['P1873', 'P1872']), (gameplay, ['P404']), (mode, ['P404'])]\n",
      "-> q_predicates \tRunning time is 11.23s\n",
      "--> Potential meaningful keywords for the sentence: ['a game', 'game', 'gameplay', 'mode', 'Gameplay', 'Mode']\n",
      "q_focused_parts: [(player, ['Q18536342', 'Q4197743']), (single, ['Q1307021', 'Q1196988', 'Q1309930']), (mode, ['Q188224', 'Q3317768', 'P404']), (gameplay, ['P404', 'Q1331296'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 48.61s\n",
      "-->  1629 nodes and 1626 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 1620 nodes and 1618 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 1620 nodes or 1618 edges was above the limit of 350\n",
      "---> Too many nodes, statistically it's not worth the run. Cancelling question, it probably require reasoning.\n",
      "\n",
      "->\tRunning time is 111.6s\n",
      "False ---> result_tmqa: Q7602433\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-6457.pickle.bz2\n",
      "question      what is a game with single_player as its gamep...\n",
      "source                                                 Q7602433\n",
      "qanswer                                                   False\n",
      "platypus                                                  False\n",
      "convex                                                    Q6654\n",
      "tm1                                                       False\n",
      "tm1_time                                                  111.6\n",
      "tm1_top2                                                  False\n",
      "tm1_top3                                                  False\n",
      "tm1_top4                                                  False\n",
      "tm1_top5                                                  False\n",
      "tm1_topall                                                False\n",
      "Name: 6457, dtype: object\n",
      "\n",
      "\n",
      "It is  2020-03-09 19:44:52.945297\n",
      "6458/9961 what is the genre of heat -> source: Q860626\n",
      "User input: what is the genre of heat\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the genre of heat \n",
      "-> q_themes: ([(heat, ['Q44432', 'Q28974922']), (Heat, ['Q1149669', 'Q12485481']), (genre, ['Q483394', 'P136'])], [the genre, The Genre, the Genre])\n",
      "-> q_themes_enhanced: [('Genre', ['Q28490034', 'P136'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: heat\n",
      "-> q_predicates: [(be, ['P31']), (genre, ['P136']), (heat, ['P2076'])]\n",
      "-> q_predicates \tRunning time is 5.15s\n",
      "--> Potential meaningful keywords for the sentence: ['heat', 'Heat', 'genre', 'Genre']\n",
      "q_focused_parts: [(genre, ['Q483394', 'Q188451', 'P136']), (heat, ['Q28974922', 'Q44432'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.04s\n",
      "-->  403 nodes and 398 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 398 nodes and 394 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 398 nodes or 394 edges was above the limit of 350\n",
      "-> predicates_dict: {'P642': 2, 'P828': 1, 'P279': 2, 'P136': 5, 'P31': 153, 'P373': 1, 'P360': 1, 'P407': 1, 'P3499': 1, 'P364': 1, 'P1963': 1, 'P111': 1, 'P577': 6, 'P348': 6, 'P618': 1, 'P910': 1, 'P495': 1, 'P1880': 1, 'P2047': 1, 'P123': 1}\n",
      "-> paths_keywords: (['genre', 'heat', 'music genre'], {'instance of': [instance of, ['P31']], 'Genre': [genre, ['P136']], 'temperature': [temperature, ['P2076']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 2110\n",
      "->Computing possible paths \tRunning time is 16.38s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 2102\n",
      "->\tRunning time is 4.67s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q4104520', 15.047053746350425], ['Q4413495', 14.942403782637914], ['Q4150965', 14.878461680573585], ['Q130232', 4.032542237683055], ['Q20442589', 4.004549466163114]]\n",
      "->Computing hypothesises \tRunning time is 9.11s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 84\n",
      "->\tRunning time is 10.62s\n",
      "--> len(cleared_golden_paths): 42\n",
      "---> First path: ['Q4104520', 'P136', 'Q483394', 'P31', 'Q11865310']\n",
      "->\tTotal Running time is 110.01s\n",
      "\n",
      "->\tRunning time is 110.41s\n",
      "False ---> result_tmqa: Q860626\n",
      "Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/wd-sq/benchmarking-qanswer-platypus-convex-graphqa-from-0-to-6458.pickle.bz2\n",
      "question      what is the genre of heat\n",
      "source                          Q860626\n",
      "qanswer                         Q130232\n",
      "platypus                          False\n",
      "convex                         Q7481824\n",
      "tm1                            Q4104520\n",
      "tm1_time                         110.41\n",
      "tm1_top2                          False\n",
      "tm1_top3                          False\n",
      "tm1_top4                          False\n",
      "tm1_top5                          False\n",
      "tm1_topall                        False\n",
      "Name: 6458, dtype: object\n",
      "\n",
      "\n",
      "It is  2020-03-09 19:46:43.599324\n",
      "6459/9961 What is the name of a black-and-white film? -> source: Q7432122\n",
      "User input: What is the name of a black-and-white film?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of a black and white film \n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (film, ['Q11424']), (Film, ['Q12871879', 'Q11332514']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'Q503992'])], [a black and white film, A Black And White Film, a black and white Film])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: white\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (black, ['P4248']), (white, ['P4248']), (film, ['P57'])]\n",
      "-> q_predicates \tRunning time is 7.14s\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'film', 'Film', 'The Name', 'name']\n",
      "q_focused_parts: [(film, ['Q11424']), (black, ['Q23445', 'Q17244465']), (white, ['Q235155', 'Q28308148', 'Q1237438', 'Q23444'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 41.73s\n",
      "-->  1855 nodes and 1852 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 1855 nodes and 1852 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 1855 nodes or 1852 edges was above the limit of 350\n"
     ]
    }
   ],
   "source": [
    "banning_str = False#[[\"ř\",\"r\"],[\"ø\",\"o\"]]\n",
    "\n",
    "df_loaded_len = len(df_loaded)\n",
    "for i, question in enumerate(df_loaded['question']):\n",
    "    if i >= 6457:\n",
    "        print(\"It is \", datetime.now())\n",
    "        \n",
    "        source = str(df_loaded['source'][i])\n",
    "        print(str(i)+\"/\"+str(df_loaded_len),question,\"-> source:\",source)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result_tmqa = ask_tmqa(question, verbose=True, timer=True, show_graph=False, banning_str=banning_str) \n",
    "        if result_tmqa:\n",
    "            df_loaded['tm1'][i] = result_tmqa[0]\n",
    "            if source in result_tmqa[:2]:\n",
    "                df_loaded['tm1_top2'][i] = True\n",
    "            if source in result_tmqa[:3]:\n",
    "                df_loaded['tm1_top3'][i] = True\n",
    "            if source in result_tmqa[:4]:\n",
    "                df_loaded['tm1_top4'][i] = True\n",
    "            if source in result_tmqa[:5]:\n",
    "                df_loaded['tm1_top5'][i] = True\n",
    "            if source in result_tmqa:\n",
    "                df_loaded['tm1_topall'][i] = True\n",
    "        else:\n",
    "            df_loaded['tm1'][i] = False\n",
    "        end_time = time.time()\n",
    "        df_loaded['tm1_time'][i] = round(end_time-start_time,2)\n",
    "        print(\"->\\tRunning time is {}s\".format(round(end_time-start_time,2)))\n",
    "        print(str(str(df_loaded['tm1'][i])==str(source)),\"---> result_tmqa:\",str(source))\n",
    "        \n",
    "        pickle_data(df_loaded, \"benchmarking-qanswer-platypus-convex-graphqa-from-0-to-\"+str(i))\n",
    "        \n",
    "        print(df_loaded.loc[i,:])\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded.head(4486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_loaded.copy()\n",
    "#df = df.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = 6454\n",
    "df_len = len(df_copy)\n",
    "df_qanswer_max = df_copy[(df_copy.index<=max_row) & (df_copy.qanswer == df_copy.source)]\n",
    "df_qanswer_max_len = len(df_qanswer_max)\n",
    "\n",
    "df_platypus_max = df_copy[(df_copy.index<=max_row) & (df_copy.platypus == df_copy.source)]\n",
    "df_platypus_max_len = len(df_platypus_max)\n",
    "\n",
    "df_convex_max = df_copy[(df_copy.index<=max_row) & (df_copy.convex == df_copy.source)]\n",
    "df_convex_max_len = len(df_convex_max)\n",
    "\n",
    "df_tm1_max = df_copy[(df_copy.index<=max_row) & (df_copy.tm1 == df_copy.source)]\n",
    "df_tm1_max_len = len(df_tm1_max)\n",
    "\n",
    "df_tm1_max_top2 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top2 == True)]\n",
    "df_tm1_max_top2_len = len(df_tm1_max_top2)\n",
    "\n",
    "df_tm1_max_top3 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top3 == True)]\n",
    "df_tm1_max_top3_len = len(df_tm1_max_top3)\n",
    "\n",
    "df_tm1_max_top4 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top4 == True)]\n",
    "df_tm1_max_top4_len = len(df_tm1_max_top4)\n",
    "\n",
    "df_tm1_max_top5 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top5 == True)]\n",
    "df_tm1_max_top5_len = len(df_tm1_max_top5)\n",
    "\n",
    "df_tm1_max_topall = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_topall == True)]\n",
    "df_tm1_max_topall_len = len(df_tm1_max_topall)\n",
    "\n",
    "print(\"qanswer:\", df_qanswer_max_len,df_qanswer_max_len/max_row)\n",
    "print(\"platypus:\", df_platypus_max_len, df_platypus_max_len/max_row)\n",
    "print(\"convex:\", df_convex_max_len, df_convex_max_len/max_row)\n",
    "print(\"tm1:\", df_tm1_max_len, df_tm1_max_len/max_row)\n",
    "print(\"tm1_top2:\", df_tm1_max_top2_len, df_tm1_max_top2_len/max_row)\n",
    "print(\"tm1_top3:\", df_tm1_max_top3_len, df_tm1_max_top3_len/max_row)\n",
    "print(\"tm1_top4:\", df_tm1_max_top4_len, df_tm1_max_top4_len/max_row)\n",
    "print(\"tm1_top5:\", df_tm1_max_top5_len, df_tm1_max_top5_len/max_row)\n",
    "print(\"tm1_topall:\", df_tm1_max_topall_len, df_tm1_max_topall_len/max_row)\n",
    "\n",
    "#df[ & (df.qanswer == df.source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = 6455\n",
    "\n",
    "df_qanswer_max = df_copy[(df_copy.index<=max_row) & (df_copy.qanswer == df_copy.source)]\n",
    "df_qanswer_max_len = len(df_qanswer_max)\n",
    "\n",
    "df_platypus_max = df_copy[(df_copy.index<=max_row) & (df_copy.platypus == df_copy.source)]\n",
    "df_platypus_max_len = len(df_platypus_max)\n",
    "\n",
    "df_convex_max = df_copy[(df_copy.index<=max_row) & (df_copy.convex == df_copy.source)]\n",
    "df_convex_max_len = len(df_convex_max)\n",
    "\n",
    "df_tm1_max = df_copy[(df_copy.index<=max_row) & (df_copy.tm1 == df_copy.source)]\n",
    "df_tm1_max_len = len(df_tm1_max)\n",
    "\n",
    "df_tm1_max_top2 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top2 == True)]\n",
    "df_tm1_max_top2_len = len(df_tm1_max_top2)\n",
    "\n",
    "df_tm1_max_top3 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top3 == True)]\n",
    "df_tm1_max_top3_len = len(df_tm1_max_top3)\n",
    "\n",
    "df_tm1_max_top4 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top4 == True)]\n",
    "df_tm1_max_top4_len = len(df_tm1_max_top4)\n",
    "\n",
    "df_tm1_max_top5 = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_top5 == True)]\n",
    "df_tm1_max_top5_len = len(df_tm1_max_top5)\n",
    "\n",
    "df_tm1_max_topall = df_copy[(df_copy.index<=max_row) & (df_copy.tm1_topall == True)]\n",
    "df_tm1_max_topall_len = len(df_tm1_max_topall)\n",
    "\n",
    "print(\"PRECISION\")\n",
    "print(\"qanswer:\", df_qanswer_max_len,df_qanswer_max_len)\n",
    "print(\"platypus:\", df_platypus_max_len, df_platypus_max_len)\n",
    "print(\"convex:\", df_convex_max_len, df_convex_max_len)\n",
    "print(\"tm1:\", df_tm1_max_len, df_tm1_max_len)\n",
    "print(\"tm1_top2:\", df_tm1_max_top2_len, df_tm1_max_top2_len/max_row)\n",
    "print(\"tm1_top3:\", df_tm1_max_top3_len, df_tm1_max_top3_len/max_row)\n",
    "print(\"tm1_top4:\", df_tm1_max_top4_len, df_tm1_max_top4_len/max_row)\n",
    "print(\"tm1_top5:\", df_tm1_max_top5_len, df_tm1_max_top5_len/max_row)\n",
    "print(\"tm1_topall:\", df_tm1_max_topall_len, df_tm1_max_topall_len/max_row)\n",
    "\n",
    "#df[ & (df.qanswer == df.source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_row = 6455\n",
    "\n",
    "df_qanswer_recall = (max_row-len(df_copy[(df_copy.index<=max_row) & (df_copy.qanswer == False)]))/max_row\n",
    "df_platypus_recall = (max_row-len(df_copy[(df_copy.index<=max_row) & (df_copy.platypus == False)]))/max_row\n",
    "df_convex_recall = (max_row-len(df_copy[(df_copy.index<=max_row) & (df_copy.convex == False)]))/max_row\n",
    "df_tm1_recall = (max_row-len(df_copy[(df_copy.index<=max_row) & (df_copy.tm1 == False)]))/max_row\n",
    "\n",
    "df_qanswer_precision = len(df_copy[(df_copy.index<=max_row) & (df_copy.qanswer == df_copy.source)])/max_row\n",
    "df_platypus_precision = len(df_copy[(df_copy.index<=max_row) & (df_copy.platypus == df_copy.source)])/max_row\n",
    "df_convex_precision = len(df_copy[(df_copy.index<=max_row) & (df_copy.convex == df_copy.source)])/max_row\n",
    "df_tm1_precision = len(df_copy[(df_copy.index<=max_row) & (df_copy.tm1 == df_copy.source)])/max_row\n",
    "\n",
    "\n",
    "\n",
    "print(\"RECALL\")\n",
    "print(\"qanswer:\", df_qanswer_recall)\n",
    "print(\"platypus:\", df_platypus_recall)\n",
    "print(\"convex:\", df_convex_recall)\n",
    "print(\"tm1:\", df_tm1_recall)\n",
    "                            \n",
    "                            \n",
    "print(\"PRECISION\")\n",
    "print(\"qanswer:\", df_qanswer_precision)\n",
    "print(\"platypus:\", df_platypus_precision)\n",
    "print(\"convex:\", df_convex_precision)\n",
    "print(\"tm1:\", df_tm1_precision)\n",
    "\n",
    "print(\"F1\")\n",
    "print(\"qanswer:\", 2*((df_qanswer_precision*df_qanswer_recall)/(df_qanswer_precision+df_qanswer_recall)))\n",
    "print(\"platypus:\", 2*((df_platypus_precision*df_platypus_recall)/(df_platypus_precision+df_platypus_recall)))\n",
    "print(\"convex:\", 2*((df_convex_precision*df_convex_recall)/(df_convex_precision+df_convex_recall)))\n",
    "print(\"tm1:\", 2*((df_tm1_precision*df_tm1_recall)/(df_tm1_precision+df_tm1_recall)))\n",
    "\n",
    "\n",
    "#df[ & (df.qanswer == df.source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"qanswer:\",len(df_copy[df_copy.qanswer == df_copy.source]),len(df_copy[df_copy.qanswer == df_copy.source])/len(df_copy))\n",
    "print(\"platypus:\",len(df_copy[df_copy.platypus == df_copy.source]),len(df_copy[df_copy.platypus == df_copy.source])/len(df_copy))\n",
    "print(\"convex:\",len(df_copy[df_copy.convex == df_copy.source]),len(df_copy[df_copy.convex == df_copy.source])/len(df_copy))\n",
    "print(\"tm1:\",len(df_copy[df_copy.tm1 == df_copy.source]),len(df_copy[df_copy.tm1 == df_copy.source])/len(df_copy))\n",
    "print(\"tm1_top2:\",len(df_copy[df_copy.tm1_top2 == True]),len(df_copy[df_copy.tm1_top2 == True])/len(df_copy))\n",
    "print(\"tm1_top3:\",len(df_copy[df_copy.tm1_top3 == True]),len(df_copy[df_copy.tm1_top3 == True])/len(df_copy))\n",
    "print(\"tm1_top4:\",len(df_copy[df_copy.tm1_top4 == True]),len(df_copy[df_copy.tm1_top4 == True])/len(df_copy))\n",
    "print(\"tm1_top5:\",len(df_copy[df_copy.tm1_top5 == True]),len(df_copy[df_copy.tm1_top5 == True])/len(df_copy))\n",
    "print(\"tm1_topall:\",len(df_copy[df_copy.tm1_topall == True]),len(df_copy[df_copy.tm1_topall == True])/len(df_copy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tm1_top2 = df.tm1_top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qa]",
   "language": "python",
   "name": "conda-env-qa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
