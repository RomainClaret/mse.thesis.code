{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:25: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/txt2txt/txt2txt.py:27: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the params file\n",
      "Input encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Input decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "Output encoding {'o': 2, '{': 3, '.': 4, 'J': 5, '0': 6, '1': 7, '<': 8, 'B': 9, 'd': 10, '£': 11, 'e': 12, '6': 13, '!': 14, 'O': 15, 'M': 16, 'X': 17, 'f': 18, 't': 19, 'C': 20, 'V': 21, 'z': 22, 'K': 23, '\\\\': 24, '9': 25, 'P': 26, 'S': 27, '/': 28, '₹': 29, 'F': 30, 'G': 31, '=': 32, '8': 33, ')': 34, '+': 35, ']': 36, 'U': 37, \"'\": 38, '\"': 39, 'g': 40, 'N': 41, 'r': 42, 'u': 43, '&': 44, '$': 45, 'x': 46, '%': 47, ':': 48, '@': 49, '^': 50, 'I': 51, 'L': 52, 'Z': 53, 'h': 54, 'W': 55, 'A': 56, 'v': 57, '?': 58, '2': 59, '~': 60, 's': 61, 'T': 62, 'R': 63, ',': 64, '|': 65, '4': 66, '>': 67, 'y': 68, '(': 69, '[': 70, 'k': 71, 'H': 72, 'l': 73, 'j': 74, '7': 75, 'n': 76, 'i': 77, 'D': 78, 'Q': 79, ' ': 80, 'm': 81, 'Y': 82, '*': 83, '}': 84, '#': 85, 'p': 86, 'q': 87, '5': 88, 'c': 89, '`': 90, 'a': 91, 'b': 92, 'w': 93, '3': 94, 'E': 95, ';': 96, '-': 97}\n",
      "Output decoding {2: 'o', 3: '{', 4: '.', 5: 'J', 6: '0', 7: '1', 8: '<', 9: 'B', 10: 'd', 11: '£', 12: 'e', 13: '6', 14: '!', 15: 'O', 16: 'M', 17: 'X', 18: 'f', 19: 't', 20: 'C', 21: 'V', 22: 'z', 23: 'K', 24: '\\\\', 25: '9', 26: 'P', 27: 'S', 28: '/', 29: '₹', 30: 'F', 31: 'G', 32: '=', 33: '8', 34: ')', 35: '+', 36: ']', 37: 'U', 38: \"'\", 39: '\"', 40: 'g', 41: 'N', 42: 'r', 43: 'u', 44: '&', 45: '$', 46: 'x', 47: '%', 48: ':', 49: '@', 50: '^', 51: 'I', 52: 'L', 53: 'Z', 54: 'h', 55: 'W', 56: 'A', 57: 'v', 58: '?', 59: '2', 60: '~', 61: 's', 62: 'T', 63: 'R', 64: ',', 65: '|', 66: '4', 67: '>', 68: 'y', 69: '(', 70: '[', 71: 'k', 72: 'H', 73: 'l', 74: 'j', 75: '7', 76: 'n', 77: 'i', 78: 'D', 79: 'Q', 80: ' ', 81: 'm', 82: 'Y', 83: '*', 84: '}', 85: '#', 86: 'p', 87: 'q', 88: '5', 89: 'c', 90: '`', 91: 'a', 92: 'b', 93: 'w', 94: '3', 95: 'E', 96: ';', 97: '-'}\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:3673: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 202)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 202, 256)     25088       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 202, 128)     12544       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 202, 256)     525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 202, 256)     263168      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 202, 202)     0           lstm_2[0][0]                     \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "attention (Activation)          (None, 202, 202)     0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 202, 256)     0           attention[0][0]                  \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 202, 512)     0           dot_2[0][0]                      \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 202, 128)     65664       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 202, 98)      12642       time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 904,418\n",
      "Trainable params: 904,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Hi! My PID is 6183\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import networkx as nx\n",
    "import convex as cx\n",
    "import tmqa35 as graphqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import importlib\n",
    "#import tmqa35 as graphqa\n",
    "#importlib.reload(graphqa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations_path = \"/data/users/romain.claret/tm/mse.tm.chatbot.base/data/convex/test_set/test_set_ALL.json\"\n",
    "with open(conversations_path, \"r\") as data:\n",
    "    conversations = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickle_data(df, filename):\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    filename = \"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/\"+filename+'.pickle.bz2'\n",
    "    #df.summary = df.summary.map(sanitize_str)\n",
    "    print(\"Saving Dataframe Done!\",filename)\n",
    "    return df.to_pickle(filename, compression='bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_graph(graph):\n",
    "    this_graph = graph.copy()\n",
    "    for n in this_graph.nodes():\n",
    "        n_pos = n.find(\"-\")\n",
    "        n_name = n\n",
    "        if n_pos != -1: n_name = n[:n_pos]\n",
    "        this_graph.nodes[n][\"name\"] = graphqa.get_wd_label(n_name)\n",
    "        this_graph.nodes[n][\"weight\"] = 1\n",
    "        \n",
    "    return this_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang: en, fr, de, it, es, zh\n",
    "#kb: dbpedia, wikidata, dblp, freebase\n",
    "def ask_qanswer(question):\n",
    "    data = {'query': question,'lang': 'en','kb': 'wikidata'}\n",
    "    headers = {\"Authorization\":\"Bearer eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiIzNDIiLCJpYXQiOjE1NzkyNTYxNDQsImV4cCI6MTU3OTg2MDk0NH0.YPFBZ-Xc8OI7eeTTkQaVT5a-CA5VONiCr_VIViG3t8tjVv7eRKgz_X_1KWDnly_F08rLXwpPcDUMBt8_M8-S8w\"}\n",
    "    query = requests.post('http://qanswer-core1.univ-st-etienne.fr/api/gerbil', data=data, headers=headers)\n",
    "    \n",
    "#    var settings = {\n",
    "#  \"async\": true,\n",
    "#  \"crossDomain\": true,\n",
    "#  \"url\": \"http://qanswer-core1.univ-st-etienne.fr/api/qa/full?question=what%20is%20a%20margerita&lang=en&kb=cocktails\",\n",
    "#  \"method\": \"GET\",\n",
    "#  \"headers\": {\n",
    "#    \"Authorization\": \"Bearer eyJhbGciOiJIUzUxMi.....\",\n",
    "#  }\n",
    "#}\n",
    "    \n",
    "    if not query:\n",
    "        return False,False\n",
    "    if (query.json()['questions'][0]['question']['answers']) == None:\n",
    "        return False,False\n",
    "    #if (query.json()['questions'][0]['question']['answers'].replace('\\n', '')) == None:\n",
    "    #    return False\n",
    "    #print(query.json()['questions'][0]['question']['answers'].replace('\\n', '').get(\"results\"))\n",
    "    try:\n",
    "        response = (json.loads(query.json()\n",
    "                .get(\"questions\")[0]\n",
    "                .get(\"question\")\n",
    "                .get(\"answers\")\n",
    "                .replace('\\n', ''))\n",
    "         .get(\"results\").get(\"bindings\"))\n",
    "    except:\n",
    "        return False,False\n",
    "    \n",
    "    if response:\n",
    "        result = response[0].get(\"o1\").get(\"value\")[len(\"http://www.wikidata.org/entity/\"):] if response[0].get(\"o1\") is not None else False\n",
    "        return result,False\n",
    "    else:\n",
    "        return False,False\n",
    "\n",
    "#ask_qanswer(\"Who is the wife of Barack Obama\")\n",
    "#ask_qanwser(\"Which equestrian was born in dublin?\")\n",
    "#ask_qanswer(\"what is the main language spoken in a ghentar si muore facile\")\n",
    "#ask_qanswer(\"was the film helpmates in color or black-and-white?\")\n",
    "#ask_qanswer(\"how does engelbert zaschka identify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_platypus(question):\n",
    "    headers = {'Accept': 'application/json','Accept-Language': 'en',}\n",
    "    params = (('q', question),('lang', 'en'))\n",
    "\n",
    "    response = requests.get('https://qa.askplatyp.us/v0/ask', headers=headers, params=params)\n",
    "    if response:\n",
    "        if type(response.json()['member']) is list:\n",
    "            #print(response.json()['member'][0]['result'])\n",
    "            if response.json()['member'] != []:\n",
    "                if '@id' in (json.dumps(response.json()['member'][0]['result'])):\n",
    "                    try:\n",
    "                        ps_result = (json.dumps(response.json()['member'][0]['result']['@id']))\n",
    "                    except:\n",
    "                        return False, False\n",
    "                else: return False, False\n",
    "            else: return False, False\n",
    "        else:\n",
    "            try:\n",
    "                if '@id' in (json.dumps(response.json()['member']['result'])):\n",
    "                    ps_result = (json.dumps(response.json()[\"member\"]['result']['@id']))\n",
    "                else: return False, False\n",
    "            except:\n",
    "                return False, False\n",
    "    else: return False, False\n",
    "    ps_result = ps_result[4:-1]\n",
    "    #print(result[:1])\n",
    "    #if ps_result[:1] != 'P' and ps_result[:1] != 'Q':\n",
    "    #    return False, False\n",
    "    return ps_result,False\n",
    "\n",
    "#ask_platypus(\"Which genre of album is harder.....faster?\")\n",
    "#ask_platypus(\"how does engelbert zaschka identify\")\n",
    "#ask_platypus(\"Which Swiss conductor's cause of death is myoc...\")\n",
    "#ask_platypus(\"where was padraic mcguinness's place of death\")\n",
    "#ask_platypus(\"was the film helpmates in color or black-and-white?\")\n",
    "#ask_platypus(\"Who created the show life on earth\")\n",
    "#ask_platypus(\"Who is the wife of Barack Obama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_convex(question):\n",
    "    cx_result = cx.answer_complete_question(question, cx.tagmeToken)\n",
    "    graph = cx.gp.expand_context_with_statements(None, [cx_result['context']], qa=True) \n",
    "    graph = standardize_graph(graph)\n",
    "    #print(cx_result)\n",
    "    #answer = str(cx.wd.wikidata_id_to_label(result['answers'][0]['answer']))\n",
    "    try:\n",
    "        if not cx_result:\n",
    "            return False, False\n",
    "        return [[r[\"answer\"] for r in cx_result['answers']],\n",
    "                [cx_result['context'][\"entity\"][\"id\"],cx_result['context'][\"predicate\"][\"id\"],cx_result['context'][\"object\"][\"id\"]]], graph\n",
    "    except:\n",
    "        return False, False\n",
    "\n",
    "#ask_convex(\"Which actor voiced the Unicorn in The Last Unicorn?\")\n",
    "#ask_convex(\"Which genre of album is harder.....faster?\")\n",
    "#ask_convex(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#ask_convex(\"Who is the wife of Barack Obama\")\n",
    "#ask_convex(\"100% senorita is a television show in what language?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_graphqa(question, verbose=True, timer=True, show_graph=False, cores=graphqa.mp.cpu_count(), banning_str=False,\n",
    "            answer_context=False, context_graph=False, use_convex=False, turn=1):\n",
    "    \n",
    "    frontier_detection=[0.9, 0.6, 0.3] #random_access\n",
    "    answer_detection=[0.9, 0.1] #total_distance_qa_nodes, total_distance_frontiers\n",
    "    frontiers=3\n",
    "    \n",
    "    if use_convex:\n",
    "        if not context_graph:\n",
    "            context_graph=nx.Graph()\n",
    "            if answer_context:\n",
    "                if answer_context[0]:\n",
    "                    context_graph.add_node(answer_context[0][0], name=graphqa.get_wd_label(answer_context[0][0]), type='entity', turn=i_q+1, weight=1, qa=True)\n",
    "                \n",
    "        answer_context_convex,context_graph = cx.answer_follow_up_question(question, turn, context_graph, frontier_detection+answer_detection, frontiers)\n",
    "        if context_graph: context_graph = standardize_graph(context_graph)\n",
    "        #answer_context = False\n",
    "        #print(\"answer_context\",answer_context[0]['rank'])\n",
    "        \n",
    "        answer_context=[]\n",
    "        for ac in answer_context_convex:\n",
    "            answer_context.append(ac[\"answer\"])\n",
    "        answer_context = [answer_context,[]]\n",
    "        \n",
    "        if show_graph: graphqa.plot_graph(context_graph, \"file_name_context_graph\", \"Context_Graph_title\")\n",
    "        #if verbose: print(\"Answer:\",graphqa.convert_to_literal(graphqa.get_wd_label(answer_context[0][0])), \"(\"+str(answer_context[0][0])+\")\\n\")\n",
    "        result = answer_context,context_graph\n",
    "    \n",
    "    else:\n",
    "        result = graphqa.answer_question(\n",
    "            question, verbose=verbose, timer=timer, show_graph=show_graph, cores=cores, banning_str=banning_str,\n",
    "            previous_answer=answer_context, previous_graph=context_graph)\n",
    "                    \n",
    "    if not result:\n",
    "        return (False,False)\n",
    "    #if result == (False,False):\n",
    "    #    return (False,False)\n",
    "\n",
    "    return result\n",
    "\n",
    "conversation_questions = [\n",
    "    \"Which actor voiced the Unicorn in The Last Unicorn?\",\n",
    "    \"And Alan Arkin was behind..\",\n",
    "    \"Who did the score?\",\n",
    "    \"So who performed the songs?\",\n",
    "    \"Genre of this band's music?\",\n",
    "    \"By the way, who was the director?\",\n",
    "    \"Is Alan Arkin in the cast ?\",\n",
    "]\n",
    "\n",
    "\n",
    "#for i_q,question in enumerate(conversation_questions):\n",
    "#    if i_q >= 0:\n",
    "#        if i_q == 0:\n",
    "#            answer_context_1,context_graph_1 = ask_graphqa(question ,answer_context=False, context_graph=False, verbose=True, timer=True, show_graph=True)\n",
    "#            answer_context = answer_context_1.copy()\n",
    "#            context_graph = context_graph_1.copy()\n",
    "#        elif context_graph:\n",
    "#            print(\"Context Question:\",question)\n",
    "#            answer_context,context_graph = ask_graphqa(question,answer_context=answer_context, context_graph=context_graph, verbose=True, timer=True, show_graph=True)\n",
    "#        else:\n",
    "#            print(\"NO CONTEXT ERROR\")\n",
    "#            break\n",
    "#\n",
    "#    if answer_context: print(\"Answer:\",graphqa.convert_to_literal(graphqa.get_wd_label(answer_context[0][0])), \"(\"+str(answer_context[0][0])+\")\\n\")\n",
    "#    #break\n",
    "\n",
    "#for i_q,question in enumerate(conversation_questions):\n",
    "#    if i_q >= 0:\n",
    "#        if i_q == 0:\n",
    "#            #answer_context_1,context_graph_1 = ask_graphqa(question ,previous_answer=False, previous_graph=False, verbose=True, timer=True, show_graph=True)\n",
    "#            answer_context = answer_context_1.copy()\n",
    "#            context_graph = context_graph_1.copy()\n",
    "#            continue\n",
    "#        elif context_graph:\n",
    "#            print(\"Context Question:\",question)\n",
    "#            answer_context,context_graph = ask_graphqa(question,answer_context=answer_context, context_graph=context_graph, verbose=True, timer=True, show_graph=True,\n",
    "#                                                       use_convex=True, turn=i_q+1)\n",
    "#        else:\n",
    "#            print(\"NO CONTEXT ERROR\")\n",
    "#            break\n",
    "#\n",
    "#    if answer_context: print(\"Answer:\",graphqa.convert_to_literal(graphqa.get_wd_label(answer_context[0][0])), \"(\"+str(answer_context[0][0])+\")\\n\")\n",
    "#    #break\n",
    "\n",
    "#answer_convex,context_graph = answer_conversation(conversation_questions,answer_convex=False,context_graph=False)\n",
    "\n",
    "#answer = ask_graphqa(\"Which actor voiced the Unicorn in The Last Unicorn?\", verbose=True)\n",
    "#answer = ask_graphqa(\"what's akbar tandjung's ethnicity\", verbose=True)\n",
    "#ask_graphqa(\"Which genre of album is harder.....faster?\")\n",
    "#ask_graphqa(\"Which label is somevelvetsidewalk signed to ttle of fort fisher \")\n",
    "#ask_graphqa(\"Who is the wife of Barack Obama\")\n",
    "#print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = ['conversation_id','turn',\"plus_convex\",\n",
    "           'question', 'answer', 'domain',\n",
    "           'qanswer','qanswer_time', 'qanswer_rr',\n",
    "           'platypus','platypus_time', 'platypus_rr',\n",
    "           'convex','convex_time', 'convex_rr',\n",
    "           'graphqa', \"graphqa_time\", \"graphqa_top2\", \"graphqa_top3\", \"graphqa_top4\", \"graphqa_top5\", \"graphqa_topall\",\"graphqa_rr\"]\n",
    "df = pd.DataFrame(columns=HEADERS)\n",
    "#LOADING\n",
    "df = pd.read_pickle(\"/data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-207-ic521-iq4-pcTrue.pickle.bz2\")\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for conversation in conversations:\n",
    "#    questions = [turn['question'] for turn in conversation['questions']]\n",
    "#    print(questions)\n",
    "#    golden_answers = [graphqa.wikidata_url_to_wikidata_id(turn['answer']) for turn in conversation['questions']]\n",
    "#    print(golden_answers)\n",
    "#    \n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#banning_str = False #[[\"ř\",\"r\"]]\n",
    "#conversations_len = len(conversations)\n",
    "#\n",
    "#last_i = 0\n",
    "#for i, conversation in enumerate(conversations):\n",
    "#    if i >= last_i:\n",
    "#        print(\"\\n-->\",str(i)+\"/\"+str(conversations_len), \"New conversation\")\n",
    "#        questions = [turn['question'] for turn in conversation['questions']]\n",
    "#        questions_len = len(questions)\n",
    "#        for i_q, question in enumerate(questions):\n",
    "#            print(str(i_q)+\"/\"+str(questions_len),question)\n",
    "#            print(tmqa.get_nlp(question,autocorrect=True,banning_str=banning_str))\n",
    "#    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rr(results, answer):\n",
    "    if answer in results:\n",
    "        ans_position = results.index(answer)+1\n",
    "        if ans_position == 1:\n",
    "            return 1.0\n",
    "        return float(ans_position/len(results))\n",
    "    else: return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is  2020-02-06 17:27:22.746241\n",
      "\t>>> Processing 523/2240 -> 1/5 -> Convex=False: (Q310052) What is the name of the lead signer of The Clash?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex 1976-01-01T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What is the name of the lead signer of The Clash?\n",
      "--> Auto correcting question in progress...\n",
      "WARNING:tensorflow:From /data/users/romain.claret/miniconda3/envs/qa/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "-> Auto corrected q_nlp: What is the name of the lead signer of The Clash \n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (The Clash, ['Q125603', 'Q775208']), (Clash, ['Q425178', 'Q11914000']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [the lead signer, is the name of the lead signer of The, The Lead Signer, lead signer, the lead Signer])\n",
      "-> q_themes_enhanced: [('lead', ['Q1318488']), ('The Lead', ['Q28419598']), ('Lead', ['Q5958170']), ('Signer', ['Q1694586'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: lead\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (lead, []), (signer, ['P1891'])]\n",
      "-> q_predicates \tRunning time is 19.81s\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'The Clash', 'Clash', 'The Name', 'name', 'lead', 'The Lead', 'Lead', 'Signer']\n",
      "q_focused_parts: [(lead, ['Q16948621', 'Q8776414', 'Q1318488', 'Q1765879'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.88s\n",
      "-->  1910 nodes and 1904 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 139 nodes and 134 edges\n",
      "-> predicates_dict: {'P2868': 1, 'P279': 4, 'P1552': 1, 'P1013': 3, 'P155': 1, 'P156': 3, 'P527': 5, 'P800': 1, 'P856': 1, 'P407': 2, 'P585': 1, 'P166': 1, 'P737': 1, 'P31': 884, 'P364': 1, 'P571': 1, 'P569': 1, 'P582': 1, 'P579': 2, 'P813': 1, 'P973': 1, 'P1709': 1, 'P1476': 2, 'P577': 3, 'P580': 1, 'P495': 2, 'P361': 1, 'P910': 1, 'P360': 3, 'P1433': 1, 'P264': 1, 'P27': 1, 'P1113': 1, 'P690': 1, 'P1545': 2, 'P4908': 1, 'P175': 1, 'P179': 1, 'P373': 1, 'P161': 4, 'P106': 1, 'P21': 1, 'P58': 1, 'P50': 2, 'P136': 1}\n",
      "-> paths_keywords: (['lead', 'name', 'signer', 'the clash', 'clash', 'the lead signer', 'the name', 'lead paragraph', 'leading actor'], {'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'signatory': [signatory, ['P1891']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 236\n",
      "->Computing possible paths \tRunning time is 63.55s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 210\n",
      "->\tRunning time is 3.74s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q25379', 1.3197466228123251], ['Q21191270', 1.1909836175282114], ['Q5185279', 1.1185762386870104], ['Q1860', 1.0552586201154057], ['Q5741069', 0.7490879463937604], ['Q482994', 0.6303174632790177], ['Q5958170', 0.594687678201609], ['Q11424', 0.594687678201609], ['Q25164', -0.10892906268257152]]\n",
      "->Computing hypothesises \tRunning time is 67.73s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 5.93s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q25379', 'P31', 'Q25217641', 'P407', 'Q25164']\n",
      "->\tTotal Running time is 218.55s\n",
      "\n",
      "df_graphqa Q25379\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "207             522    0       False   \n",
      "\n",
      "                                              question   answer domain  \\\n",
      "207  What is the name of the lead signer of The Clash?  Q310052  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  ...  convex_time  convex_rr  \\\n",
      "207   False          0.51         0.0    False  ...         1.69        0.0   \n",
      "\n",
      "    graphqa  graphqa_time  graphqa_top2 graphqa_top3  graphqa_top4  \\\n",
      "207  Q25379        218.78         False        False         False   \n",
      "\n",
      "    graphqa_top5 graphqa_topall graphqa_rr  \n",
      "207        False          False        0.0  \n",
      "\n",
      "[1 rows x 23 columns]\n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-208-ic522-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 17:31:13.288066\n",
      "\t>>> Processing 523/2240 -> 2/5 -> Convex=False: (Q3640) Where is he from?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Where is he from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where is he from \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Where is The Clash from\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31'])]\n",
      "-> q_predicates \tRunning time is 2.09s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(1976 - 01 01T00:00:00Z, ['1976-01-01T00:00:00Z'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['1976 - 01 01T00:00:00Z']\n",
      "---> Meaningful keywords enhanced by previous context: ['1976 - 01 01T00:00:00Z', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [1976 - 01 01T00:00:00Z, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(The Clash, ['Q56274328', 'Q55642270', 'Q125603'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.35s\n",
      "-->  17 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 16 edges\n",
      "-> predicates_dict: {'P571': 1, 'P31': 2, 'P495': 1, 'P585': 1, 'P166': 1, 'P737': 1, 'P527': 3, 'P1113': 1}\n",
      "-> paths_keywords: (['the clash', 'clash'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 132\n",
      "->Computing possible paths \tRunning time is 64.16s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 58\n",
      "->\tRunning time is 3.4s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Where is he from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where is he from \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Where date of foundation or creation The Clash from\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31'])]\n",
      "-> q_predicates \tRunning time is 2.1s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(1976 - 01 01T00:00:00Z, ['1976-01-01T00:00:00Z'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['1976 - 01 01T00:00:00Z']\n",
      "---> Meaningful keywords enhanced by previous context: ['1976 - 01 01T00:00:00Z', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [1976 - 01 01T00:00:00Z, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(The Clash, ['Q56274328', 'Q55642270', 'Q125603'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.51s\n",
      "-->  17 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 16 edges\n",
      "-> predicates_dict: {'P571': 1, 'P31': 2, 'P495': 1, 'P585': 1, 'P166': 1, 'P737': 1, 'P527': 3, 'P1113': 1}\n",
      "-> paths_keywords: (['the clash', 'date', 'clash'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 73.41s\n",
      "-> Filtering paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(paths_nodes_filtered): 58\n",
      "->\tRunning time is 3.38s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 94.98s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Where is he from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where is he from \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Where is The Name from\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31'])]\n",
      "-> q_predicates \tRunning time is 2.2s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(Play, ['Q25379'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Play', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [Play, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(Play, ['Q1427408', 'Q1079716', 'Q1064897']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(Play, ['Q1427408', 'Q1079716', 'Q1064897']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.49s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 14, 'P800': 1, 'P155': 2, 'P585': 2, 'P1411': 2, 'P1476': 1, 'P27': 1, 'P1191': 1, 'P156': 1, 'P495': 1, 'P1433': 1, 'P569': 1, 'P1394': 2, 'P136': 1, 'P220': 2, 'P21': 1}\n",
      "-> paths_keywords: (['play', 'the name', 'nynorsk', 'name'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 115.12s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.69s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.04s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Where is he from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where is he from \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Where instance of The Name from\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31'])]\n",
      "-> q_predicates \tRunning time is 2.15s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(Play, ['Q25379'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Play', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [Play, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(Play, ['Q1427408', 'Q1079716', 'Q1064897']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(Play, ['Q1427408', 'Q1079716', 'Q1064897']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.8s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 14, 'P800': 1, 'P155': 2, 'P585': 2, 'P1411': 2, 'P1476': 1, 'P27': 1, 'P1191': 1, 'P156': 1, 'P495': 1, 'P1433': 1, 'P569': 1, 'P1394': 2, 'P136': 1, 'P220': 2, 'P21': 1}\n",
      "-> paths_keywords: (['play', 'the name', 'nynorsk', 'instance', 'name'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 124.09s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.46s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 153.34s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex           question answer domain qanswer  \\\n",
      "208             522    1       False  Where is he from?  Q3640  music   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "208          0.39         0.0    False           0.23          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "208       177.54        0.0   False        294.49        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "208        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-209-ic522-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 523/2240 -> 2/5 -> Convex=True: (Q3640) Where is he from?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q10741085\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1995-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex           question answer domain qanswer  \\\n",
      "209             522    1        True  Where is he from?  Q3640  music   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr     convex  \\\n",
      "209          0.37         0.0    False           0.21          0.0  Q10741085   \n",
      "\n",
      "     convex_time  convex_rr               graphqa  graphqa_time graphqa_top2  \\\n",
      "209         0.18        0.0  1995-01-01T00:00:00Z           0.2        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "209        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-210-ic522-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 17:39:06.931617\n",
      "\t>>> Processing 523/2240 -> 3/5 -> Convex=False: (Q310052) What was his real name?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What was his real name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was his real name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was The Clash real name\n",
      "-> q_themes: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his real name, His Real Name, -PRON- real name, his real Name])\n",
      "-> q_themes_enhanced: [('real name', ['P1477']), ('real', ['Q356550']), ('Real', ['Q1008953'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: real\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "-> q_predicates \tRunning time is 4.82s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "----> q_themes in context: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his, His, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['name', 'Name', 'real name', 'real', 'Real']\n",
      "---> Meaningful keywords enhanced by previous context: ['name', 'Name', 'real name', 'real', 'Real', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [name, Name, real name, real, Real, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 24.96s\n",
      "-->  23 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 22 edges\n",
      "-> predicates_dict: {'P571': 1, 'P155': 2, 'P156': 2, 'P150': 1, 'P585': 1, 'P166': 1, 'P407': 1, 'P856': 1, 'P577': 2, 'P31': 7, 'P131': 1, 'P495': 2, 'P1545': 2, 'P4908': 1, 'P179': 1, 'P737': 1, 'P527': 3, 'P361': 1, 'P910': 1, 'P1476': 1, 'P264': 1, 'P1113': 1}\n",
      "-> paths_keywords: (['name', 'the clash'], {'date of foundation or creation': [date of foundation or creation, ['P571']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'valid in place': [valid in place, ['P3005']], 'real name': [birth name, ['P1477']], 'name': [name, ['P2561']], 'birth name': [birth name, ['P1477']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 124.02s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.63s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What was his real name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was his real name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What The Clash real name\n",
      "-> q_themes: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his real name, His Real Name, -PRON- real name, his real Name])\n",
      "-> q_themes_enhanced: [('real name', ['P1477']), ('real', ['Q356550']), ('Real', ['Q1008953'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: real\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "-> q_predicates \tRunning time is 4.64s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "----> q_themes in context: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his, His, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['name', 'Name', 'real name', 'real', 'Real']\n",
      "---> Meaningful keywords enhanced by previous context: ['name', 'Name', 'real name', 'real', 'Real', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [name, Name, real name, real, Real, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.83s\n",
      "-->  23 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 22 edges\n",
      "-> predicates_dict: {'P571': 1, 'P155': 2, 'P156': 2, 'P150': 1, 'P585': 1, 'P166': 1, 'P407': 1, 'P856': 1, 'P577': 2, 'P31': 7, 'P131': 1, 'P495': 2, 'P1545': 2, 'P4908': 1, 'P179': 1, 'P737': 1, 'P527': 3, 'P361': 1, 'P910': 1, 'P1476': 1, 'P264': 1, 'P1113': 1}\n",
      "-> paths_keywords: (['name', 'the clash'], {'date of foundation or creation': [date of foundation or creation, ['P571']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'valid in place': [valid in place, ['P3005']], 'real name': [birth name, ['P1477']], 'name': [name, ['P2561']], 'birth name': [birth name, ['P1477']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 64.27s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 92\n",
      "->\tRunning time is 3.39s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 99.49s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What was his real name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was his real name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was The Name real name\n",
      "-> q_themes: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his real name, His Real Name, -PRON- real name, his real Name])\n",
      "-> q_themes_enhanced: [('real name', ['P1477']), ('real', ['Q356550']), ('Real', ['Q1008953'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: real\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "-> q_predicates \tRunning time is 4.38s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "----> q_themes in context: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['name', 'Name', 'real name', 'real', 'Real']\n",
      "---> Meaningful keywords enhanced by previous context: ['name', 'Name', 'real name', 'real', 'Real', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [name, Name, real name, real, Real, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.32s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 50, 'P31': 19, 'P155': 4, 'P156': 3, 'P150': 1, 'P800': 1, 'P585': 2, 'P1411': 2, 'P569': 1, 'P37': 2, 'P131': 1, 'P361': 3, 'P179': 1, 'P1545': 2, 'P4908': 1, 'P1476': 4, 'P27': 1, 'P1191': 1, 'P495': 2, 'P577': 5, 'P1433': 1, 'P264': 1, 'P1394': 2, 'P136': 1, 'P106': 1, 'P1018': 1, 'P220': 2, 'P21': 1}\n",
      "-> paths_keywords: (['name', 'the name', 'nynorsk', 'play'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'valid in place': [valid in place, ['P3005']], 'real name': [birth name, ['P1477']], 'name': [name, ['P2561']], 'birth name': [birth name, ['P1477']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 121.5s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.4s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.6s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What was his real name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was his real name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What The Name real name\n",
      "-> q_themes: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his real name, His Real Name, -PRON- real name, his real Name])\n",
      "-> q_themes_enhanced: [('real name', ['P1477']), ('real', ['Q356550']), ('Real', ['Q1008953'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: real\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "-> q_predicates \tRunning time is 4.57s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (name, ['P735', 'P1448']), (real, ['P3005'])]\n",
      "----> q_themes in context: ([(name, ['Q82799', 'P2561']), (Name, ['Q11236330', 'Q13873817'])], [his, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['name', 'Name', 'real name', 'real', 'Real']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['name', 'Name', 'real name', 'real', 'Real', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [name, Name, real name, real, Real, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(name, ['P2561']), (Name, ['Q11236330', 'Q13873817']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 26.61s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 50, 'P31': 19, 'P155': 4, 'P156': 3, 'P150': 1, 'P800': 1, 'P585': 2, 'P1411': 2, 'P569': 1, 'P37': 2, 'P131': 1, 'P361': 3, 'P1545': 2, 'P179': 1, 'P4908': 1, 'P1476': 4, 'P27': 1, 'P1191': 1, 'P495': 2, 'P577': 5, 'P1433': 1, 'P264': 1, 'P1394': 2, 'P1018': 1, 'P136': 1, 'P106': 1, 'P220': 2, 'P21': 1}\n",
      "-> paths_keywords: (['name', 'the name', 'nynorsk', 'play'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'valid in place': [valid in place, ['P3005']], 'real name': [birth name, ['P1477']], 'name': [name, ['P2561']], 'birth name': [birth name, ['P1477']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 122.02s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.39s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.81s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 163.55s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                 question   answer domain  \\\n",
      "210             522    2       False  What was his real name?  Q310052  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "210   False          0.63         0.0    False           0.48          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "210  False       257.79        0.0   False        328.73        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "210        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-211-ic522-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 523/2240 -> 3/5 -> Convex=True: (Q310052) What was his real name?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q125603\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Namnet@nn\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                 question   answer domain  \\\n",
      "211             522    2        True  What was his real name?  Q310052  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "211   False          0.63         0.0    False           0.52          0.0   \n",
      "\n",
      "      convex  convex_time  convex_rr    graphqa  graphqa_time graphqa_top2  \\\n",
      "211  Q125603         0.15        0.0  Namnet@nn          0.09        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "211        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-212-ic522-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 17:48:56.014663\n",
      "\t>>> Processing 523/2240 -> 4/5 -> Convex=False: (Q775208) Their debut album was called what?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer 3595f\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Their debut album was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Their debut album was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: The Clash debut album was called what\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their debut album, Their Debut Album, their debut album, their Debut Album])\n",
      "-> q_themes_enhanced: [('debut', ['Q1181693']), ('album', ['Q10666342'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 6.8s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (called, ['P474'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their, their])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'What', 'Debut Album', 'debut', 'album']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'What', 'Debut Album', 'debut', 'album', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [what, What, Debut Album, debut, album, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.21s\n",
      "-->  19 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 18 edges\n",
      "-> predicates_dict: {'P571': 2, 'P577': 1, 'P31': 102, 'P518': 1, 'P186': 1, 'P495': 2, 'P585': 1, 'P166': 1, 'P737': 1, 'P527': 4, 'P1552': 1, 'P279': 3, 'P195': 1, 'P217': 1, 'P276': 1, 'P2670': 1, 'P793': 2, 'P361': 1, 'P1113': 1}\n",
      "-> paths_keywords: (['what', 'debut album', 'the clash'], {'date of foundation or creation': [date of foundation or creation, ['P571']], 'instance of': [instance of, ['P31']], 'country calling code': [country calling code, ['P474']]}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 57.22s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 74\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Their debut album was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Their debut album was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: The Clash debut album called what\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their debut album, Their Debut Album, their debut album, their Debut Album])\n",
      "-> q_themes_enhanced: [('debut', ['Q1181693']), ('album', ['Q10666342'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: album\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474']), (debut, ['P2318']), (album, [])]\n",
      "-> q_predicates \tRunning time is 6.81s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (called, ['P474']), (debut, ['P2318']), (album, [])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their, their])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'What', 'Debut Album', 'debut', 'album']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'What', 'Debut Album', 'debut', 'album', 'The Clash', '1976-01-01T00:00:00Z']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [what, What, Debut Album, debut, album, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.26s\n",
      "-->  31 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 31 nodes and 30 edges\n",
      "-> predicates_dict: {'P571': 2, 'P31': 102, 'P361': 1, 'P577': 1, 'P518': 1, 'P186': 1, 'P495': 2, 'P585': 1, 'P166': 1, 'P737': 1, 'P527': 4, 'P1552': 1, 'P279': 3, 'P195': 1, 'P276': 1, 'P2670': 1, 'P358': 1, 'P217': 1, 'P793': 2, 'P264': 2, 'P175': 4, 'P136': 1, 'P1113': 1, 'P170': 1}\n",
      "-> paths_keywords: (['what', 'debut album', 'the clash'], {'date of foundation or creation': [date of foundation or creation, ['P571']], 'instance of': [instance of, ['P31']], 'country calling code': [country calling code, ['P474']], 'debut participant': [debut participant, ['P2318']]}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 132\n",
      "->Computing possible paths \tRunning time is 46.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 92\n",
      "->\tRunning time is 3.66s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 82.5s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Their debut album was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Their debut album was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: The Name debut album was called what\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their debut album, Their Debut Album, their debut album, their Debut Album])\n",
      "-> q_themes_enhanced: [('debut', ['Q1181693']), ('album', ['Q10666342'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 6.75s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (called, ['P474'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their, their])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'What', 'Debut Album', 'debut', 'album']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'What', 'Debut Album', 'debut', 'album', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [what, What, Debut Album, debut, album, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 25.18s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 114, 'P571': 1, 'P800': 1, 'P2670': 1, 'P518': 1, 'P186': 1, 'P361': 1, 'P1394': 2, 'P1627': 1, 'P155': 2, 'P585': 2, 'P1411': 2, 'P1476': 1, 'P27': 1, 'P495': 2, 'P1552': 1, 'P527': 1, 'P279': 3, 'P195': 1, 'P217': 1, 'P276': 1, 'P1191': 1, 'P156': 1, 'P793': 2, 'P1433': 1, 'P569': 1, 'P220': 2, 'P264': 1, 'P136': 1, 'P373': 1, 'P21': 1, 'P106': 1}\n",
      "-> paths_keywords: (['what', 'debut album', 'the name', 'nynorsk', 'play'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'country calling code': [country calling code, ['P474']]}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 127.06s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.43s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.24s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Their debut album was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Their debut album was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: The Name debut album called what\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their debut album, Their Debut Album, their debut album, their Debut Album])\n",
      "-> q_themes_enhanced: [('debut', ['Q1181693']), ('album', ['Q10666342'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: album\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474']), (debut, ['P2318']), (album, [])]\n",
      "-> q_predicates \tRunning time is 6.79s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (called, ['P474']), (debut, ['P2318']), (album, [])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (Debut Album, ['Q17001551'])], [Their, their])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'What', 'Debut Album', 'debut', 'album']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'What', 'Debut Album', 'debut', 'album', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [what, What, Debut Album, debut, album, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(What, ['Q22073920', 'Q28036789']), (Debut Album, ['Q17001551']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.28s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 114, 'P361': 1, 'P571': 1, 'P800': 1, 'P2670': 1, 'P518': 1, 'P186': 1, 'P1394': 2, 'P1627': 1, 'P155': 2, 'P585': 2, 'P1411': 2, 'P1476': 2, 'P27': 1, 'P495': 2, 'P1552': 1, 'P527': 2, 'P279': 3, 'P195': 1, 'P217': 1, 'P276': 1, 'P1191': 1, 'P156': 1, 'P793': 2, 'P264': 5, 'P106': 1, 'P175': 3, 'P1433': 1, 'P136': 2, 'P569': 1, 'P220': 2, 'P577': 2, 'P373': 1, 'P50': 1, 'P1412': 2, 'P1705': 1, 'P21': 1, 'P170': 1}\n",
      "-> paths_keywords: (['what', 'debut album', 'the name', 'nynorsk', 'play'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'country calling code': [country calling code, ['P474']], 'debut participant': [debut participant, ['P2318']]}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 126.76s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.7s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.97s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 174.12s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                            question  \\\n",
      "212             522    3       False  Their debut album was called what?   \n",
      "\n",
      "      answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "212  Q775208  music   3595f          0.35         0.0    False           1.44   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "212          0.0  False       171.99        0.0   False        340.49   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "212        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "212         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-213-ic522-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 523/2240 -> 4/5 -> Convex=True: (Q775208) Their debut album was called what?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 3595f\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q16155851\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q25217641\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                            question  \\\n",
      "213             522    3        True  Their debut album was called what?   \n",
      "\n",
      "      answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "213  Q775208  music   3595f           0.0         0.0    False           1.49   \n",
      "\n",
      "     platypus_rr     convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "213          0.0  Q16155851         0.21        0.0  Q25217641          0.19   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "213        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "213         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-214-ic522-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 17:57:32.222486\n",
      "\t>>> Processing 523/2240 -> 5/5 -> Convex=False: (4) How many people were originally in the band?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How many people were originally in the band\n",
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.39s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', '3595f']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, 3595f]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.89s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How many people originally in the band\n",
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.15s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', '3595f']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, 3595f]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.08s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How many people were originally in the band\n",
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.53s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.26s\n",
      "-->  23 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 22 edges\n",
      "-> predicates_dict: {'P571': 1, 'P19': 5, 'P31': 5, 'P495': 2, 'P580': 2, 'P582': 1, 'P6': 2, 'P1480': 1, 'P1810': 2, 'P4900': 1, 'P737': 1, 'P1013': 2, 'P459': 4, 'P585': 3, 'P1082': 2, 'P166': 1, 'P527': 3, 'P421': 4, 'P131': 2, 'P1113': 1, 'P740': 1, 'P17': 2, 'P910': 1, 'P1383': 1, 'P36': 1, 'P856': 1}\n",
      "-> paths_keywords: (['band', 'the band', 'the clash', 'were'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 132\n",
      "->Computing possible paths \tRunning time is 48.08s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 92\n",
      "->\tRunning time is 3.51s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How many people originally in the band\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.16s\n",
      "--> Predicates enhanced by previous context: [(date of foundation or creation, ['P571']), (be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', 'The Clash', '1976-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, The Clash, 1976 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Clash, ['Q56274328', 'Q55642270', 'Q125603']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.35s\n",
      "-->  23 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 22 edges\n",
      "-> predicates_dict: {'P571': 1, 'P19': 5, 'P31': 5, 'P495': 2, 'P580': 2, 'P582': 1, 'P6': 2, 'P1480': 1, 'P1810': 2, 'P4900': 1, 'P737': 1, 'P1013': 2, 'P459': 4, 'P585': 3, 'P1082': 2, 'P166': 1, 'P527': 3, 'P421': 4, 'P131': 2, 'P1113': 1, 'P740': 1, 'P17': 2, 'P910': 1, 'P1383': 1, 'P36': 1, 'P856': 1}\n",
      "-> paths_keywords: (['band', 'the band', 'the clash', 'people'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 132\n",
      "->Computing possible paths \tRunning time is 52.12s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 92\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 83.33s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How many people were originally in the band\n",
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.53s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 25.81s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 17, 'P800': 1, 'P131': 2, 'P155': 2, 'P1480': 1, 'P1810': 2, 'P4900': 1, 'P1013': 2, 'P459': 4, 'P585': 4, 'P1082': 2, 'P1411': 2, 'P264': 1, 'P1476': 1, 'P27': 1, 'P495': 2, 'P421': 4, 'P1191': 1, 'P156': 1, 'P580': 2, 'P582': 1, 'P6': 2, 'P19': 4, 'P1433': 1, 'P569': 1, 'P21': 1, 'P17': 2, 'P1018': 1, 'P1394': 2, 'P361': 1, 'P279': 1, 'P136': 2, 'P1383': 1, 'P36': 1, 'P856': 1, 'P220': 2}\n",
      "-> paths_keywords: (['band', 'the band', 'the name', 'nynorsk', 'play', 'were'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 137.63s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.64s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.6s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: How many people were originally in the band?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How many people were originally in the band \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How many people originally in the band\n",
      "-> q_themes: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: many\n",
      "behold: get_most_similar started with: band\n",
      "-> q_predicates: [(be, ['P31']), (many, []), (people, ['P172', 'P1315']), (band, [])]\n",
      "-> q_predicates \tRunning time is 6.02s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (many, []), (people, ['P172', 'P1315'])]\n",
      "----> q_themes in context: ([(the band, ['Q600344', 'Q926142']), (band, ['Q215380', 'Q29289832']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the band', 'band', 'Band', 'The Band']\n",
      "---> Meaningful keywords enhanced by previous context: ['the band', 'band', 'Band', 'The Band', 'The Name', 'Nynorsk', 'Play']\n",
      "meaningful_names_no_previous_answer [the band, band, Band, The Band, The Name, Nynorsk, Play]\n",
      "----> Meaningful keywords casted as theme ([(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897'])], [])\n",
      "q_focused_parts: [(band, ['Q29289832', 'Q215380']), (Band, ['Q12080772', 'Q1096385']), (The Band, ['Q1681495']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Nynorsk, ['Q25164']), (Play, ['Q1427408', 'Q1079716', 'Q1064897']), (the band, ['Q600344', 'Q926142'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.23s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 49, 'P31': 17, 'P800': 1, 'P131': 2, 'P155': 2, 'P1480': 1, 'P1810': 2, 'P4900': 1, 'P1013': 2, 'P459': 4, 'P585': 4, 'P1082': 2, 'P1411': 2, 'P264': 1, 'P1476': 1, 'P27': 1, 'P495': 2, 'P421': 4, 'P1191': 1, 'P156': 1, 'P580': 2, 'P582': 1, 'P6': 2, 'P19': 4, 'P1433': 1, 'P569': 1, 'P21': 1, 'P17': 2, 'P1018': 1, 'P1394': 2, 'P361': 1, 'P279': 1, 'P136': 2, 'P1383': 1, 'P36': 1, 'P856': 1, 'P220': 2}\n",
      "-> paths_keywords: (['band', 'the band', 'the name', 'nynorsk', 'play', 'people'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 132.22s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.47s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.85s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 171.52s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex  \\\n",
      "214             522    4       False   \n",
      "\n",
      "                                         question answer domain qanswer  \\\n",
      "214  How many people were originally in the band?      4  music   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "214         41.98         0.0    False            6.6          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "214       161.37        0.0   False        349.49        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "214        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-215-ic522-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 523/2240 -> 5/5 -> Convex=True: (4) How many people were originally in the band?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 3595f\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q5741069\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q443868\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "215             522    4        True   \n",
      "\n",
      "                                         question answer domain qanswer  \\\n",
      "215  How many people were originally in the band?      4  music   3595f   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr    convex  \\\n",
      "215           0.0         0.0    False           5.91          0.0  Q5741069   \n",
      "\n",
      "     convex_time  convex_rr  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "215         0.26        0.0  Q443868          0.21        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "215        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-216-ic522-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:06:58.092693\n",
      "\t>>> Processing 524/2240 -> 1/5 -> Convex=False: (Q145) What country are they from?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex 26\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What country are they from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What country are they from \n",
      "-> q_themes: ([(country, ['Q6256', 'P17']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (country, ['P17', 'P3005'])]\n",
      "-> q_predicates \tRunning time is 4.03s\n",
      "--> Potential meaningful keywords for the sentence: ['country', 'Country']\n",
      "q_focused_parts: [(country, ['Q83440', 'P3005', 'P17', 'Q6256'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.86s\n",
      "-->  458 nodes and 458 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 458 nodes and 458 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 458 nodes or 458 edges was above the limit of 350\n",
      "-> predicates_dict: {'P17': 1, 'P1282': 1, 'P1963': 2, 'P495': 1, 'P131': 1, 'P291': 1, 'P577': 1, 'P2453': 1, 'P805': 1, 'P1411': 1, 'P364': 1, 'P31': 207, 'P813': 1, 'P973': 1, 'P1709': 1, 'P2452': 2, 'P734': 1, 'P106': 1}\n",
      "-> paths_keywords: (['country', 'are', 'country music'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 4152\n",
      "->Computing possible paths \tRunning time is 31.87s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 4026\n",
      "->\tRunning time is 5.0s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q258', 26.678714661514114], ['Q145', 12.593664169565244], ['Q1008', 12.562891636446281], ['Q16', 12.522763735964807], ['Q213', 12.512927868612815], ['Q148', 12.510945083987211], ['Q183', 12.507543614361486], ['Q142', 12.487159090695776], ['Q17', 12.48683703435693], ['Q159', 12.481189568220103], ['Q1033', 12.468278603823899], ['Q155', 12.460850515701914], ['Q114', 12.459346914520781], ['Q1006', 12.443349567295598], ['Q117', 12.44287842774289], ['Q20', 12.441584555001796], ['Q1028', 12.430063295601324], ['Q212', 12.429974691944656], ['Q115', 12.428503869646358], ['Q218', 12.428177144357933], ['Q1045', 12.425124782585067], ['Q189', 12.423649972496785], ['Q1011', 12.414388109538429], ['Q1049', 12.414270285338546], ['Q1036', 12.413908798050223], ['Q1016', 12.40910687674527], ['Q219', 12.405130116763663], ['Q222', 12.399985353146171], ['Q1044', 12.398787638728336], ['Q1019', 12.391245927941355], ['Q221', 12.39107466022208], ['Q1041', 12.385089815035476], ['Q215', 12.384556823519427], ['Q214', 12.382224986907703], ['Q1037', 12.380559786247758], ['Q191', 12.379286728075625], ['Q1009', 12.37182013811523], ['Q1029', 12.371441644450142], ['Q1030', 12.369097354185522], ['Q184', 12.365366044225581], ['Q211', 12.364341532360237], ['Q1027', 12.363247003879016], ['Q1005', 12.355799823718938], ['Q1020', 12.354970125543035], ['Q1014', 12.35164762910282], ['Q217', 12.35146716660936], ['Q1007', 12.349391427899638], ['Q1042', 12.335848056519822], ['Q1050', 12.331784773952498], ['Q1025', 12.320610044672966], ['Q1013', 12.318985670023757], ['Q1000', 12.301711209434776], ['Q30', 9.755339331198902], ['Q22302160', 1.8961492143200795], ['Q219060', 1.8517217293299684], ['Q1032', 0.31592329546124703], ['Q1039', -0.09230417665037267]]\n",
      "->Computing hypothesises \tRunning time is 59.29s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 177\n",
      "->\tRunning time is 216.23s\n",
      "--> len(cleared_golden_paths): 117\n",
      "---> First path: ['Q258', 'P17', 'Q6256', 'P31', 'Q219060']\n",
      "->\tTotal Running time is 403.75s\n",
      "\n",
      "df_graphqa Q258\n",
      "df_graphqa_rr 0.03508771929824561\n",
      "\n",
      "PARTIAL_CORRECT 524 - 1 -> graphqa in answers ['Q258', 'Q145', 'Q1008', 'Q16', 'Q213', 'Q148', 'Q183', 'Q142', 'Q17', 'Q159', 'Q1033', 'Q155', 'Q114', 'Q1006', 'Q117', 'Q20', 'Q1028', 'Q212', 'Q115', 'Q218', 'Q1045', 'Q189', 'Q1011', 'Q1049', 'Q1036', 'Q1016', 'Q219', 'Q222', 'Q1044', 'Q1019', 'Q221', 'Q1041', 'Q215', 'Q214', 'Q1037', 'Q191', 'Q1009', 'Q1029', 'Q1030', 'Q184', 'Q211', 'Q1027', 'Q1005', 'Q1020', 'Q1014', 'Q217', 'Q1007', 'Q1042', 'Q1050', 'Q1025', 'Q1013', 'Q1000', 'Q30', 'Q22302160', 'Q219060', 'Q1032', 'Q1039']\n",
      "    conversation_id turn plus_convex                     question answer  \\\n",
      "216             523    0       False  What country are they from?   Q145   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "216  soccer   False          0.33         0.0    False           0.18   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "216          0.0     26         0.59        0.0    Q258         404.0   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "216         True         True         True         True           True   \n",
      "\n",
      "     graphqa_rr  \n",
      "216    0.035088  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-217-ic523-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:13:43.220816\n",
      "\t>>> Processing 524/2240 -> 2/5 -> Convex=False: (Q9448) What's the name of their league?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What's the name of their league?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of their league \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of What a Country league\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their league, Their League, -PRON- league, their League])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 6.55s\n",
      "--> Predicates enhanced by previous context: [(number of episodes, ['P1113']), (be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their, Their, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name', 'What a Country!', '26']\n",
      "meaningful_names_no_previous_answer [the name, what, league, What, League, The Name, name, What a Country, 26]\n",
      "----> Meaningful keywords casted as theme ([(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (26, ['Q26300452', 'Q17219446', 'Q23774'])], [])\n",
      "q_focused_parts: [(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (26, ['Q26300452', 'Q17219446', 'Q23774']), (the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 15.24s\n",
      "-->  13 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 12 edges\n",
      "-> predicates_dict: {'P1113': 1, 'P1013': 2, 'P800': 1, 'P2437': 1, 'P734': 1, 'P31': 12, 'P407': 3, 'P361': 1, 'P585': 1, 'P518': 1, 'P186': 1, 'P527': 1, 'P571': 1, 'P131': 1, 'P569': 1, 'P1216': 1, 'P1476': 2, 'P495': 2, 'P1923': 1, 'P577': 2, 'P1435': 1, 'P1705': 1, 'P1433': 1, 'P264': 1, 'P27': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P17': 1, 'P106': 1, 'P175': 1, 'P282': 1, 'P155': 1, 'P21': 1}\n",
      "-> paths_keywords: (['league', 'what', 'the name', 'name', '26'], {}, [What, What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 156\n",
      "->Computing possible paths \tRunning time is 90.07s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 24\n",
      "->\tRunning time is 3.58s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What's the name of their league?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of their league \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What number of episodes the name of What a Country league\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their league, Their League, -PRON- league, their League])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 7.68s\n",
      "--> Predicates enhanced by previous context: [(number of episodes, ['P1113']), (be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their, Their, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name', 'What a Country!', '26']\n",
      "meaningful_names_no_previous_answer [the name, what, league, What, League, The Name, name, What a Country, 26]\n",
      "----> Meaningful keywords casted as theme ([(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (26, ['Q26300452', 'Q17219446', 'Q23774'])], [])\n",
      "q_focused_parts: [(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (26, ['Q26300452', 'Q17219446', 'Q23774']), (the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 15.92s\n",
      "-->  13 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 12 edges\n",
      "-> predicates_dict: {'P1113': 1, 'P1013': 2, 'P800': 1, 'P2437': 1, 'P734': 1, 'P31': 12, 'P407': 3, 'P361': 1, 'P585': 1, 'P518': 1, 'P186': 1, 'P527': 1, 'P131': 1, 'P569': 1, 'P571': 1, 'P1216': 1, 'P1476': 2, 'P495': 2, 'P1923': 1, 'P577': 2, 'P1435': 1, 'P1705': 1, 'P1433': 1, 'P27': 1, 'P195': 1, 'P264': 1, 'P217': 1, 'P276': 1, 'P17': 1, 'P106': 1, 'P282': 1, 'P175': 1, 'P21': 1, 'P155': 1}\n",
      "-> paths_keywords: (['league', 'what', 'the name', 'name', '26', 'number'], {}, [What, What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 156\n",
      "->Computing possible paths \tRunning time is 95.94s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 26\n",
      "->\tRunning time is 3.72s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 127.45s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What's the name of their league?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of their league \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of country league\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their league, Their League, -PRON- league, their League])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 7.05s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (be, ['P31']), (league, ['P118']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789']), (league, ['Q13530508', 'P118']), (What, ['Q22073920']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [their, Their, -PRON-])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'what', 'league', 'What', 'League', 'The Name', 'name', 'country', 'South Africa', 'country', 'State of Palestine']\n",
      "meaningful_names_no_previous_answer [the name, what, league, What, League, The Name, name, country, South Africa, country, State of Palestine]\n",
      "----> Meaningful keywords casted as theme ([(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256']), (State of Palestine, ['Q219060'])], [])\n",
      "q_focused_parts: [(league, ['P118', 'Q13530508']), (What, ['Q22073920', 'Q28036789']), (League, ['Q12770238', 'Q37436664']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256']), (State of Palestine, ['Q219060']), (the name, ['Q50929476', 'Q25217641']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 105.75s\n",
      "-->  16 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 16 nodes and 18 edges\n",
      "-> predicates_dict: {'P17': 712, 'P1963': 8, 'P31': 290, 'P1013': 2, 'P1282': 1, 'P800': 1, 'P1813': 1, 'P734': 1, 'P495': 1, 'P27': 1, 'P407': 3, 'P898': 1, 'P580': 1, 'P463': 2, 'P37': 1, 'P805': 8, 'P530': 8, 'P138': 2, 'P518': 1, 'P186': 1, 'P527': 4, 'P361': 1, 'P571': 1, 'P131': 1, 'P569': 1, 'P1476': 3, 'P577': 3, 'P813': 1, 'P973': 1, 'P1709': 1, 'P921': 1, 'P1313': 1, 'P1906': 1, 'P360': 3, 'P2341': 1, 'P585': 3, 'P1081': 3, 'P1705': 1, 'P1433': 1, 'P195': 2, 'P2061': 1, 'P242': 1, 'P1532': 3, 'P217': 1, 'P276': 1, 'P2452': 2, 'P2888': 1, 'P106': 1, 'P282': 1, 'P21': 1}\n",
      "-> paths_keywords: (['league', 'what', 'the name', 'name', 'country', 'south africa', 'state of palestine'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 168\n",
      "->Computing possible paths \tRunning time is 38.67s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 120\n",
      "->\tRunning time is 3.7s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7127349', 2.977715626330542]]\n",
      "->Computing hypothesises \tRunning time is 39.97s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 5\n",
      "->\tRunning time is 4.52s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q7127349', 'P17', 'Q219060', 'P31', 'Q6256', 'P1282', 'Tag:place=country']\n",
      "->\tTotal Running time is 202.57s\n",
      "\n",
      "df_graphqa Q7127349\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                          question answer  \\\n",
      "217             523    1       False  What's the name of their league?  Q9448   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "217  soccer   False          0.42         0.0    False           1.25   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr   graphqa  graphqa_time  \\\n",
      "217          0.0  False       243.83        0.0  Q7127349        202.81   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "217        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "217         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-218-ic523-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 524/2240 -> 2/5 -> Convex=True: (Q9448) What's the name of their league?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q1860\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q7275\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                          question answer  \\\n",
      "218             523    1        True  What's the name of their league?  Q9448   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "218  soccer   False           0.4         0.0    False           1.23   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "218          0.0  Q1860         0.04        0.0   Q7275         15.04   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "218        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "218         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-219-ic523-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:21:28.285426\n",
      "\t>>> Processing 524/2240 -> 3/5 -> Convex=False: (Q18656) Does the team have a nickname?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Does the team have a nickname?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Does the team have a nickname \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Does the team have a nickname\n",
      "> Binary question related question detected\n",
      "-> q_themes: ([(the team, ['Q19407439', 'Q24197453']), (nickname, ['Q49614', 'Q15622880']), (Team, ['Q327245', 'Q15054311']), (team, ['Q30130054'])], [a nickname, A Nickname, a Nickname])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(Does, []), (have, ['P527'])]\n",
      "-> q_predicates \tRunning time is 4.18s\n",
      "--> Predicates enhanced by previous context: [(number of episodes, ['P1113']), (Does, []), (have, ['P527'])]\n",
      "----> q_themes in context: ([(the team, ['Q19407439', 'Q24197453']), (nickname, ['Q49614', 'Q15622880']), (Team, ['Q327245', 'Q15054311']), (team, ['Q30130054'])], [A])\n",
      "--> Potential meaningful keywords for the sentence: ['the team', 'nickname', 'Team', 'team']\n",
      "---> Meaningful keywords enhanced by previous context: ['the team', 'nickname', 'Team', 'team', 'What a Country!', '26']\n",
      "meaningful_names_no_previous_answer [the team, nickname, Team, team, What a Country, 26]\n",
      "----> Meaningful keywords casted as theme ([(nickname, ['Q15622880', 'Q49614']), (Team, ['Q15054311']), (team, ['Q30130054', 'Q327245']), (26, ['Q26300452', 'Q17219446', 'Q23774'])], [])\n",
      "q_focused_parts: [(nickname, ['Q15622880', 'Q49614']), (Team, ['Q15054311']), (team, ['Q30130054', 'Q327245']), (26, ['Q26300452', 'Q17219446', 'Q23774']), (the team, ['Q19407439', 'Q24197453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.97s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "df_convex no\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Does the team have a nickname?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Does the team have a nickname \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Does the team have a nickname\n",
      "> Binary question related question detected\n",
      "-> q_themes: ([(the team, ['Q19407439', 'Q24197453']), (nickname, ['Q49614', 'Q15622880']), (Team, ['Q327245', 'Q15054311']), (team, ['Q30130054'])], [a nickname, A Nickname, a Nickname])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(Does, []), (have, ['P527'])]\n",
      "-> q_predicates \tRunning time is 4.31s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (Does, []), (have, ['P527']), (instance of, ['P31']), (OSM tag or key, ['P1282'])]\n",
      "----> q_themes in context: ([(the team, ['Q19407439', 'Q24197453']), (nickname, ['Q49614', 'Q15622880']), (Team, ['Q327245', 'Q15054311']), (team, ['Q30130054'])], [a, A])\n",
      "--> Potential meaningful keywords for the sentence: ['the team', 'nickname', 'Team', 'team']\n",
      "---> Meaningful keywords enhanced by previous context: ['the team', 'nickname', 'Team', 'team', 'country', 'South Africa', 'State of Palestine', 'Palestine–South Africa relations', 'Tag:place=country', 'country']\n",
      "meaningful_names_no_previous_answer [the team, nickname, Team, team, country, South Africa, State of Palestine, Palestine South Africa relations, Tag place country, country]\n",
      "----> Meaningful keywords casted as theme ([(nickname, ['Q15622880', 'Q49614']), (Team, ['Q15054311']), (team, ['Q30130054', 'Q327245']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (State of Palestine, ['Q219060']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(nickname, ['Q15622880', 'Q49614']), (Team, ['Q15054311']), (team, ['Q30130054', 'Q327245']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (State of Palestine, ['Q219060']), (country, ['P17', 'Q6256']), (the team, ['Q19407439', 'Q24197453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 94.21s\n",
      "-->  17 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 20 edges\n",
      "df_graphqa no\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                        question  answer  \\\n",
      "219             523    2       False  Does the team have a nickname?  Q18656   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "219  soccer   False           0.3         0.0    False           1.51   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "219          0.0     no        25.79        0.0      no        101.09   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "219        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "219         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-220-ic523-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 524/2240 -> 3/5 -> Convex=True: (Q18656) Does the team have a nickname?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex yes\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Does the team have a nickname?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Does the team have a nickname \n",
      "> Binary question related question detected\n",
      "-> q_themes: ([(the team, ['Q19407439', 'Q24197453']), (nickname, ['Q49614', 'Q15622880']), (Team, ['Q327245', 'Q15054311']), (team, ['Q30130054'])], [a nickname, A Nickname, a Nickname])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(Does, []), (have, ['P527'])]\n",
      "-> q_predicates \tRunning time is 4.1s\n",
      "--> Potential meaningful keywords for the sentence: ['the team', 'nickname', 'Team', 'team']\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.52s\n",
      "-->  56 nodes and 52 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 30 nodes and 26 edges\n",
      "---> Rebuilding the graph with k_deep 6 ... Previously: 30 nodes or 26 edges was below the limit of 100\n",
      "->New graph \tRunning time is 21.29s\n",
      "-->  84 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 52 nodes and 50 edges\n",
      "---> Rebuilding the graph with k_deep 8 ... Previously: 52 nodes or 50 edges was below the limit of 100\n",
      "->New graph \tRunning time is 21.32s\n",
      "-->  95 nodes and 94 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 59 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 59 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.06s\n",
      "-->  107 nodes and 106 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 69 nodes and 68 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 69 nodes or 68 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.15s\n",
      "-->  123 nodes and 122 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 83 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 83 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.22s\n",
      "-->  133 nodes and 132 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 89 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 89 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.17s\n",
      "-->  139 nodes and 138 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 95 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 95 nodes or 94 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.69s\n",
      "-->  149 nodes and 148 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 103 nodes and 102 edges\n",
      "node_name_id ['Q30130054']\n",
      "df_graphqa yes\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                        question  answer  \\\n",
      "220             523    2        True  Does the team have a nickname?  Q18656   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "220  soccer   False           0.3         0.0    False           1.49   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "220          0.0    yes         0.03        0.0     yes        182.84   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "220        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "220         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-221-ic523-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:26:41.708041\n",
      "\t>>> Processing 524/2240 -> 4/5 -> Convex=False: (Q83457) Where do the play their home games?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex 4184899\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Where do the play their home games?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where do the play their home games \n",
      "-> q_themes: ([(games, ['Q50808406']), (Games, ['Q19824673', 'Q1493102'])], [their home games, Their Home Games, the play -PRON- home game, home games, their Home Games])\n",
      "-> q_themes_enhanced: [('home', ['P263']), ('Home Game', ['Q24255796']), ('Home', ['Q10297942'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(do, []), (play, ['P741'])]\n",
      "-> q_predicates \tRunning time is 6.9s\n",
      "--> Potential meaningful keywords for the sentence: ['games', 'Games', 'home', 'Home Game', 'Home']\n",
      "q_focused_parts: [(games, ['Q47537672']), (home, ['P263', 'Q7743', 'Q3046346', 'Q699405'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.3s\n",
      "-->  55 nodes and 52 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 55 nodes and 52 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 55 nodes or 52 edges was below the limit of 100\n",
      "->New graph \tRunning time is 18.83s\n",
      "-->  61 nodes and 58 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 61 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 61 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 18.82s\n",
      "-->  63 nodes and 60 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 63 nodes and 60 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 63 nodes or 60 edges was below the limit of 100\n",
      "->New graph \tRunning time is 18.78s\n",
      "-->  68 nodes and 66 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 68 nodes and 66 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 68 nodes or 66 edges was below the limit of 100\n",
      "->New graph \tRunning time is 20.03s\n",
      "-->  70 nodes and 68 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 70 nodes and 68 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 70 nodes or 68 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.68s\n",
      "-->  70 nodes and 68 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 70 nodes and 68 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "-> predicates_dict: {'P1433': 3, 'P155': 3, 'P856': 1, 'P1545': 1, 'P179': 1, 'P4908': 1, 'P407': 2, 'P571': 1, 'P136': 2, 'P495': 2, 'P361': 1, 'P156': 2, 'P577': 3, 'P31': 5, 'P175': 1, 'P275': 1, 'P1476': 1, 'P123': 2, 'P50': 1}\n",
      "-> paths_keywords: (['games', 'home', 'residence'], {'playing hand': [playing hand, ['P741']], 'home': [official residence, ['P263']], 'official residence': [official residence, ['P263']]}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 178\n",
      "->Computing possible paths \tRunning time is 80.25s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 88\n",
      "->\tRunning time is 3.91s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1860', 0.42639992877697686], ['Q24255796', 0.41230668337614357]]\n",
      "->Computing hypothesises \tRunning time is 14.34s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 10\n",
      "->\tRunning time is 4.98s\n",
      "--> len(cleared_golden_paths): 5\n",
      "---> First path: ['Q1860', 'P407', 'Q1493102', 'P1476', 'Games@en']\n",
      "->\tTotal Running time is 231.24s\n",
      "\n",
      "df_graphqa Q1860\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                             question  \\\n",
      "221             523    3       False  Where do the play their home games?   \n",
      "\n",
      "     answer  domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "221  Q83457  soccer   False          1.16         0.0    False           3.89   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "221          0.0  4184899         1.86        0.0   Q1860        231.48   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "221        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "221         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-222-ic523-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 524/2240 -> 4/5 -> Convex=True: (Q83457) Where do the play their home games?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q25379\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1977-10-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                             question  \\\n",
      "222             523    3        True  Where do the play their home games?   \n",
      "\n",
      "     answer  domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "222  Q83457  soccer   False          1.14         0.0    False           3.82   \n",
      "\n",
      "     platypus_rr  convex  convex_time  convex_rr               graphqa  \\\n",
      "222          0.0  Q25379         1.69        0.0  1977-10-01T00:00:00Z   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "222          0.02        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "222          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-223-ic523-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:30:46.818748\n",
      "\t>>> Processing 524/2240 -> 5/5 -> Convex=False: (Q18125) What town are the located in?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What town are the located in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What town are the located in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What town are the located in\n",
      "-> q_themes: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What town, The Located, the locate, what Town])\n",
      "-> q_themes_enhanced: [('locate', ['Q709128']), ('Locate', ['Q1654549'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (located, ['P276', 'P131'])]\n",
      "-> q_predicates \tRunning time is 5.06s\n",
      "--> Predicates enhanced by previous context: [(Great Russian Encyclopedia Online ID, ['P2924']), (be, ['P31']), (located, ['P276', 'P131'])]\n",
      "----> q_themes in context: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What, The, the, what])\n",
      "--> Potential meaningful keywords for the sentence: ['Town', 'town', 'locate', 'Locate']\n",
      "---> Meaningful keywords enhanced by previous context: ['Town', 'town', 'locate', 'Locate', 'theater', '4184899']\n",
      "meaningful_names_no_previous_answer [Town, town, locate, Locate, theater, 4184899]\n",
      "----> Meaningful keywords casted as theme ([(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (theater, ['Q24354', 'Q11635'])], [])\n",
      "q_focused_parts: [(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (theater, ['Q24354', 'Q11635'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 43.17s\n",
      "-->  259 nodes and 258 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 259 nodes and 258 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 259 nodes or 258 edges was above the limit of 100\n",
      "-> predicates_dict: {'P2924': 16, 'P360': 1, 'P805': 2, 'P1343': 2, 'P425': 2, 'P361': 2, 'P31': 153, 'P527': 3, 'P2541': 1, 'P2354': 1, 'P5125': 1, 'P5008': 1, 'P279': 1, 'P5429': 2, 'P1151': 1}\n",
      "-> paths_keywords: (['town', 'theater', 'located'], {'Great Russian Encyclopedia Online ID': [Great Russian Encyclopedia Online ID, ['P2924']], 'instance of': [instance of, ['P31']], 'located in': [located in, ['P276']], 'is in the administrative unit': [is in the administrative unit, ['P131']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8648\n",
      "->Computing possible paths \tRunning time is 40.89s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 10564\n",
      "->\tRunning time is 16.49s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.11s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What town are the located in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What town are the located in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What Great Russian Encyclopedia Online ID town the located in\n",
      "-> q_themes: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What town, The Located, the locate, what Town])\n",
      "-> q_themes_enhanced: [('locate', ['Q709128']), ('Locate', ['Q1654549'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: town\n",
      "-> q_predicates: [(be, ['P31']), (located, ['P276', 'P131']), (town, ['P131'])]\n",
      "-> q_predicates \tRunning time is 4.94s\n",
      "--> Predicates enhanced by previous context: [(Great Russian Encyclopedia Online ID, ['P2924']), (be, ['P31']), (located, ['P276', 'P131']), (town, ['P131'])]\n",
      "----> q_themes in context: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What, The, the, what])\n",
      "--> Potential meaningful keywords for the sentence: ['Town', 'town', 'locate', 'Locate']\n",
      "---> Meaningful keywords enhanced by previous context: ['Town', 'town', 'locate', 'Locate', 'theater', '4184899']\n",
      "meaningful_names_no_previous_answer [Town, town, locate, Locate, theater, 4184899]\n",
      "----> Meaningful keywords casted as theme ([(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (theater, ['Q24354', 'Q11635'])], [])\n",
      "q_focused_parts: [(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (theater, ['Q24354', 'Q11635'])]\n",
      "-> Building the graph with k_deep 2 ... (could be long)\n",
      "->New graph \tRunning time is 46.55s\n",
      "-->  245 nodes and 244 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 245 nodes and 244 edges\n",
      "---> Rebuilding the graph with k_deep 1 ... Previously: 245 nodes or 244 edges was above the limit of 100\n",
      "-> predicates_dict: {'P2924': 16, 'P279': 1, 'P360': 1, 'P805': 1, 'P1343': 1, 'P425': 1, 'P361': 1, 'P527': 2, 'P2541': 1, 'P2354': 1, 'P5125': 1, 'P5008': 1, 'P1151': 1, 'P31': 153}\n",
      "-> paths_keywords: (['town', 'theater', 'located'], {'Great Russian Encyclopedia Online ID': [Great Russian Encyclopedia Online ID, ['P2924']], 'instance of': [instance of, ['P31']], 'located in': [located in, ['P276']], 'is in the administrative unit': [is in the administrative unit, ['P131']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8015\n",
      "->Computing possible paths \tRunning time is 53.28s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 10328\n",
      "->\tRunning time is 14.27s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 168.37s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What town are the located in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What town are the located in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What town are the located in\n",
      "-> q_themes: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What town, The Located, the locate, what Town])\n",
      "-> q_themes_enhanced: [('locate', ['Q709128']), ('Locate', ['Q1654549'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (located, ['P276', 'P131'])]\n",
      "-> q_predicates \tRunning time is 5.2s\n",
      "--> Predicates enhanced by previous context: [(title, ['P1476']), (be, ['P31']), (located, ['P276', 'P131']), (language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Town, ['Q3957', 'Q10740142']), (town, ['Q11881845'])], [What, The, the, what])\n",
      "--> Potential meaningful keywords for the sentence: ['Town', 'town', 'locate', 'Locate']\n",
      "---> Meaningful keywords enhanced by previous context: ['Town', 'town', 'locate', 'Locate', 'Games', 'Games@en', 'English']\n",
      "meaningful_names_no_previous_answer [Town, town, locate, Locate, Games, Games@en, English]\n",
      "----> Meaningful keywords casted as theme ([(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (Games, ['Q19824673', 'Q2364140', 'Q1493102']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Town, ['Q10740142']), (town, ['Q3957', 'Q11881845']), (Games, ['Q19824673', 'Q2364140', 'Q1493102']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 23.32s\n",
      "-->  23 nodes and 24 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 24 edges\n",
      "-> predicates_dict: {'P1476': 3, 'P407': 2, 'P131': 1, 'P364': 1, 'P571': 1, 'P360': 1, 'P31': 52, 'P361': 2, 'P527': 1, 'P2354': 1, 'P279': 2, 'P136': 1, 'P495': 2, 'P910': 2, 'P17': 1, 'P625': 1, 'P577': 2, 'P373': 2, 'P462': 1}\n",
      "-> paths_keywords: (['town', 'games', 'english', 'located'], {'title': [title, ['P1476']], 'instance of': [instance of, ['P31']], 'located in': [located in, ['P276']], 'is in the administrative unit': [is in the administrative unit, ['P131']], 'language of work or name': [language of work or name, ['P407']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 130\n",
      "->Computing possible paths \tRunning time is 25.32s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 128\n",
      "->\tRunning time is 4.08s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q30', 2.501005462339397], ['Games@en', 0.8702784855589447], ['Q11424', 0.7215208433963175], ['Q41298', 0.6205241754858682], ['1977-01-01T00:00:00Z', 0.35831682396098175]]\n",
      "->Computing hypothesises \tRunning time is 67.12s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 16\n",
      "->\tRunning time is 6.79s\n",
      "--> len(cleared_golden_paths): 7\n",
      "---> First path: ['Q30', 'P495', 'Q1493102', 'P407', 'Q1860', 'P364', 'Q2364140', 'P31', 'Q11424']\n",
      "->\tTotal Running time is 135.27s\n",
      "\n",
      "df_graphqa Q30\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                       question  answer  \\\n",
      "223             523    4       False  What town are the located in?  Q18125   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "223  soccer   False           1.1         0.0    False           0.25   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "223          0.0  False       317.91        0.0     Q30        135.52   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "223        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "223         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-224-ic523-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 524/2240 -> 5/5 -> Convex=True: (Q18125) What town are the located in?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q30\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q30\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                       question  answer  \\\n",
      "224             523    4        True  What town are the located in?  Q18125   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "224  soccer   False          1.14         0.0    False           0.26   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "224          0.0    Q30         0.98        0.0     Q30          0.01   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "224        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "224         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-225-ic523-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:38:24.020021\n",
      "\t>>> Processing 525/2240 -> 1/5 -> Convex=False: (Q429828) Who is the character in Grey's Anatomy that shares her last name with part of the title?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q1860\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who is the character in Grey's Anatomy that shares her last name with part of the title?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the character in Grey Anatomy that shares her last name with part of the title \n",
      "-> q_themes: ([(grey, ['Q2703557', 'Q17245659']), (Grey, ['Q15916844', 'Q15299784']), (part, ['Q15989253', 'Q153126']), (the title, ['Q7769479']), (title, ['Q216353', 'Q13629195']), (Title, ['Q783521', 'Q18164480']), (Part, ['Q37017525', 'Q414241']), (character, ['Q3241972', 'Q1792372'])], [Grey Anatomy, her last name, Grey Title, Title Grey, is the character in Grey, Her Last Name, Grey Anatomy share, Grey Anatomy shares, her last Name])\n",
      "-> q_themes_enhanced: [('Anatomy', ['Q13429539']), ('anatomy', ['Q514']), ('last name', ['P734']), ('Last Name', ['Q2617635']), ('share', ['Q11692']), ('Share', ['Q1195736'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (shares, ['P47'])]\n",
      "-> q_predicates \tRunning time is 15.33s\n",
      "--> Potential meaningful keywords for the sentence: ['grey', 'Grey', 'part', 'the title', 'title', 'Title', 'Part', 'character', 'Anatomy', 'anatomy', 'last name', 'Last Name', 'share', 'Share']\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (Anatomy, ['Q17989169', 'Q13429539']), (Grey, ['Q15916844', 'Q1147689', 'Q15299784', 'Q17245659']), (title, ['Q13629195', 'P1476'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 68.0s\n",
      "-->  2820 nodes and 2810 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 2811 nodes and 2802 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 2811 nodes or 2802 edges was above the limit of 350\n",
      "---> Too many nodes, statistically it's not worth the run. Cancelling question, it probably require reasoning.\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex  \\\n",
      "225             524    0       False   \n",
      "\n",
      "                                              question   answer     domain  \\\n",
      "225  Who is the character in Grey's Anatomy that sh...  Q429828  tv_series   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "225   False          2.99         0.0    False           0.19          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "225  Q1860         3.71        0.0   False        148.73        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "225        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-226-ic524-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:40:59.677569\n",
      "\t>>> Processing 525/2240 -> 2/5 -> Convex=False: (Q941961) Who does she end up marrying?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q9067\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who does English end up marrying\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 5.62s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "----> q_themes in context: ([(English, ['Q1860'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['English']\n",
      "---> Meaningful keywords enhanced by previous context: ['English', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [English, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(English, ['Q1219933', 'Q12261586', 'Q11616958']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(English, ['Q1219933', 'Q12261586', 'Q11616958']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 13.05s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 407, 'P131': 1, 'P577': 1, 'P31': 3, 'P17': 2, 'P136': 1, 'P910': 1, 'P373': 1}\n",
      "-> paths_keywords: (['english', 'end'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 118.44s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.85s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who does English end up marrying\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 3.53s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "----> q_themes in context: ([(English, ['Q1860'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['English']\n",
      "---> Meaningful keywords enhanced by previous context: ['English', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [English, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(English, ['Q1219933', 'Q12261586', 'Q11616958']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(English, ['Q1219933', 'Q12261586', 'Q11616958']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.2s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 407, 'P131': 1, 'P577': 1, 'P31': 3, 'P17': 2, 'P136': 1, 'P910': 1, 'P373': 1}\n",
      "-> paths_keywords: (['english', 'end'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 132.15s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 155.36s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 3.72s\n",
      "--> Potential meaningful keywords for the sentence: []\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.52s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 3.66s\n",
      "--> Potential meaningful keywords for the sentence: []\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.81s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                       question   answer  \\\n",
      "226             524    1       False  Who does she end up marrying?  Q941961   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "226  tv_series   Q9067           0.5         0.0    False           2.82   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "226          0.0  False       296.91        0.0   False         17.16   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "226        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "226         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-227-ic524-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 525/2240 -> 2/5 -> Convex=True: (Q941961) Who does she end up marrying?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q9067\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 2005-09-27T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 3.53s\n",
      "--> Potential meaningful keywords for the sentence: []\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.68s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who does she end up marrying?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who does she end up marrying \n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "-> q_predicates: [(does, []), (end, ['P3712', 'P582']), (marrying, ['P26'])]\n",
      "-> q_predicates \tRunning time is 3.7s\n",
      "--> Potential meaningful keywords for the sentence: []\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.86s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                       question   answer  \\\n",
      "227             524    1        True  Who does she end up marrying?  Q941961   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "227  tv_series   Q9067           0.0         0.0    False           2.85   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr graphqa  \\\n",
      "227          0.0  2005-09-27T00:00:00Z         0.03        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "227         17.25        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "227          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-228-ic524-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 18:46:37.270327\n",
      "\t>>> Processing 525/2240 -> 3/5 -> Convex=False: (Q9385011) What is Derek's occupation?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is Derek occupation\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 8.34s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (occupation, ['P106'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek, Occupation, is, derek])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'Occupation', 'occupation', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Derek, Occupation, occupation, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.59s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What Derek occupation\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.98s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (occupation, ['P106'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek, Occupation, is, derek])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'Occupation', 'occupation', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Derek, Occupation, occupation, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.46s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is Derek occupation\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.77s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (occupation, ['P106'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek, Occupation, is, derek])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'Occupation', 'occupation', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Derek, Occupation, occupation, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 41.77s\n",
      "-->  17 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 16 edges\n",
      "-> predicates_dict: {'P407': 408, 'P279': 1, 'P155': 2, 'P156': 2, 'P1013': 1, 'P31': 9, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P131': 2, 'P495': 1, 'P577': 2, 'P17': 3, 'P150': 1, 'P910': 1, 'P179': 1, 'P4908': 1, 'P373': 1}\n",
      "-> paths_keywords: (['derek', 'occupation', 'english'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 142.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What Derek occupation\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.89s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (occupation, ['P106'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek, Occupation, is, derek])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'Occupation', 'occupation', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Derek, Occupation, occupation, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 46.2s\n",
      "-->  17 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 16 edges\n",
      "-> predicates_dict: {'P407': 408, 'P279': 1, 'P155': 2, 'P156': 2, 'P1013': 1, 'P31': 9, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P131': 2, 'P495': 1, 'P577': 2, 'P17': 3, 'P150': 1, 'P179': 1, 'P910': 1, 'P4908': 1, 'P373': 1}\n",
      "-> paths_keywords: (['derek', 'occupation', 'english'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 131.58s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.63s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 190.89s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.61s\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "q_focused_parts: [(occupation, ['Q188686', 'P106', 'Q10687729']), (Derek, ['Q1199993', 'Q11740724'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.62s\n",
      "-->  61 nodes and 58 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 61 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 61 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 43.44s\n",
      "-->  66 nodes and 64 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 66 nodes and 64 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 66 nodes or 64 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.59s\n",
      "-->  70 nodes and 68 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 70 nodes and 68 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 70 nodes or 68 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.41s\n",
      "-->  74 nodes and 72 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 74 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 74 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 41.37s\n",
      "-->  78 nodes and 76 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 78 nodes and 76 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 78 nodes or 76 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.54s\n",
      "-->  82 nodes and 80 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 82 nodes and 80 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 82 nodes or 80 edges was below the limit of 100\n",
      "->New graph \tRunning time is 49.23s\n",
      "-->  84 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 69.11s\n",
      "-->  86 nodes and 84 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 86 nodes and 84 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 86 nodes or 84 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.22s\n",
      "-->  88 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 16 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.06s\n",
      "-->  90 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 90 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 90 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.45s\n",
      "-->  94 nodes and 92 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 18 ... Previously: 94 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.89s\n",
      "-->  98 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 98 nodes and 96 edges\n",
      "---> Rebuilding the graph with k_deep 19 ... Previously: 98 nodes or 96 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.41s\n",
      "-->  100 nodes and 98 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 100 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 20 ... Previously: 100 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.36s\n",
      "-->  102 nodes and 100 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 21 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 41.62s\n",
      "-->  104 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 102 edges\n",
      "-> predicates_dict: {'P279': 1, 'P31': 7, 'P971': 1, 'P155': 2, 'P156': 3, 'P1013': 1, 'P407': 2, 'P131': 1, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P421': 1, 'P577': 2, 'P495': 1, 'P17': 1, 'P150': 1, 'P625': 1, 'P4908': 1, 'P735': 13, 'P179': 1, 'P57': 1, 'P282': 1, 'P58': 1, 'P1705': 1, 'P3880': 1}\n",
      "-> paths_keywords: (['occupation', 'derek', 'military occupation'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.93s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.5s\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "q_focused_parts: [(occupation, ['Q188686', 'P106', 'Q10687729']), (Derek, ['Q1199993', 'Q11740724'])]\n",
      "-> Building the graph with k_deep 21 ... (could be long)\n",
      "->New graph \tRunning time is 41.57s\n",
      "-->  104 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 102 edges\n",
      "-> predicates_dict: {'P279': 1, 'P31': 7, 'P971': 1, 'P155': 2, 'P156': 3, 'P1013': 1, 'P407': 2, 'P131': 1, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P421': 1, 'P577': 2, 'P495': 1, 'P17': 1, 'P150': 1, 'P625': 1, 'P4908': 1, 'P735': 13, 'P179': 1, 'P57': 1, 'P282': 1, 'P58': 1, 'P1705': 1, 'P3880': 1}\n",
      "-> paths_keywords: (['occupation', 'derek', 'military occupation'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 140.16s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.54s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 194.34s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                     question    answer  \\\n",
      "228             524    2       False  What is Derek's occupation?  Q9385011   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "228  tv_series   False         99.84         0.0    False           0.28   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "228          0.0  False       384.87        0.0   False        999.68   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "228        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "228         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-229-ic524-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 525/2240 -> 3/5 -> Convex=True: (Q9385011) What is Derek's occupation?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q9067\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q438357\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.61s\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "q_focused_parts: [(occupation, ['Q188686', 'P106', 'Q10687729']), (Derek, ['Q1199993', 'Q11740724'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.86s\n",
      "-->  61 nodes and 58 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 61 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 61 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 45.1s\n",
      "-->  66 nodes and 64 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 66 nodes and 64 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 66 nodes or 64 edges was below the limit of 100\n",
      "->New graph \tRunning time is 39.48s\n",
      "-->  70 nodes and 68 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 70 nodes and 68 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 70 nodes or 68 edges was below the limit of 100\n",
      "->New graph \tRunning time is 38.84s\n",
      "-->  74 nodes and 72 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 74 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 74 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 39.95s\n",
      "-->  78 nodes and 76 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 78 nodes and 76 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 78 nodes or 76 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.13s\n",
      "-->  82 nodes and 80 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 82 nodes and 80 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 82 nodes or 80 edges was below the limit of 100\n",
      "->New graph \tRunning time is 43.74s\n",
      "-->  84 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.75s\n",
      "-->  86 nodes and 84 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 86 nodes and 84 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 86 nodes or 84 edges was below the limit of 100\n",
      "->New graph \tRunning time is 38.83s\n",
      "-->  88 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 16 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 39.56s\n",
      "-->  90 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 90 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 90 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 43.93s\n",
      "-->  94 nodes and 92 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 18 ... Previously: 94 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.98s\n",
      "-->  98 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 98 nodes and 96 edges\n",
      "---> Rebuilding the graph with k_deep 19 ... Previously: 98 nodes or 96 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.23s\n",
      "-->  100 nodes and 98 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 100 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 20 ... Previously: 100 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.57s\n",
      "-->  102 nodes and 100 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 21 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 41.22s\n",
      "-->  104 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 102 edges\n",
      "-> predicates_dict: {'P279': 1, 'P31': 7, 'P971': 1, 'P155': 2, 'P156': 3, 'P1013': 1, 'P407': 2, 'P131': 1, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P421': 1, 'P577': 2, 'P495': 1, 'P17': 1, 'P150': 1, 'P625': 1, 'P4908': 1, 'P735': 13, 'P179': 1, 'P57': 1, 'P282': 1, 'P58': 1, 'P1705': 1, 'P3880': 1}\n",
      "-> paths_keywords: (['occupation', 'derek', 'military occupation'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 144.69s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.68s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What is Derek's occupation?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Derek occupation \n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (Occupation, ['Q55400358', 'Q15703263']), (occupation, ['P106', 'Q10687729'])], [Derek occupation, Derek Occupation, Occupation Derek, is Derek, derek occupation])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (occupation, ['P106'])]\n",
      "-> q_predicates \tRunning time is 5.62s\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'Occupation', 'occupation']\n",
      "q_focused_parts: [(occupation, ['Q188686', 'P106', 'Q10687729']), (Derek, ['Q1199993', 'Q11740724'])]\n",
      "-> Building the graph with k_deep 21 ... (could be long)\n",
      "->New graph \tRunning time is 41.26s\n",
      "-->  104 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 102 edges\n",
      "-> predicates_dict: {'P279': 1, 'P31': 7, 'P971': 1, 'P155': 2, 'P156': 3, 'P1013': 1, 'P407': 2, 'P131': 1, 'P1114': 1, 'P1545': 3, 'P1683': 1, 'P793': 1, 'P421': 1, 'P577': 2, 'P495': 1, 'P17': 1, 'P150': 1, 'P625': 1, 'P4908': 1, 'P735': 13, 'P179': 1, 'P57': 1, 'P282': 1, 'P58': 1, 'P1705': 1, 'P3880': 1}\n",
      "-> paths_keywords: (['occupation', 'derek', 'military occupation'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 149.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 4.19s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 203.82s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                     question    answer  \\\n",
      "229             524    2        True  What is Derek's occupation?  Q9385011   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "229  tv_series   Q9067           0.0         0.0    False           2.19   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "229          0.0  Q438357         0.03        0.0   False        980.88   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "229        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "229         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-230-ic524-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 19:27:45.099805\n",
      "\t>>> Processing 525/2240 -> 4/5 -> Convex=False: (n/a) What about Meredith's current position?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What about Meredith current position\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 11.24s\n",
      "--> Predicates enhanced by previous context: []\n",
      "----> q_themes in context: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith, Position, about, meredith])\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "---> Meaningful keywords enhanced by previous context: ['Meredith', 'position', 'Position', 'current', 'Current', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Meredith, position, Position, current, Current, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 5.08s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What about Meredith current position\n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "-> q_predicates: [(current, []), (position, ['P625'])]\n",
      "-> q_predicates \tRunning time is 8.36s\n",
      "--> Predicates enhanced by previous context: [(current, []), (position, ['P625'])]\n",
      "----> q_themes in context: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith, Position, about, meredith])\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "---> Meaningful keywords enhanced by previous context: ['Meredith', 'position', 'Position', 'current', 'Current', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Meredith, position, Position, current, Current, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.74s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What about Meredith current position\n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 8.33s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith, Position, about, meredith])\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "---> Meaningful keywords enhanced by previous context: ['Meredith', 'position', 'Position', 'current', 'Current', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Meredith, position, Position, current, Current, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.11s\n",
      "-->  11 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 10 edges\n",
      "-> predicates_dict: {'P407': 407, 'P364': 1, 'P1013': 1, 'P31': 6, 'P373': 1, 'P17': 1, 'P5008': 1, 'P462': 1}\n",
      "-> paths_keywords: (['meredith', 'position', 'english', 'about'], {'language of work or name': [language of work or name, ['P407']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 90\n",
      "->Computing possible paths \tRunning time is 107.41s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14\n",
      "->\tRunning time is 3.78s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What about Meredith current position\n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "-> q_predicates: [(current, []), (position, ['P625'])]\n",
      "-> q_predicates \tRunning time is 8.26s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (current, []), (position, ['P625'])]\n",
      "----> q_themes in context: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith, Position, about, meredith])\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "---> Meaningful keywords enhanced by previous context: ['Meredith', 'position', 'Position', 'current', 'Current', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Meredith, position, Position, current, Current, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Meredith, ['Q1276644']), (position, ['Q1412501']), (Position, ['Q11658173', 'Q24834761']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 27.01s\n",
      "-->  11 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 10 edges\n",
      "-> predicates_dict: {'P407': 407, 'P625': 1, 'P364': 1, 'P1013': 1, 'P31': 6, 'P373': 3, 'P131': 1, 'P618': 1, 'P5008': 1, 'P17': 1, 'P361': 1, 'P495': 1, 'P910': 2, 'P462': 1}\n",
      "-> paths_keywords: (['meredith', 'position', 'english', 'about'], {'language of work or name': [language of work or name, ['P407']], 'coordinate location': [coordinate location, ['P625']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 90\n",
      "->Computing possible paths \tRunning time is 104.91s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14\n",
      "->\tRunning time is 5.62s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 148.86s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 8.59s\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "q_focused_parts: [(position, ['Q1412501', 'P625', 'Q1781513']), (Meredith, ['Q531358', 'Q6818913', 'Q1276644', 'Q15299568']), (current, ['Q11651'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.52s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "-> q_predicates: [(current, []), (position, ['P625'])]\n",
      "-> q_predicates \tRunning time is 8.17s\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "q_focused_parts: [(position, ['Q1412501', 'P625', 'Q1781513']), (Meredith, ['Q531358', 'Q6818913', 'Q1276644', 'Q15299568']), (current, ['Q11651'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.43s\n",
      "-->  46 nodes and 42 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 33 nodes and 30 edges\n",
      "---> Rebuilding the graph with k_deep 6 ... Previously: 33 nodes or 30 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.22s\n",
      "-->  70 nodes and 66 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 53 nodes and 50 edges\n",
      "---> Rebuilding the graph with k_deep 8 ... Previously: 53 nodes or 50 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.36s\n",
      "-->  78 nodes and 74 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 59 nodes and 56 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 59 nodes or 56 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.28s\n",
      "-->  89 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 68 nodes and 66 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 68 nodes or 66 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.3s\n",
      "-->  99 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 74 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 74 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.06s\n",
      "-->  109 nodes and 106 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 80 nodes and 78 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 80 nodes or 78 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.37s\n",
      "-->  115 nodes and 112 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 16 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.23s\n",
      "-->  121 nodes and 118 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.21s\n",
      "-->  127 nodes and 124 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 92 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 18 ... Previously: 92 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 28.73s\n",
      "-->  131 nodes and 128 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 19 ... Previously: 94 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 25.4s\n",
      "-->  135 nodes and 132 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 96 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 20 ... Previously: 96 nodes or 94 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.92s\n",
      "-->  141 nodes and 138 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 21 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.25s\n",
      "-->  146 nodes and 144 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 107 nodes and 106 edges\n",
      "-> predicates_dict: {'P625': 1, 'P373': 3, 'P111': 4, 'P2283': 2, 'P279': 4, 'P159': 1, 'P242': 1, 'P131': 6, 'P585': 1, 'P1082': 1, 'P618': 1, 'P1013': 1, 'P5008': 1, 'P2046': 1, 'P364': 1, 'P31': 6, 'P473': 1, 'P407': 1, 'P577': 2, 'P291': 1, 'P282': 1, 'P910': 2, 'P361': 1, 'P774': 1, 'P495': 1, 'P2044': 1, 'P1408': 1, 'P828': 1, 'P150': 1, 'P735': 6, 'P19': 4, 'P856': 1, 'P20': 2, 'P17': 1, 'P161': 1, 'P462': 1, 'P57': 1, 'P1705': 1, 'P3878': 1, 'P3879': 1, 'P3880': 1, 'P58': 1}\n",
      "-> paths_keywords: (['position', 'meredith', 'current', 'about', 'louisa anne meredith', 'meredith college', 'electric current'], {'coordinate location': [coordinate location, ['P625']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 177.66s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 503.09s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                                 question  \\\n",
      "230             524    3       False  What about Meredith's current position?   \n",
      "\n",
      "    answer     domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "230    n/a  tv_series   False         48.88         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "230           0.51          0.0  False       293.43        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "230        516.67        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "230          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-231-ic524-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 525/2240 -> 4/5 -> Convex=True: (n/a) What about Meredith's current position?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q9067\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q438357\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 8.03s\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "q_focused_parts: [(position, ['Q1412501', 'P625', 'Q1781513']), (Meredith, ['Q531358', 'Q6818913', 'Q1276644', 'Q15299568']), (current, ['Q11651'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.57s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What about Meredith's current position?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What about Meredith current position \n",
      "-> q_themes: ([(Meredith, ['Q1276644', 'Q2276259']), (position, ['Q4164871', 'Q1412501']), (Position, ['Q11658173', 'Q24834761'])], [Meredith current position, Meredith Position, Position Meredith, about Meredith, Meredith Current Position, meredith current position, Meredith current Position])\n",
      "-> q_themes_enhanced: [('current', ['Q11651']), ('Current', ['Q11056977'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "-> q_predicates: [(current, []), (position, ['P625'])]\n",
      "-> q_predicates \tRunning time is 7.75s\n",
      "--> Potential meaningful keywords for the sentence: ['Meredith', 'position', 'Position', 'current', 'Current']\n",
      "q_focused_parts: [(position, ['Q1412501', 'P625', 'Q1781513']), (Meredith, ['Q531358', 'Q6818913', 'Q1276644', 'Q15299568']), (current, ['Q11651'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.43s\n",
      "-->  46 nodes and 42 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 33 nodes and 30 edges\n",
      "---> Rebuilding the graph with k_deep 6 ... Previously: 33 nodes or 30 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.16s\n",
      "-->  70 nodes and 66 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 53 nodes and 50 edges\n",
      "---> Rebuilding the graph with k_deep 8 ... Previously: 53 nodes or 50 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.69s\n",
      "-->  78 nodes and 74 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 59 nodes and 56 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 59 nodes or 56 edges was below the limit of 100\n",
      "->New graph \tRunning time is 22.98s\n",
      "-->  89 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 68 nodes and 66 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 68 nodes or 66 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.19s\n",
      "-->  99 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 74 nodes and 72 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 74 nodes or 72 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.27s\n",
      "-->  109 nodes and 106 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 80 nodes and 78 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 80 nodes or 78 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.32s\n",
      "-->  115 nodes and 112 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 16 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 24.51s\n",
      "-->  121 nodes and 118 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 25.59s\n",
      "-->  127 nodes and 124 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 92 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 18 ... Previously: 92 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 25.05s\n",
      "-->  131 nodes and 128 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 19 ... Previously: 94 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 25.31s\n",
      "-->  135 nodes and 132 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 96 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 20 ... Previously: 96 nodes or 94 edges was below the limit of 100\n",
      "->New graph \tRunning time is 25.07s\n",
      "-->  141 nodes and 138 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 21 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 24.79s\n",
      "-->  146 nodes and 144 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 107 nodes and 106 edges\n",
      "-> predicates_dict: {'P625': 1, 'P373': 3, 'P111': 4, 'P2283': 2, 'P279': 4, 'P159': 1, 'P242': 1, 'P131': 6, 'P585': 1, 'P1082': 1, 'P618': 1, 'P1013': 1, 'P5008': 1, 'P2046': 1, 'P364': 1, 'P31': 6, 'P473': 1, 'P407': 1, 'P577': 2, 'P291': 1, 'P282': 1, 'P910': 2, 'P361': 1, 'P774': 1, 'P495': 1, 'P2044': 1, 'P1408': 1, 'P828': 1, 'P150': 1, 'P735': 6, 'P19': 4, 'P856': 1, 'P20': 2, 'P17': 1, 'P161': 1, 'P462': 1, 'P57': 1, 'P1705': 1, 'P3878': 1, 'P3879': 1, 'P3880': 1, 'P58': 1}\n",
      "-> paths_keywords: (['position', 'meredith', 'current', 'about', 'louisa anne meredith', 'meredith college', 'electric current'], {'coordinate location': [coordinate location, ['P625']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 190.04s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.67s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 515.69s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                                 question  \\\n",
      "231             524    3        True  What about Meredith's current position?   \n",
      "\n",
      "    answer     domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "231    n/a  tv_series   Q9067           0.0         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr   convex  convex_time  convex_rr graphqa  \\\n",
      "231            0.5          0.0  Q438357         0.03        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "231        528.81        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "231          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-232-ic524-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 19:50:53.994148\n",
      "\t>>> Processing 525/2240 -> 5/5 -> Convex=False: (Q61037771) What kind of accident ended up killing Derek?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What kind of accident ended up killing Derek?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of accident ended up killing Derek \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What kind of accident ended up killing Derek\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What kind of accident ended up killing Derek])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_predicates: [(ended, ['P1534']), (killing, ['P157'])]\n",
      "-> q_predicates \tRunning time is 9.44s\n",
      "--> Predicates enhanced by previous context: [(ended, ['P1534']), (killing, ['P157'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'accident', 'Kind', 'Accident']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'accident', 'Kind', 'Accident', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Derek, accident, Kind, Accident, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 42.54s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What kind of accident ended up killing Derek?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of accident ended up killing Derek \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What kind of accident ended up killing Derek\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What kind of accident ended up killing Derek])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: kind\n",
      "-> q_predicates: [(ended, ['P1534']), (killing, ['P157']), (kind, []), (accident, ['P1755'])]\n",
      "-> q_predicates \tRunning time is 7.59s\n",
      "--> Predicates enhanced by previous context: [(ended, ['P1534']), (killing, ['P157']), (kind, []), (accident, ['P1755'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'accident', 'Kind', 'Accident']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'accident', 'Kind', 'Accident', 'Hungarian language']\n",
      "meaningful_names_no_previous_answer [Derek, accident, Kind, Accident, Hungarian language]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (Hungarian language, ['Q9067'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (Hungarian language, ['Q9067'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.44s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What kind of accident ended up killing Derek?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of accident ended up killing Derek \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What kind of accident ended up killing Derek\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What kind of accident ended up killing Derek])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(ended, ['P1534']), (killing, ['P157'])]\n",
      "-> q_predicates \tRunning time is 7.67s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (ended, ['P1534']), (killing, ['P157'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'accident', 'Kind', 'Accident']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'accident', 'Kind', 'Accident', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Derek, accident, Kind, Accident, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 50.37s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P407': 408, 'P364': 1, 'P1013': 3, 'P571': 1, 'P805': 1, 'P1343': 2, 'P31': 8, 'P1114': 1, 'P1545': 1, 'P1683': 1, 'P793': 1, 'P131': 2, 'P734': 1, 'P921': 1, 'P17': 1, 'P136': 2, 'P421': 1, 'P462': 1, 'P495': 2, 'P577': 1, 'P625': 1, 'P910': 1, 'P373': 1}\n",
      "-> paths_keywords: (['derek', 'accident', 'kind', 'english', 'ended'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.13s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.7s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What kind of accident ended up killing Derek?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of accident ended up killing Derek \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What kind of accident ended up killing Derek\n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What kind of accident ended up killing Derek])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: kind\n",
      "-> q_predicates: [(ended, ['P1534']), (killing, ['P157']), (kind, []), (accident, ['P1755'])]\n",
      "-> q_predicates \tRunning time is 7.61s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (ended, ['P1534']), (killing, ['P157']), (kind, []), (accident, ['P1755'])]\n",
      "----> q_themes in context: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What])\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'accident', 'Kind', 'Accident']\n",
      "---> Meaningful keywords enhanced by previous context: ['Derek', 'accident', 'Kind', 'Accident', \"Grey's Anatomy\", 'English']\n",
      "meaningful_names_no_previous_answer [Derek, accident, Kind, Accident, Grey Anatomy, English]\n",
      "----> Meaningful keywords casted as theme ([(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Derek, ['Q1991801', 'Q11740724']), (accident, ['Q424630', 'Q171558']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 46.56s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P407': 408, 'P1013': 3, 'P364': 1, 'P571': 1, 'P805': 1, 'P1343': 2, 'P31': 8, 'P1114': 1, 'P1545': 1, 'P1683': 1, 'P793': 1, 'P131': 2, 'P734': 3, 'P921': 1, 'P17': 1, 'P136': 2, 'P282': 1, 'P495': 2, 'P421': 1, 'P462': 1, 'P910': 1, 'P577': 1, 'P373': 1, 'P625': 1}\n",
      "-> paths_keywords: (['derek', 'accident', 'kind', 'english', 'ended'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 130.32s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 190.84s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What kind of accident ended up killing Derek?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What kind of accident ended up killing Derek \n",
      "-> q_themes: ([(Derek, ['Q11740724', 'Q1991801']), (accident, ['Q171558', 'Q424630']), (Kind, ['Q16871404', 'Q1178576']), (Accident, ['Q18161530', 'Q12719914'])], [What kind of accident ended up killing Derek])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(ended, ['P1534']), (killing, ['P157'])]\n",
      "-> q_predicates \tRunning time is 7.12s\n",
      "--> Potential meaningful keywords for the sentence: ['Derek', 'accident', 'Kind', 'Accident']\n",
      "q_focused_parts: [(kind, ['Q21146257']), (accident, ['Q424630', 'Q171558'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 40.02s\n",
      "-->  62 nodes and 56 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 62 nodes and 56 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 62 nodes or 56 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.21s\n",
      "-->  69 nodes and 64 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 69 nodes and 64 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 69 nodes or 64 edges was below the limit of 100\n",
      "->New graph \tRunning time is 40.61s\n",
      "-->  78 nodes and 74 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 78 nodes and 74 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 78 nodes or 74 edges was below the limit of 100\n",
      "->New graph \tRunning time is 41.6s\n",
      "-->  91 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 91 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 91 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.35s\n",
      "-->  93 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 93 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 93 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 43.11s\n",
      "-->  96 nodes and 94 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 96 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 96 nodes or 94 edges was below the limit of 100\n",
      "->New graph \tRunning time is 42.76s\n",
      "-->  98 nodes and 96 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 98 nodes and 96 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 98 nodes or 96 edges was below the limit of 100\n",
      "->New graph \tRunning time is 41.99s\n",
      "-->  100 nodes and 98 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 100 nodes and 98 edges\n",
      "---> Rebuilding the graph with k_deep 14 ... Previously: 100 nodes or 98 edges was below the limit of 100\n",
      "->New graph \tRunning time is 48.84s\n",
      "-->  102 nodes and 100 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 44.42s\n",
      "-->  104 nodes and 102 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 104 nodes and 102 edges\n",
      "-> predicates_dict: {'P1013': 3, 'P734': 13, 'P1114': 1, 'P1545': 1, 'P1683': 1, 'P793': 1, 'P131': 1, 'P571': 1, 'P805': 1, 'P1343': 2, 'P31': 6, 'P364': 1, 'P421': 1, 'P921': 1, 'P495': 2, 'P282': 2, 'P136': 2, 'P577': 1, 'P17': 1, 'P150': 1, 'P625': 1, 'P279': 1, 'P1476': 1, 'P462': 1, 'P407': 2, 'P57': 1, 'P3879': 1}\n",
      "-> paths_keywords: (['kind', 'accident', 'ended', 'derek', 'type'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 392\n",
      "->Computing possible paths \tRunning time is 39.8s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 356\n",
      "->\tRunning time is 3.78s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7411', 1.7505719695465685], ['Q56043481', 1.0138201842035397], ['Q101352', 0.9727006049400674], ['Q11424', 0.8049236469280054], ['Q12308941', 0.7114895955971116], ['Q1860', 0.34107388252004606], ['Q29671747', 0.24297902213466577]]\n",
      "->Computing hypothesises \tRunning time is 29.49s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 6\n",
      "->\tRunning time is 7.2s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q7411', 'P407', 'Q11740724', 'P282', 'Q8229']\n",
      "->\tTotal Running time is 517.15s\n",
      "\n",
      "df_graphqa Q7411\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "232             524    4       False   \n",
      "\n",
      "                                          question     answer     domain  \\\n",
      "232  What kind of accident ended up killing Derek?  Q61037771  tv_series   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "232   False        113.76         0.0    False           1.36          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "232  False       394.42        0.0   Q7411        517.42        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "232        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-233-ic524-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 525/2240 -> 5/5 -> Convex=True: (Q61037771) What kind of accident ended up killing Derek?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q9067\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q438357\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q26906271\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "233             524    4        True   \n",
      "\n",
      "                                          question     answer     domain  \\\n",
      "233  What kind of accident ended up killing Derek?  Q61037771  tv_series   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "233   Q9067           0.0         0.0    False           1.41          0.0   \n",
      "\n",
      "      convex  convex_time  convex_rr    graphqa  graphqa_time graphqa_top2  \\\n",
      "233  Q438357         0.04        0.0  Q26906271          8.37        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "233        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-234-ic524-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 20:08:10.832194\n",
      "\t>>> Processing 526/2240 -> 1/5 -> Convex=False: (Q8682) Who won the Champions League in 2018?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q1543\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who won the Champions League in 2018?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who won the Champions League in 2018 \n",
      "-> q_themes: ([(Champions League, ['Q224610']), (Won, ['Q20080348', 'Q5399384'])], [won the Champions])\n",
      "-> q_themes_enhanced: [('won', ['P1355']), ('The Win', ['Q29639012']), ('The Champions', ['Q10942673']), ('Win', ['Q1202506'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(won, ['P2522', 'P1355'])]\n",
      "-> q_predicates \tRunning time is 5.43s\n",
      "--> Potential meaningful keywords for the sentence: ['Champions League', 'Won', 'won', 'The Win', 'The Champions', 'Win']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_focused_parts: [(League, ['Q12770238', 'Q223341', 'Q37436664']), (Champions, ['Q1061243', 'Q10942673', 'Q16717686', 'Q10448296']), (2018, ['Q20094148', 'Q12681715'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.4s\n",
      "-->  48 nodes and 46 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 48 nodes and 46 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 48 nodes or 46 edges was below the limit of 100\n",
      "->New graph \tRunning time is 21.13s\n",
      "-->  52 nodes and 50 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 52 nodes and 50 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 52 nodes or 50 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.67s\n",
      "-->  56 nodes and 54 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 56 nodes and 54 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 56 nodes or 54 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.61s\n",
      "-->  60 nodes and 58 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 60 nodes and 58 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 60 nodes or 58 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.03s\n",
      "-->  64 nodes and 62 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 64 nodes and 62 edges\n",
      "---> Rebuilding the graph with k_deep 13 ... Previously: 64 nodes or 62 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.5s\n",
      "-->  68 nodes and 66 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 68 nodes and 66 edges\n",
      "---> Rebuilding the graph with k_deep 15 ... Previously: 68 nodes or 66 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.5s\n",
      "-->  72 nodes and 70 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 72 nodes and 70 edges\n",
      "---> Rebuilding the graph with k_deep 17 ... Previously: 72 nodes or 70 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.94s\n",
      "-->  76 nodes and 74 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 76 nodes and 74 edges\n",
      "---> Rebuilding the graph with k_deep 19 ... Previously: 76 nodes or 74 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.84s\n",
      "-->  80 nodes and 78 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 80 nodes and 78 edges\n",
      "---> Rebuilding the graph with k_deep 20 ... Previously: 80 nodes or 78 edges was below the limit of 100\n",
      "->New graph \tRunning time is 20.97s\n",
      "-->  82 nodes and 80 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 82 nodes and 80 edges\n",
      "---> Rebuilding the graph with k_deep 21 ... Previously: 82 nodes or 80 edges was below the limit of 100\n",
      "->New graph \tRunning time is 21.45s\n",
      "-->  84 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 84 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 22 ... Previously: 84 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.06s\n",
      "-->  86 nodes and 84 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 86 nodes and 84 edges\n",
      "---> Rebuilding the graph with k_deep 23 ... Previously: 86 nodes or 84 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.66s\n",
      "-->  88 nodes and 86 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 88 nodes and 86 edges\n",
      "---> Rebuilding the graph with k_deep 24 ... Previously: 88 nodes or 86 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.1s\n",
      "-->  90 nodes and 88 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 90 nodes and 88 edges\n",
      "---> Rebuilding the graph with k_deep 25 ... Previously: 90 nodes or 88 edges was below the limit of 100\n",
      "->New graph \tRunning time is 27.59s\n",
      "-->  92 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 92 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 26 ... Previously: 92 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 23.36s\n",
      "-->  94 nodes and 92 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 94 nodes and 92 edges\n",
      "---> Rebuilding the graph with k_deep 27 ... Previously: 94 nodes or 92 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.56s\n",
      "-->  96 nodes and 94 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 96 nodes and 94 edges\n",
      "---> Rebuilding the graph with k_deep 28 ... Previously: 96 nodes or 94 edges was below the limit of 100\n",
      "-> predicates_dict: {'P1013': 3, 'P527': 27, 'P155': 2, 'P156': 2, 'P31': 3, 'P495': 1, 'P577': 2, 'P1545': 2, 'P4908': 1, 'P282': 1, 'P1705': 1, 'P279': 1, 'P179': 1}\n",
      "-> paths_keywords: (['league', 'champions', '2018', 'won', 'league of legends', 'the champions'], {'victory': [victory, ['P2522']], 'won': [number of wins, ['P1355']], 'number of wins': [number of wins, ['P1355']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 1898\n",
      "->Computing possible paths \tRunning time is 36.04s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 810\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q18210311', 0.7335233923334535], ['Q18111936', 0.714099135785704], ['Q16256864', 0.5281396929648395], ['Q5095028', 0.522043032959227], ['Q18210719', 0.5182396140018076], ['Q16256726', 0.4930342736174578], ['Q18210064', 0.46974962247779956], ['Q16255585', 0.4544617726158859], ['Q18210720', 0.4473538314065052], ['Q6191267', 0.43935121371648733], ['Q18125404', 0.4369758681315835], ['Q16256159', 0.4093171533737598], ['Q1417633', 0.4029598347258915], ['Q18210725', 0.39223321973154335], ['Q5208136', 0.3754358968186683], ['Q16290493', 0.3669157322035859], ['Q18125824', 0.34547326791923505], ['Q18210724', 0.3438325207408471], ['Q16256699', 0.3315424637994059], ['Q16277445', 0.32768784640500004], ['Q18125810', 0.3063206904537768], ['Q7457039', 0.29053053078852625], ['Q16255978', 0.2849621499141006], ['Q28698566', 0.28211472812212135], ['Q18210722', 0.2663370243576877], ['Q18210717', 0.21337180272770984]]\n",
      "->Computing hypothesises \tRunning time is 119.91s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 7.4s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q18210311', 'P527', 'Q20080348', 'P1013', 'Q23765057']\n",
      "->\tTotal Running time is 529.64s\n",
      "\n",
      "df_graphqa Q18210311\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                               question  \\\n",
      "234             525    0       False  Who won the Champions League in 2018?   \n",
      "\n",
      "    answer  domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "234  Q8682  soccer   False           0.4         0.0    False           1.49   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "234          0.0  Q1543         1.25        0.0  Q18210311        529.88   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "234        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "234         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-235-ic525-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 20:17:03.891089\n",
      "\t>>> Processing 526/2240 -> 2/5 -> Convex=False: (Q1130849) Who did Madrid beat?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q60\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who did Madrid beat?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who did Madrid beat \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who did Madrid beat\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617'])], [did Madrid])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (beat, ['P1725'])]\n",
      "-> q_predicates \tRunning time is 3.7s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (did, ['P248']), (beat, ['P1725'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617'])], [did])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', '2006–07 UEFA Champions League', 'A.C. Milan']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Madrid, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 43.68s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P585': 1, 'P407': 3, 'P856': 2, 'P31': 4, 'P571': 2, 'P54': 3, 'P1351': 1, 'P5138': 3, 'P2348': 1, 'P3085': 1, 'P1350': 1, 'P664': 1, 'P155': 1, 'P156': 1, 'P3450': 1, 'P373': 1, 'P910': 1, 'P3744': 1, 'P2002': 1, 'P580': 4, 'P582': 3, 'P286': 4, 'P641': 2, 'P118': 1, 'P17': 1, 'P281': 1, 'P969': 1, 'P159': 1}\n",
      "-> paths_keywords: (['2006–07 uefa champions league', 'a.c. milan', 'madrid'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.38s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who did Madrid beat?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who did Madrid beat \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who did Madrid beat\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617'])], [did Madrid])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (beat, ['P1725'])]\n",
      "-> q_predicates \tRunning time is 3.47s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (did, ['P248']), (beat, ['P1725'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617'])], [did])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Madrid, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 45.36s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P585': 1, 'P407': 3, 'P856': 2, 'P31': 4, 'P571': 2, 'P54': 3, 'P1351': 1, 'P5138': 3, 'P2348': 1, 'P3085': 1, 'P1350': 1, 'P664': 1, 'P155': 1, 'P156': 1, 'P3450': 1, 'P373': 1, 'P910': 1, 'P3744': 1, 'P2002': 1, 'P580': 4, 'P582': 3, 'P286': 4, 'P641': 2, 'P118': 1, 'P17': 1, 'P281': 1, 'P969': 1, 'P159': 1}\n",
      "-> paths_keywords: (['2006–07 uefa champions league', 'a.c. milan', 'madrid'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.96s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.71s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 189.45s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who did Madrid beat?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who did Madrid beat \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who did Madrid beat\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617'])], [did Madrid])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (beat, ['P1725'])]\n",
      "-> q_predicates \tRunning time is 3.68s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (did, ['P248']), (beat, ['P1725']), (has part, ['P527'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617'])], [did])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Won', 'given name has to use a different item than disambiguation pages', 'So-won', 'Won']\n",
      "meaningful_names_no_previous_answer [Madrid, Won, given name has to use a different item than disambiguation pages, So won, Won]\n",
      "----> Meaningful keywords casted as theme ([(Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348'])], [])\n",
      "q_focused_parts: [(Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.24s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P1013': 4, 'P527': 44, 'P1545': 2, 'P156': 1, 'P2001': 1, 'P735': 1, 'P31': 4, 'P577': 1, 'P407': 2, 'P282': 1, 'P1705': 1, 'P155': 2, 'P175': 1, 'P17': 1, 'P625': 1}\n",
      "-> paths_keywords: (['won', 'madrid'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 127.92s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 4.02s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who did Madrid beat?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who did Madrid beat \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who did Madrid beat\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617'])], [did Madrid])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (beat, ['P1725'])]\n",
      "-> q_predicates \tRunning time is 3.82s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (did, ['P248']), (beat, ['P1725']), (has part, ['P527'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617'])], [did])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Won', 'given name has to use a different item than disambiguation pages', 'So-won', 'Won']\n",
      "meaningful_names_no_previous_answer [Madrid, Won, given name has to use a different item than disambiguation pages, So won, Won]\n",
      "----> Meaningful keywords casted as theme ([(Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348'])], [])\n",
      "q_focused_parts: [(Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.89s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P1013': 4, 'P527': 44, 'P1545': 2, 'P156': 1, 'P2001': 1, 'P735': 1, 'P31': 4, 'P577': 1, 'P407': 2, 'P282': 1, 'P1705': 1, 'P155': 2, 'P175': 1, 'P17': 1, 'P625': 1}\n",
      "-> paths_keywords: (['won', 'madrid'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 123.5s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.68s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->\tTotal Running time is 147.41s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex              question    answer  domain  \\\n",
      "235             525    1       False  Who did Madrid beat?  Q1130849  soccer   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "235     Q60          0.27         0.0    False           2.79          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "235  False        370.3        0.0   False        296.87        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "235        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-236-ic525-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 526/2240 -> 2/5 -> Convex=True: (Q1130849) Who did Madrid beat?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q60\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q1543\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q20080348\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex              question    answer  domain  \\\n",
      "236             525    1        True  Who did Madrid beat?  Q1130849  soccer   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "236     Q60           0.0         0.0    False           0.91          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr    graphqa  graphqa_time graphqa_top2  \\\n",
      "236  Q1543          2.7        0.0  Q20080348          0.11        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "236        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-237-ic525-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 20:28:17.894206\n",
      "\t>>> Processing 526/2240 -> 3/5 -> Convex=False: (Q1899) Where did Madrid and Liverpool play the final?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741'])]\n",
      "-> q_predicates \tRunning time is 8.06s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (play, ['P741'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', 'New York City']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, New York City]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.68s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: final\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "-> q_predicates \tRunning time is 7.95s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', 'New York City']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, New York City]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.52s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741'])]\n",
      "-> q_predicates \tRunning time is 8.09s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (did, ['P248']), (play, ['P741'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 48.9s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P585': 1, 'P1350': 1, 'P407': 3, 'P856': 2, 'P364': 1, 'P31': 7, 'P155': 2, 'P156': 3, 'P571': 2, 'P1476': 1, 'P361': 1, 'P5138': 3, 'P495': 1, 'P3450': 1, 'P750': 1, 'P54': 3, 'P2348': 1, 'P3085': 1, 'P664': 1, 'P641': 3, 'P373': 1, 'P175': 1, 'P57': 1, 'P580': 4, 'P582': 3, 'P286': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['liverpool', 'the final', '2006–07 uefa champions league', 'a.c. milan', 'madrid'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 142.35s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.67s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: final\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "-> q_predicates \tRunning time is 7.91s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 47.45s\n",
      "-->  10 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 10 nodes and 10 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P577': 2, 'P156': 3, 'P361': 1, 'P571': 2, 'P580': 4, 'P582': 3, 'P286': 4, 'P585': 1, 'P2348': 1, 'P2184': 1, 'P1350': 1, 'P31': 7, 'P1344': 1, 'P407': 3, 'P856': 2, 'P364': 1, 'P155': 2, 'P1476': 1, 'P5138': 3, 'P495': 1, 'P3450': 1, 'P750': 1, 'P54': 3, 'P664': 1, 'P3085': 1, 'P641': 3, 'P373': 1, 'P118': 1, 'P175': 1, 'P57': 1}\n",
      "-> paths_keywords: (['liverpool', 'the final', '2006–07 uefa champions league', 'a.c. milan', 'madrid'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 146.73s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 209.16s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741'])]\n",
      "-> q_predicates \tRunning time is 7.59s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (did, ['P248']), (play, ['P741'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', 'Won', 'given name has to use a different item than disambiguation pages', 'So-won', 'Won']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, Won, given name has to use a different item than disambiguation pages, So won, Won]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.67s\n",
      "-->  21 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 21 nodes and 20 edges\n",
      "-> predicates_dict: {'P1013': 4, 'P527': 18, 'P156': 3, 'P364': 1, 'P31': 6, 'P155': 1, 'P1476': 1, 'P361': 1, 'P577': 1, 'P175': 1, 'P495': 1, 'P750': 1, 'P407': 1, 'P282': 1, 'P1705': 1, 'P17': 1, 'P625': 1}\n",
      "-> paths_keywords: (['liverpool', 'the final', 'won', 'madrid'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 130.46s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Where did Madrid and Liverpool play the final?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Where did Madrid and Liverpool play the final \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Where did Madrid and Liverpool play the final\n",
      "-> q_themes: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where did Madrid, Madrid and Liverpool])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: final\n",
      "-> q_predicates: [(did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "-> q_predicates \tRunning time is 7.83s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (did, ['P248']), (play, ['P741']), (final, ['P577'])]\n",
      "----> q_themes in context: ([(Madrid, ['Q2807', 'Q6728617']), (Liverpool, ['Q24826', 'Q10568093']), (The Final, ['Q1169316', 'Q2073341'])], [Where, Madrid])\n",
      "--> Potential meaningful keywords for the sentence: ['Madrid', 'Liverpool', 'The Final']\n",
      "---> Meaningful keywords enhanced by previous context: ['Madrid', 'Liverpool', 'The Final', 'Won', 'given name has to use a different item than disambiguation pages', 'So-won', 'Won']\n",
      "meaningful_names_no_previous_answer [Madrid, Liverpool, The Final, Won, given name has to use a different item than disambiguation pages, So won, Won]\n",
      "----> Meaningful keywords casted as theme ([(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348'])], [])\n",
      "q_focused_parts: [(Liverpool, ['Q10568093']), (The Final, ['Q2073341', 'Q1169316']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Madrid, ['Q2807', 'Q6728617'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 14.3s\n",
      "-->  21 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 21 nodes and 20 edges\n",
      "-> predicates_dict: {'P1013': 4, 'P527': 18, 'P577': 3, 'P156': 3, 'P361': 1, 'P407': 1, 'P31': 6, 'P364': 1, 'P155': 2, 'P1476': 1, 'P175': 1, 'P495': 1, 'P750': 1, 'P282': 1, 'P1705': 1, 'P17': 1, 'P625': 1}\n",
      "-> paths_keywords: (['liverpool', 'the final', 'won', 'madrid'], {}, [Where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.89s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.47s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 159.22s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex  \\\n",
      "237             525    2       False   \n",
      "\n",
      "                                           question answer  domain qanswer  \\\n",
      "237  Where did Madrid and Liverpool play the final?  Q1899  soccer   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "237         45.01         0.0    False           5.88          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "237       412.93        0.0   False        315.09        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "237        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-238-ic525-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 526/2240 -> 3/5 -> Convex=True: (Q1899) Where did Madrid and Liverpool play the final?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q60\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q490\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q20080348\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "238             525    2        True   \n",
      "\n",
      "                                           question answer  domain qanswer  \\\n",
      "238  Where did Madrid and Liverpool play the final?  Q1899  soccer     Q60   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "238           0.0         0.0    False           5.84          0.0   Q490   \n",
      "\n",
      "     convex_time  convex_rr    graphqa  graphqa_time graphqa_top2  \\\n",
      "238         2.09        0.0  Q20080348           0.1        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "238        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-239-ic525-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 20:41:24.860874\n",
      "\t>>> Processing 526/2240 -> 4/5 -> Convex=False: (Q184586) Who was named Man of the Match?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who was named Man of the Match?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was named Man of the Match \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was named Man of the Match\n",
      "-> q_themes: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was named Man])\n",
      "-> q_themes_enhanced: [('man', ['Q12656568']), ('Named', ['Q6961550']), ('Name', ['Q11236330', 'P735'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "-> q_predicates \tRunning time is 5.09s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "----> q_themes in context: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was])\n",
      "--> Potential meaningful keywords for the sentence: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name', 'New York City']\n",
      "meaningful_names_no_previous_answer [Man of the Match, the Match, match, Match, The Match, name, Man, man, Named, Name, New York City]\n",
      "----> Meaningful keywords casted as theme ([(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (the Match, ['Q3224390', 'Q688474'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.88s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who was named Man of the Match?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was named Man of the Match \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who named Man of the Match\n",
      "-> q_themes: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was named Man])\n",
      "-> q_themes_enhanced: [('man', ['Q12656568']), ('Named', ['Q6961550']), ('Name', ['Q11236330', 'P735'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "-> q_predicates \tRunning time is 5.09s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "----> q_themes in context: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was])\n",
      "--> Potential meaningful keywords for the sentence: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name', 'New York City']\n",
      "meaningful_names_no_previous_answer [Man of the Match, the Match, match, Match, The Match, name, Man, man, Named, Name, New York City]\n",
      "----> Meaningful keywords casted as theme ([(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (the Match, ['Q3224390', 'Q688474'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.8s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who was named Man of the Match?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was named Man of the Match \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was named Man of the Match\n",
      "-> q_themes: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was named Man])\n",
      "-> q_themes_enhanced: [('man', ['Q12656568']), ('Named', ['Q6961550']), ('Name', ['Q11236330', 'P735'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "-> q_predicates \tRunning time is 5.01s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "----> q_themes in context: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was])\n",
      "--> Potential meaningful keywords for the sentence: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Man of the Match, the Match, match, Match, The Match, name, Man, man, Named, Name, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (the Match, ['Q3224390', 'Q688474'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 60.16s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P155': 3, 'P156': 3, 'P1448': 1, 'P734': 1, 'P31': 16, 'P1013': 1, 'P407': 5, 'P443': 1, 'P856': 2, 'P1559': 1, 'P585': 1, 'P1449': 1, 'P364': 3, 'P571': 2, 'P3085': 1, 'P495': 4, 'P5138': 1, 'P1350': 1, 'P54': 4, 'P186': 3, 'P2563': 3, 'P577': 2, 'P2888': 2, 'P1476': 2, 'P361': 1, 'P282': 2, 'P1705': 2, 'P3450': 1, 'P264': 1, 'P2348': 1, 'P910': 1, 'P664': 1, 'P1433': 1, 'P27': 1, 'P641': 4, 'P373': 1, 'P1431': 3, 'P463': 1, 'P57': 1, 'P935': 1, 'P921': 1, 'P136': 1, 'P575': 1, 'P175': 1, 'P449': 1, 'P162': 1, 'P462': 1, 'P527': 1, 'P86': 1, 'P580': 4, 'P582': 3, 'P286': 4}\n",
      "-> paths_keywords: (['man of the match', 'match', 'the match', 'name', 'man', '2006–07 uefa champions league', 'a.c. milan'], {'winner': [winner, ['P1346']], 'instance of': [instance of, ['P31']], 'named as': [named as, ['P1810']], 'given name': [given name, ['P735']], 'name': [name, ['P2561']], 'Name': [given name, ['P735']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 180.54s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.42s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.14s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who was named Man of the Match?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was named Man of the Match \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who named Man of the Match\n",
      "-> q_themes: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was named Man])\n",
      "-> q_themes_enhanced: [('man', ['Q12656568']), ('Named', ['Q6961550']), ('Name', ['Q11236330', 'P735'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "-> q_predicates \tRunning time is 4.79s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "----> q_themes in context: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was])\n",
      "--> Potential meaningful keywords for the sentence: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Man of the Match, the Match, match, Match, The Match, name, Man, man, Named, Name, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (the Match, ['Q3224390', 'Q688474'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 57.26s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P155': 3, 'P156': 3, 'P1448': 1, 'P734': 1, 'P31': 16, 'P1013': 1, 'P407': 5, 'P443': 1, 'P856': 2, 'P1559': 1, 'P585': 1, 'P1449': 1, 'P364': 3, 'P571': 2, 'P3085': 1, 'P495': 4, 'P5138': 1, 'P1350': 1, 'P54': 4, 'P186': 3, 'P2563': 3, 'P577': 2, 'P2888': 2, 'P1476': 2, 'P361': 1, 'P282': 2, 'P1705': 2, 'P3450': 1, 'P264': 1, 'P2348': 1, 'P910': 1, 'P664': 1, 'P27': 1, 'P1433': 1, 'P641': 4, 'P373': 1, 'P1431': 3, 'P921': 1, 'P57': 1, 'P935': 1, 'P136': 1, 'P463': 1, 'P575': 1, 'P175': 1, 'P449': 1, 'P462': 1, 'P527': 1, 'P162': 1, 'P580': 4, 'P86': 1, 'P582': 3, 'P286': 4}\n",
      "-> paths_keywords: (['man of the match', 'match', 'the match', 'name', 'man', '2006–07 uefa champions league', 'a.c. milan'], {'winner': [winner, ['P1346']], 'instance of': [instance of, ['P31']], 'named as': [named as, ['P1810']], 'given name': [given name, ['P735']], 'name': [name, ['P2561']], 'Name': [given name, ['P735']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 186.63s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.71s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 256.48s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who was named Man of the Match?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was named Man of the Match \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was named Man of the Match\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was named Man])\n",
      "-> q_themes_enhanced: [('man', ['Q12656568']), ('Named', ['Q6961550']), ('Name', ['Q11236330', 'P735'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "-> q_predicates \tRunning time is 5.18s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (be, ['P31']), (named, ['P1810']), (name, [])]\n",
      "----> q_themes in context: ([(Man of the Match, ['Q18809391', 'Q1378679']), (the Match, ['Q3224390', 'Q688474']), (match, ['Q37507']), (Match, ['Q1778900', 'Q15766502']), (The Match, ['Q44874961']), (name, ['Q82799', 'P2561']), (Man, ['Q8441', 'Q12594770'])], [was])\n",
      "--> Potential meaningful keywords for the sentence: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Man of the Match', 'the Match', 'match', 'Match', 'The Match', 'name', 'Man', 'man', 'Named', 'Name', 'Won', 'given name has to use a different item than disambiguation pages', 'So-won', 'Won']\n",
      "meaningful_names_no_previous_answer [Man of the Match, the Match, match, Match, The Match, name, Man, man, Named, Name, Won, given name has to use a different item than disambiguation pages, So won, Won]\n",
      "----> Meaningful keywords casted as theme ([(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348'])], [])\n",
      "q_focused_parts: [(Man of the Match, ['Q18809391']), (match, ['Q37507']), (Match, ['Q15766502', 'Q1778900']), (The Match, ['Q688474', 'Q3224390', 'Q44874961']), (name, ['P2561']), (Man, ['Q12594770']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (the Match, ['Q3224390', 'Q688474'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 26.62s\n",
      "-->  22 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 22 nodes and 22 edges\n",
      "-> predicates_dict: {'P1013': 5, 'P527': 15, 'P155': 3, 'P156': 2, 'P735': 2, 'P31': 15, 'P734': 1, 'P407': 3, 'P443': 1, 'P1559': 1, 'P186': 3, 'P364': 3, 'P495': 4, 'P175': 1, 'P2563': 3, 'P577': 3, 'P2888': 2, 'P1476': 2, 'P361': 1, 'P1240': 1, 'P282': 3, 'P1705': 3, 'P264': 1, 'P279': 1, 'P910': 1, 'P1433': 1, 'P27': 1, 'P17': 1, 'P1431': 3, 'P463': 1, 'P921': 1, 'P57': 1, 'P625': 1, 'P136': 1, 'P575': 1, 'P935': 1, 'P641': 1, 'P449': 1, 'P462': 1}\n",
      "-> paths_keywords: (['man of the match', 'match', 'the match', 'name', 'man', 'won'], {'criterion used': [criterion used, ['P1013']], 'instance of': [instance of, ['P31']], 'named as': [named as, ['P1810']], 'given name': [given name, ['P735']], 'name': [name, ['P2561']], 'Name': [given name, ['P735']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 148\n",
      "->Computing possible paths \tRunning time is 56.42s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 102\n",
      "->\tRunning time is 3.69s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q23765057', 6.127676410635351], ['Q9176', 3.812495240403642], ['Q42652077', 1.61332891377895], ['Q18210311', 1.2255749709139796]]\n",
      "->Computing hypothesises \tRunning time is 101.09s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 13\n",
      "->\tRunning time is 6.46s\n",
      "--> len(cleared_golden_paths): 6\n",
      "---> First path: ['Q23765057', 'P1013', 'Q20080348', 'P407', 'Q9176']\n",
      "->\tTotal Running time is 203.38s\n",
      "\n",
      "df_graphqa Q23765057\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question  \\\n",
      "239             525    3       False  Who was named Man of the Match?   \n",
      "\n",
      "      answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "239  Q184586  soccer   False         60.31         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr    graphqa  \\\n",
      "239           1.64          0.0  False       506.67        0.0  Q23765057   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "239         203.8        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "239          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-240-ic525-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 526/2240 -> 4/5 -> Convex=True: (Q184586) Who was named Man of the Match?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q60\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex http://www.acmilan.com/\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q12586160\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question  \\\n",
      "240             525    3        True  Who was named Man of the Match?   \n",
      "\n",
      "      answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "240  Q184586  soccer     Q60           0.0         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr                   convex  convex_time  \\\n",
      "240           9.41          0.0  http://www.acmilan.com/         1.89   \n",
      "\n",
      "     convex_rr    graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "240        0.0  Q12586160          0.09        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "240        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-241-ic525-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 20:54:28.725503\n",
      "\t>>> Processing 526/2240 -> 5/5 -> Convex=False: (Q25) What's Bale's nation of origin?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What's Bale's nation of origin?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Bale nation of origin \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is Bale nation of origin\n",
      "-> q_themes: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale nation, Bale Origin, Origin Bale, is Bale, Bale Nation, bale nation])\n",
      "-> q_themes_enhanced: [('nation', ['Q597897']), ('Nation', ['Q1418711'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: origin\n",
      "-> q_predicates: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "-> q_predicates \tRunning time is 11.54s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "----> q_themes in context: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale, Origin, is, bale])\n",
      "--> Potential meaningful keywords for the sentence: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation', 'New York City']\n",
      "meaningful_names_no_previous_answer [Bale, origin, what, bale, What, Origin, nation, Nation, New York City]\n",
      "----> Meaningful keywords casted as theme ([(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (Bale, ['Q519226', 'Q804880']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 23.67s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What's Bale's nation of origin?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Bale nation of origin \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What Bale nation of origin\n",
      "-> q_themes: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale nation, Bale Origin, Origin Bale, is Bale, Bale Nation, bale nation])\n",
      "-> q_themes_enhanced: [('nation', ['Q597897']), ('Nation', ['Q1418711'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: origin\n",
      "-> q_predicates: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "-> q_predicates \tRunning time is 9.06s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "----> q_themes in context: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale, Origin, is, bale])\n",
      "--> Potential meaningful keywords for the sentence: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation', 'New York City']\n",
      "meaningful_names_no_previous_answer [Bale, origin, what, bale, What, Origin, nation, Nation, New York City]\n",
      "----> Meaningful keywords casted as theme ([(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043'])], [])\n",
      "q_focused_parts: [(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (New York City, ['Q16998793', 'Q1200081', 'Q20496043']), (Bale, ['Q519226', 'Q804880']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.84s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What's Bale's nation of origin?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Bale nation of origin \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is Bale nation of origin\n",
      "-> q_themes: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale nation, Bale Origin, Origin Bale, is Bale, Bale Nation, bale nation])\n",
      "-> q_themes_enhanced: [('nation', ['Q597897']), ('Nation', ['Q1418711'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: origin\n",
      "-> q_predicates: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "-> q_predicates \tRunning time is 9.19s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "----> q_themes in context: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale, Origin, is, bale])\n",
      "--> Potential meaningful keywords for the sentence: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation', '2006–07 UEFA Champions League', 'A.C. Milan']\n",
      "meaningful_names_no_previous_answer [Bale, origin, what, bale, What, Origin, nation, Nation, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Bale, ['Q519226', 'Q804880']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 62.18s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P155': 3, 'P156': 4, 'P527': 1, 'P31': 49, 'P5051': 1, 'P81': 2, 'P197': 2, 'P833': 1, 'P17': 3, 'P281': 1, 'P969': 1, 'P159': 1, 'P373': 3, 'P571': 4, 'P407': 3, 'P856': 3, 'P518': 3, 'P186': 1, 'P580': 6, 'P1435': 1, 'P582': 4, 'P585': 1, 'P361': 1, 'P664': 1, 'P131': 1, 'P3085': 1, 'P5138': 1, 'P1344': 1, 'P1103': 1, 'P577': 3, 'P348': 2, 'P54': 4, 'P195': 1, 'P217': 1, 'P276': 1, 'P366': 1, 'P641': 3, 'P3450': 1, 'P2348': 1, 'P2184': 1, 'P3279': 1, 'P138': 1, 'P3744': 1, 'P2002': 1, 'P1545': 2, 'P4908': 1, 'P910': 1, 'P306': 1, 'P1619': 1, 'P58': 1, 'P275': 1, 'P179': 1, 'P286': 4, 'P170': 1}\n",
      "-> paths_keywords: (['origin', 'bale', 'what', '2006–07 uefa champions league', 'a.c. milan', 'nation'], {'winner': [winner, ['P1346']], 'instance of': [instance of, ['P31']], 'country of citizenship': [country of citizenship, ['P27']], 'US National Archives Identifier': [US National Archives Identifier, ['P1225']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 182.65s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.99s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What's Bale's nation of origin?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Bale nation of origin \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What Bale nation of origin\n",
      "-> q_themes: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale nation, Bale Origin, Origin Bale, is Bale, Bale Nation, bale nation])\n",
      "-> q_themes_enhanced: [('nation', ['Q597897']), ('Nation', ['Q1418711'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: origin\n",
      "-> q_predicates: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "-> q_predicates \tRunning time is 9.06s\n",
      "--> Predicates enhanced by previous context: [(winner, ['P1346']), (be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "----> q_themes in context: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale, Origin, is, bale])\n",
      "--> Potential meaningful keywords for the sentence: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation', '2006–07 UEFA Champions League', 'A.C. Milan']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Bale, origin, what, bale, What, Origin, nation, Nation, 2006–07 UEFA Champions League, A.C. Milan]\n",
      "----> Meaningful keywords casted as theme ([(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277'])], [])\n",
      "q_focused_parts: [(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (2006–07 UEFA Champions League, ['Q192736']), (A.C. Milan, ['Q1543', 'Q3857792', 'Q2753277']), (Bale, ['Q519226', 'Q804880']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 62.16s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P1346': 9, 'P155': 3, 'P156': 4, 'P527': 1, 'P31': 49, 'P5051': 1, 'P81': 2, 'P197': 2, 'P833': 1, 'P17': 3, 'P281': 1, 'P969': 1, 'P159': 1, 'P373': 3, 'P571': 4, 'P407': 3, 'P856': 3, 'P518': 3, 'P186': 1, 'P580': 6, 'P1435': 1, 'P582': 4, 'P585': 1, 'P361': 1, 'P664': 1, 'P131': 1, 'P3085': 1, 'P5138': 1, 'P1344': 1, 'P1103': 1, 'P577': 3, 'P348': 2, 'P54': 4, 'P195': 1, 'P217': 1, 'P276': 1, 'P366': 1, 'P641': 3, 'P3450': 1, 'P2348': 1, 'P2184': 1, 'P3279': 1, 'P138': 1, 'P3744': 1, 'P2002': 1, 'P1545': 2, 'P4908': 1, 'P910': 1, 'P306': 1, 'P1619': 1, 'P275': 1, 'P58': 1, 'P179': 1, 'P286': 4, 'P170': 1}\n",
      "-> paths_keywords: (['origin', 'bale', 'what', '2006–07 uefa champions league', 'a.c. milan', 'nation'], {'winner': [winner, ['P1346']], 'instance of': [instance of, ['P31']], 'country of citizenship': [country of citizenship, ['P27']], 'US National Archives Identifier': [US National Archives Identifier, ['P1225']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 184.01s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 262.55s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What's Bale's nation of origin?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is Bale nation of origin \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is Bale nation of origin\n",
      "-> q_themes: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale nation, Bale Origin, Origin Bale, is Bale, Bale Nation, bale nation])\n",
      "-> q_themes_enhanced: [('nation', ['Q597897']), ('Nation', ['Q1418711'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: origin\n",
      "-> q_predicates: [(be, ['P31']), (nation, ['P27', 'P1225']), (origin, [])]\n",
      "-> q_predicates \tRunning time is 9.26s\n",
      "--> Predicates enhanced by previous context: [(criterion used, ['P1013']), (be, ['P31']), (nation, ['P27', 'P1225']), (origin, []), (language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Bale, ['Q519226', 'Q804880']), (origin, ['Q40735', 'Q3885844']), (what, ['Q20656446', 'Q28036789']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920']), (Origin, ['Q1307239', 'Q12046668'])], [Bale, Origin, is, bale])\n",
      "--> Potential meaningful keywords for the sentence: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation']\n",
      "---> Meaningful keywords enhanced by previous context: ['Bale', 'origin', 'what', 'bale', 'What', 'Origin', 'nation', 'Nation', 'Won', 'given name has to use a different item than disambiguation pages', 'Won', 'Korean language', 'So-won']\n",
      "meaningful_names_no_previous_answer [Bale, origin, what, bale, What, Origin, nation, Nation, Won, given name has to use a different item than disambiguation pages, Won, Korean language, So won]\n",
      "----> Meaningful keywords casted as theme ([(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Korean language, ['Q9176'])], [])\n",
      "q_focused_parts: [(origin, ['Q40735', 'Q3885844']), (bale, ['Q805183', 'Q805181']), (What, ['Q22073920', 'Q28036789']), (Origin, ['Q1307239', 'Q12046668']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (given name has to use a different item than disambiguation pages, ['Q23765057']), (Won, ['Q34933625', 'Q16967828', 'Q20080348']), (Korean language, ['Q9176']), (Bale, ['Q519226', 'Q804880']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 27.38s\n",
      "-->  21 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 21 nodes and 20 edges\n",
      "-> predicates_dict: {'P1013': 4, 'P407': 4, 'P527': 19, 'P155': 2, 'P156': 4, 'P31': 48, 'P5051': 3, 'P81': 3, 'P197': 4, 'P833': 1, 'P571': 2, 'P17': 3, 'P518': 3, 'P186': 2, 'P580': 2, 'P1435': 1, 'P582': 1, 'P361': 1, 'P282': 1, 'P1705': 1, 'P373': 2, 'P577': 4, 'P348': 2, 'P195': 1, 'P217': 1, 'P276': 1, 'P366': 1, 'P131': 1, 'P175': 1, 'P1103': 1, 'P856': 1, 'P138': 1, 'P625': 1, 'P1545': 2, 'P179': 1, 'P4908': 1, 'P275': 1, 'P306': 1, 'P3610': 1}\n",
      "-> paths_keywords: (['origin', 'bale', 'what', 'won', 'korean language', 'nation'], {'criterion used': [criterion used, ['P1013']], 'instance of': [instance of, ['P31']], 'country of citizenship': [country of citizenship, ['P27']], 'US National Archives Identifier': [US National Archives Identifier, ['P1225']], 'language of work or name': [language of work or name, ['P407']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 132\n",
      "->Computing possible paths \tRunning time is 57.25s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 66\n",
      "->\tRunning time is 3.72s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q23765057', 6.646362234662703], ['Q202444', 2.052015126276327], ['Q18210311', 1.646634298471176], ['Q1417633', 0.8575332559378941], ['Q16255585', 0.826482952758667], ['Q16255978', 0.5030745926450158], ['Q8222', -0.00893725125623135]]\n",
      "->Computing hypothesises \tRunning time is 84.82s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 21\n",
      "->\tRunning time is 6.66s\n",
      "--> len(cleared_golden_paths): 13\n",
      "---> First path: ['Q23765057', 'P1013', 'Q20080348', 'P31', 'Q202444']\n",
      "->\tTotal Running time is 193.03s\n",
      "\n",
      "df_graphqa Q23765057\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "241             525    4       False  What's Bale's nation of origin?    Q25   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "241  soccer   False         68.57         0.0    False           0.88   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "241          0.0  False       521.52        0.0  Q23765057        193.42   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "241        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "241         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-242-ic525-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 526/2240 -> 5/5 -> Convex=True: (Q25) What's Bale's nation of origin?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q60\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q1543\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q884\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "242             525    4        True  What's Bale's nation of origin?    Q25   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "242  soccer     Q60           0.0         0.0    False           0.88   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "242          0.0  Q1543         2.03        0.0    Q884          0.13   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "242        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "242         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-243-ic525-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 21:07:36.225436\n",
      "\t>>> Processing 527/2240 -> 1/5 -> Convex=False: (Q13417189) Who was the director of the movie Interstellar?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q25191\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who was the director of the movie Interstellar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the director of the movie Interstellar \n",
      "-> q_themes: ([(the director, ['Q50078600']), (the movie, ['Q7752538', 'Q16955125']), (Interstellar, ['Q13417189', 'Q3153615']), (The Director, ['Q42531725', 'Q26883246']), (director, ['P57', 'Q1162163'])], [was the director of the movie Interstellar, The Movie Interstellar, movie Interstellar, the Movie Interstellar])\n",
      "-> q_themes_enhanced: [('Movie', ['Q2512663']), ('The Movie', ['Q16955125'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 7.58s\n",
      "--> Potential meaningful keywords for the sentence: ['the director', 'the movie', 'Interstellar', 'The Director', 'director', 'Movie', 'The Movie']\n",
      "q_focused_parts: [(movie, ['Q11424']), (Interstellar, ['Q13417189', 'Q21186666'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 64.54s\n",
      "-->  160 nodes and 164 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 160 nodes and 164 edges\n",
      "-> predicates_dict: {'P57': 2, 'P155': 4, 'P156': 4, 'P527': 1, 'P31': 15, 'P136': 1, 'P1431': 1, 'P2453': 11, 'P805': 1, 'P1411': 5, 'P1441': 2, 'P175': 3, 'P364': 1, 'P921': 1, 'P361': 1, 'P58': 1, 'P2388': 3, 'P1545': 4, 'P4908': 2, 'P3831': 1, 'P3092': 1, 'P291': 4, 'P577': 3, 'P642': 1, 'P279': 1, 'P21': 2, 'P179': 2, 'P2868': 3, 'P495': 1}\n",
      "-> paths_keywords: (['movie', 'interstellar', 'director', 'the movie', 'the movie interstellar', 'the director', 'film'], {'instance of': [instance of, ['P31']], 'director': [director, ['P57']], 'manager/director': [manager  director, ['P1037']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 304\n",
      "->Computing possible paths \tRunning time is 42.38s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 250\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7815268', 14.464805044114234], ['Q25191', 13.739655335978657], ['Q291731', 2.329200265161948], ['Q18661829', 0.7033679280116425], ['Q39613326', 0.2894327504655309], ['Q2059621', 0.21588174227412774]]\n",
      "->Computing hypothesises \tRunning time is 35.32s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 6.29s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q7815268', 'P57', 'Q7752538', 'P31', 'Q21191270', 'P31', 'Q50078600', 'P155', 'Q50078603']\n",
      "->\tTotal Running time is 164.47s\n",
      "\n",
      "df_graphqa Q7815268\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "243             526    0       False   \n",
      "\n",
      "                                            question     answer  domain  \\\n",
      "243  Who was the director of the movie Interstellar?  Q13417189  movies   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "243   False          0.68         0.0    False           0.51          0.0   \n",
      "\n",
      "     convex  convex_time  convex_rr   graphqa  graphqa_time graphqa_top2  \\\n",
      "243  Q25191         1.79        0.0  Q7815268        164.72        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "243        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-244-ic526-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 21:10:23.952090\n",
      "\t>>> Processing 527/2240 -> 2/5 -> Convex=False: (Q188955) Who is the main charceter in the movie                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who is the main charceter in the movie\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the main charceter in the movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who is the main charceter in the movie\n",
      "-> q_themes: ([(the movie, ['Q7752538', 'Q16955125'])], [the main charceter, The Main Charceter, main charceter, the main Charceter])\n",
      "-> q_themes_enhanced: [('main', ['Q3278265']), ('The Main', ['Q24025978']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: charceter\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (main, ['P921', 'P301']), (charceter, []), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.18s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (main, ['P921', 'P301']), (charceter, [])]\n",
      "----> q_themes in context: ([(the movie, ['Q7752538', 'Q16955125'])], [the, The, main])\n",
      "--> Potential meaningful keywords for the sentence: ['the movie', 'main', 'The Main', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['the movie', 'main', 'The Main', 'Main', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [the movie, main, The Main, Main, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.78s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P921': 2, 'P910': 1, 'P106': 4, 'P2453': 10, 'P805': 4, 'P1411': 7, 'P1686': 3, 'P1431': 1, 'P373': 1, 'P131': 3, 'P361': 1, 'P31': 6, 'P364': 1, 'P580': 1, 'P1435': 1, 'P2363': 1, 'P735': 1, 'P3831': 1, 'P3092': 1, 'P642': 1, 'P111': 1, 'P585': 1, 'P166': 1, 'P264': 1, 'P291': 2, 'P577': 2, 'P138': 1, 'P625': 1, 'P175': 1, 'P734': 1, 'P136': 1, 'P1039': 2, 'P1038': 2, 'P1040': 1, 'P155': 1, 'P156': 1, 'P1050': 1}\n",
      "-> paths_keywords: (['interstellar', 'christopher nolan', 'the movie', 'charceter'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 161.71s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.5s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.11s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who is the main charceter in the movie\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the main charceter in the movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who director the main charceter in the movie\n",
      "-> q_themes: ([(the movie, ['Q7752538', 'Q16955125'])], [the main charceter, The Main Charceter, main charceter, the main Charceter])\n",
      "-> q_themes_enhanced: [('main', ['Q3278265']), ('The Main', ['Q24025978']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: charceter\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (main, ['P921', 'P301']), (charceter, []), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.28s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (main, ['P921', 'P301']), (charceter, [])]\n",
      "----> q_themes in context: ([(the movie, ['Q7752538', 'Q16955125'])], [the, The, main])\n",
      "--> Potential meaningful keywords for the sentence: ['the movie', 'main', 'The Main', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['the movie', 'main', 'The Main', 'Main', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [the movie, main, The Main, Main, Interstellar, Christopher Nolan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Meaningful keywords casted as theme ([(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.52s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P921': 2, 'P910': 1, 'P106': 4, 'P2453': 10, 'P805': 4, 'P1411': 7, 'P1686': 3, 'P1431': 1, 'P373': 1, 'P131': 3, 'P361': 1, 'P31': 6, 'P364': 1, 'P580': 1, 'P1435': 1, 'P2363': 1, 'P735': 1, 'P3831': 1, 'P3092': 1, 'P642': 1, 'P111': 1, 'P585': 1, 'P166': 1, 'P264': 1, 'P291': 2, 'P577': 2, 'P138': 1, 'P625': 1, 'P175': 1, 'P734': 1, 'P136': 1, 'P1039': 2, 'P1038': 2, 'P1040': 1, 'P155': 1, 'P156': 1, 'P1050': 1}\n",
      "-> paths_keywords: (['interstellar', 'christopher nolan', 'the movie', 'director'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.75s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.46s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 188.39s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who is the main charceter in the movie\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the main charceter in the movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who is the main charceter in the movie\n",
      "-> q_themes: ([(the movie, ['Q7752538', 'Q16955125'])], [the main charceter, The Main Charceter, main charceter, the main Charceter])\n",
      "-> q_themes_enhanced: [('main', ['Q3278265']), ('The Main', ['Q24025978']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: charceter\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (main, ['P921', 'P301']), (charceter, []), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.03s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (main, ['P921', 'P301']), (charceter, []), (follows, ['P155'])]\n",
      "----> q_themes in context: ([(the movie, ['Q7752538', 'Q16955125'])], [the, main])\n",
      "--> Potential meaningful keywords for the sentence: ['the movie', 'main', 'The Main', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['the movie', 'main', 'The Main', 'Main', 'The Movie', 'The Director', 'Tom Cherones', 'The Director: Conclusion', 'TV series episode']\n",
      "meaningful_names_no_previous_answer [the movie, main, The Main, Main, The Movie, The Director, Tom Cherones, The Director Conclusion, TV series episode]\n",
      "----> Meaningful keywords casted as theme ([(The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (Tom Cherones, ['Q7815268']), (TV series episode, ['Q21191270'])], [])\n",
      "q_focused_parts: [(The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (Tom Cherones, ['Q7815268']), (TV series episode, ['Q21191270']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.47s\n",
      "-->  19 nodes and 24 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 24 edges\n",
      "-> predicates_dict: {'P57': 81, 'P155': 7, 'P156': 8, 'P31': 12, 'P106': 2, 'P1441': 2, 'P175': 3, 'P527': 1, 'P373': 1, 'P131': 3, 'P735': 1, 'P19': 1, 'P361': 1, 'P580': 1, 'P1435': 1, 'P58': 1, 'P1545': 6, 'P4908': 3, 'P642': 2, 'P111': 1, 'P69': 1, 'P166': 1, 'P138': 1, 'P495': 1, 'P179': 3, 'P625': 1, 'P21': 2}\n",
      "-> paths_keywords: (['the movie', 'the director', 'tom cherones', 'tv series episode', 'charceter'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'follows': [follows, ['P155']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 284\n",
      "->Computing possible paths \tRunning time is 13.55s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 284\n",
      "->\tRunning time is 3.65s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7757033', 3.2301919708355467], ['Q7772854', 2.9120212397998806]]\n",
      "->Computing hypothesises \tRunning time is 52.45s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 6.96s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q7757033', 'P155', 'Q7752538', 'P57', 'Q7815268']\n",
      "->\tTotal Running time is 110.11s\n",
      "\n",
      "df_graphqa Q7757033\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                                question  \\\n",
      "244             526    1       False  Who is the main charceter in the movie   \n",
      "\n",
      "      answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "244  Q188955  movies   False          0.75         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr   graphqa  \\\n",
      "244           1.43          0.0  False       393.52        0.0  Q7757033   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "244        110.36        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "244          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-245-ic526-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 527/2240 -> 2/5 -> Convex=True: (Q188955) Who is the main charceter in the movie                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q834826\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1993-01-06T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                                question  \\\n",
      "245             526    1        True  Who is the main charceter in the movie   \n",
      "\n",
      "      answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "245  Q188955  movies   False          0.74         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr   convex  convex_time  convex_rr  \\\n",
      "245           1.58          0.0  Q834826         0.62        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "245  1993-01-06T00:00:00Z           0.2        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "245        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-246-ic526-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 21:18:53.191993\n",
      "\t>>> Processing 527/2240 -> 3/5 -> Convex=False: (Q188955) What movie type is this?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q10301427\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What movie type is this?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What movie type is this \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What movie type is this\n",
      "-> q_themes: ([], [What movie type, Movie Type, movie type, what Movie Type])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('type', ['Q1325930']), ('Movie', ['Q2512663']), ('Type', ['Q2463013'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "behold: get_most_similar started with: type\n",
      "-> q_predicates: [(be, ['P31']), (movie, ['P57']), (type, ['P427'])]\n",
      "-> q_predicates \tRunning time is 5.66s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (type, ['P427'])]\n",
      "----> q_themes in context: ([(, [])], [What, Movie, movie, what])\n",
      "--> Potential meaningful keywords for the sentence: ['movie', 'type', 'Movie', 'Type']\n",
      "---> Meaningful keywords enhanced by previous context: ['movie', 'type', 'Movie', 'Type', 'Interstellar', 'Christopher Nolan']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [movie, type, Movie, Type, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.89s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P106': 5, 'P1431': 1, 'P1039': 2, 'P1038': 2, 'P2453': 6, 'P805': 3, 'P1411': 5, 'P1686': 2, 'P123': 1, 'P1433': 1, 'P407': 1, 'P973': 1, 'P364': 1, 'P921': 2, 'P31': 5, 'P361': 1, 'P3831': 1, 'P3092': 1, 'P4810': 4, 'P735': 1, 'P264': 1, 'P291': 2, 'P577': 3, 'P69': 1, 'P2363': 1, 'P175': 1, 'P1412': 1, 'P462': 1, 'P734': 1, 'P136': 1}\n",
      "-> paths_keywords: (['interstellar', 'christopher nolan'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'taxonomic type': [taxonomic type, ['P427']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 127.62s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.68s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What movie type is this?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What movie type is this \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What movie type this\n",
      "-> q_themes: ([], [What movie type, Movie Type, movie type, what Movie Type])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('type', ['Q1325930']), ('Movie', ['Q2512663']), ('Type', ['Q2463013'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "behold: get_most_similar started with: type\n",
      "-> q_predicates: [(be, ['P31']), (movie, ['P57']), (type, ['P427'])]\n",
      "-> q_predicates \tRunning time is 4.67s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (type, ['P427'])]\n",
      "----> q_themes in context: ([(, [])], [What, Movie, movie, what])\n",
      "--> Potential meaningful keywords for the sentence: ['movie', 'type', 'Movie', 'Type']\n",
      "---> Meaningful keywords enhanced by previous context: ['movie', 'type', 'Movie', 'Type', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [movie, type, Movie, Type, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.31s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P106': 5, 'P1431': 1, 'P1039': 2, 'P1038': 2, 'P2453': 6, 'P805': 3, 'P1411': 5, 'P1686': 2, 'P123': 1, 'P1433': 1, 'P407': 1, 'P973': 1, 'P364': 1, 'P921': 2, 'P31': 5, 'P361': 1, 'P3831': 1, 'P3092': 1, 'P4810': 4, 'P735': 1, 'P264': 1, 'P291': 2, 'P577': 3, 'P69': 1, 'P2363': 1, 'P175': 1, 'P1412': 1, 'P734': 1, 'P462': 1, 'P136': 1}\n",
      "-> paths_keywords: (['interstellar', 'christopher nolan'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'taxonomic type': [taxonomic type, ['P427']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 126.53s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 170.55s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What movie type is this?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What movie type is this \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What movie type is this\n",
      "-> q_themes: ([], [What movie type, Movie Type, movie type, what Movie Type])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('type', ['Q1325930']), ('Movie', ['Q2512663']), ('Type', ['Q2463013'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "behold: get_most_similar started with: type\n",
      "-> q_predicates: [(be, ['P31']), (movie, ['P57']), (type, ['P427'])]\n",
      "-> q_predicates \tRunning time is 4.55s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (be, ['P31']), (type, ['P427']), (follows, ['P155'])]\n",
      "----> q_themes in context: ([(The Pick, ['Q7757033'])], [What, movie])\n",
      "--> Potential meaningful keywords for the sentence: ['The Pick', 'movie', 'type', 'Movie', 'Type']\n",
      "---> Meaningful keywords enhanced by previous context: ['The Pick', 'movie', 'type', 'Movie', 'Type', 'The Movie', 'Tom Cherones', 'The Pick', 'The Director', 'The Director: Conclusion', 'TV series episode']\n",
      "meaningful_names_no_previous_answer [The Pick, movie, type, Movie, Type, The Movie, Tom Cherones, The Pick, The Director, The Director Conclusion, TV series episode]\n",
      "----> Meaningful keywords casted as theme ([(The Pick, ['Q7757033']), (The Movie, ['Q16955125', 'Q7752538']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270'])], [])\n",
      "q_focused_parts: [(The Pick, ['Q7757033']), (The Movie, ['Q16955125', 'Q7752538']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.82s\n",
      "-->  38 nodes and 50 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 38 nodes and 50 edges\n",
      "-> predicates_dict: {'P57': 136, 'P155': 8, 'P156': 11, 'P31': 11, 'P106': 2, 'P1441': 2, 'P175': 3, 'P123': 1, 'P1433': 1, 'P407': 1, 'P973': 1, 'P527': 2, 'P735': 1, 'P19': 1, 'P361': 1, 'P58': 1, 'P1545': 6, 'P4908': 3, 'P4810': 4, 'P642': 1, 'P69': 1, 'P166': 1, 'P2364': 2, 'P21': 2, 'P495': 1, 'P179': 3, 'P577': 2}\n",
      "-> paths_keywords: (['the pick', 'the movie', 'tom cherones', 'the director', 'tv series episode'], {'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'taxonomic type': [taxonomic type, ['P427']], 'follows': [follows, ['P155']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 30.98s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 9792\n",
      "->\tRunning time is 15.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q23733', 8.270576435265795], ['Q7712939', 4.257318516720784], ['Q7772854', 3.2384494803761177]]\n",
      "->Computing hypothesises \tRunning time is 69.29s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 83\n",
      "->\tRunning time is 27.6s\n",
      "--> len(cleared_golden_paths): 63\n",
      "---> First path: ['Q7815268', 'P57', 'Q23733', 'P179', 'Q7757033', 'P1545', '53']\n",
      "->\tTotal Running time is 175.71s\n",
      "\n",
      "df_graphqa Q23733\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question   answer  \\\n",
      "246             526    2       False  What movie type is this?  Q188955   \n",
      "\n",
      "     domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "246  movies  Q10301427          0.59         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "246          0.0  False       340.15        0.0  Q23733        175.93   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "246        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "246         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-247-ic526-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 527/2240 -> 3/5 -> Convex=True: (Q188955) What movie type is this?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q10301427\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex v576585\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q7752538\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question   answer  \\\n",
      "247             526    2        True  What movie type is this?  Q188955   \n",
      "\n",
      "     domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "247  movies  Q10301427           0.0         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr   graphqa  graphqa_time  \\\n",
      "247          0.0  v576585         0.42        0.0  Q7752538          0.12   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "247        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "247         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-248-ic526-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 21:27:30.817023\n",
      "\t>>> Processing 527/2240 -> 4/5 -> Convex=False: (Q76364) Who made the movie's music?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who made the movie's music?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who made the movie music \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who made the movie music\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the movie music, Music Movie, The Movie Music, the Movie Music])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('The Movie', ['Q16955125']), ('The Music', ['Q1807651'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(made, ['P186'])]\n",
      "-> q_predicates \tRunning time is 5.33s\n",
      "--> Predicates enhanced by previous context: [(made, ['P186'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the, Music, The])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music', '']\n",
      "meaningful_names_no_previous_answer [Movie, music, Music, movie, The Movie, The Music]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 17.97s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who made the movie's music?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who made the movie music \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who made the movie music\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the movie music, Music Movie, The Movie Music, the Movie Music])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('The Movie', ['Q16955125']), ('The Music', ['Q1807651'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(made, ['P186']), (movie, ['P57']), (music, ['P136'])]\n",
      "-> q_predicates \tRunning time is 5.36s\n",
      "--> Predicates enhanced by previous context: [(made, ['P186']), (movie, ['P57']), (music, ['P136'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the, Music, The])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music', '']\n",
      "meaningful_names_no_previous_answer [Movie, music, Music, movie, The Movie, The Music]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.67s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who made the movie's music?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who made the movie music \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who made the movie music\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the movie music, Music Movie, The Movie Music, the Movie Music])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('The Movie', ['Q16955125']), ('The Music', ['Q1807651'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(made, ['P186'])]\n",
      "-> q_predicates \tRunning time is 5.36s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (made, ['P186'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the, Music, The])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [Movie, music, Music, movie, The Movie, The Music, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.17s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P57': 14, 'P106': 4, 'P1431': 1, 'P364': 1, 'P2453': 6, 'P805': 4, 'P1411': 6, 'P1686': 3, 'P1552': 1, 'P571': 1, 'P361': 3, 'P31': 9, 'P131': 1, 'P156': 2, 'P136': 3, 'P175': 7, 'P735': 1, 'P577': 3, 'P264': 2, 'P3831': 1, 'P3092': 1, 'P291': 2, 'P17': 1, 'P740': 1, 'P155': 2, 'P856': 1, 'P452': 1, 'P734': 1, 'P1039': 2, 'P1038': 2, 'P495': 1}\n",
      "-> paths_keywords: (['movie', 'music', 'interstellar', 'christopher nolan'], {'director': [director, ['P57']], 'material used': [material used, ['P186']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 124.57s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.29s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who made the movie's music?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who made the movie music \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who made the movie music\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the movie music, Music Movie, The Movie Music, the Movie Music])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('The Movie', ['Q16955125']), ('The Music', ['Q1807651'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(made, ['P186']), (movie, ['P57']), (music, ['P136'])]\n",
      "-> q_predicates \tRunning time is 5.5s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (made, ['P186']), (music, ['P136'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the, Music, The])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [Movie, music, Music, movie, The Movie, The Music, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.08s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P57': 14, 'P136': 7, 'P264': 3, 'P155': 2, 'P156': 2, 'P175': 7, 'P106': 4, 'P1431': 1, 'P31': 9, 'P364': 1, 'P2453': 7, 'P805': 4, 'P1411': 7, 'P1686': 3, 'P1552': 1, 'P86': 1, 'P571': 1, 'P361': 3, 'P131': 1, 'P971': 2, 'P735': 1, 'P291': 4, 'P577': 4, 'P3831': 1, 'P3092': 1, 'P910': 1, 'P17': 2, 'P750': 1, 'P495': 1, 'P1412': 1, 'P740': 1, 'P1039': 2, 'P1038': 2, 'P856': 1, 'P452': 1, 'P734': 1}\n",
      "-> paths_keywords: (['movie', 'music', 'interstellar', 'christopher nolan'], {'director': [director, ['P57']], 'material used': [material used, ['P186']], 'genre': [genre, ['P136']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 146.5s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.72s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 190.68s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who made the movie's music?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who made the movie music \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who made the movie music\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the movie music, Music Movie, The Movie Music, the Movie Music])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('The Movie', ['Q16955125']), ('The Music', ['Q1807651'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(made, ['P186'])]\n",
      "-> q_predicates \tRunning time is 5.43s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (made, ['P186']), (series, ['P179']), (series ordinal, ['P1545'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q638', 'Q19820041']), (Music, ['Q10851752', 'Q11232362'])], [the, Music])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'music', 'Music', 'movie', 'The Movie', 'The Music', 'Tom Cherones', 'The Pick', '53', 'Seinfeld', 'The Movie', 'The Director', 'The Director: Conclusion', 'TV series episode']\n",
      "meaningful_names_no_previous_answer [Movie, music, Music, movie, The Movie, The Music, Tom Cherones, The Pick, 53, Seinfeld, The Movie, The Director, The Director Conclusion, TV series episode]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (The Movie, ['Q16955125', 'Q7752538']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (53, ['Q4640335', 'Q26417887', 'Q30440']), (Seinfeld, ['Q7446852', 'Q23733', 'Q36978598']), (The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (music, ['Q19820041']), (Music, ['Q10851752', 'Q11232362']), (The Movie, ['Q16955125', 'Q7752538']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (53, ['Q4640335', 'Q26417887', 'Q30440']), (Seinfeld, ['Q7446852', 'Q23733', 'Q36978598']), (The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 34.64s\n",
      "-->  58 nodes and 78 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 58 nodes and 78 edges\n",
      "-> predicates_dict: {'P57': 151, 'P1545': 17, 'P179': 201, 'P155': 12, 'P156': 13, 'P31': 19, 'P4908': 3, 'P527': 12, 'P106': 2, 'P1013': 1, 'P364': 1, 'P1011': 1, 'P407': 1, 'P1552': 1, 'P1441': 3, 'P175': 8, 'P1191': 1, 'P571': 1, 'P585': 1, 'P361': 3, 'P1435': 1, 'P131': 2, 'P58': 1, 'P19': 1, 'P735': 1, 'P136': 4, 'P166': 1, 'P642': 1, 'P577': 1, 'P4312': 1, 'P17': 2, 'P69': 1, 'P495': 2, 'P3744': 1, 'P2002': 1, 'P1881': 1, 'P453': 3, 'P161': 3, 'P740': 1, 'P282': 1, 'P971': 1, 'P856': 1, 'P1216': 1, 'P264': 1, 'P452': 1, 'P734': 3, 'P840': 1, 'P21': 2}\n",
      "-> paths_keywords: (['movie', 'music', 'the movie', 'tom cherones', 'the pick', '53', 'seinfeld', 'the director', 'tv series episode'], {'director': [director, ['P57']], 'material used': [material used, ['P186']], 'series': [series, ['P179']], 'series ordinal': [series ordinal, ['P1545']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 32.6s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14452\n",
      "->\tRunning time is 21.83s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7772854', 2.335993820670091], ['Q7712939', 2.1736340790306845], ['Q3468899', 2.0062312798760327], ['Q6742912', 1.971424443499926]]\n",
      "->Computing hypothesises \tRunning time is 227.93s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 3\n",
      "->\tRunning time is 196.5s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q7772854', 'P57', 'Q7815268', 'P19', 'Q30', 'P495', 'Q23733', 'P179', 'Q3468899', 'P4908', 'Q7752538', 'P31', 'Q21191270', 'P31', 'Q50078600', 'P1545', '53']\n",
      "->\tTotal Running time is 522.3s\n",
      "\n",
      "df_graphqa Q7772854\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                     question  answer  \\\n",
      "248             526    3       False  Who made the movie's music?  Q76364   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "248  movies   False         47.79         0.0    False          33.28   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr   graphqa  graphqa_time  \\\n",
      "248          0.0  False       354.77        0.0  Q7772854        522.54   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "248        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "248         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-249-ic526-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 527/2240 -> 4/5 -> Convex=True: (Q76364) Who made the movie's music?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q10301427\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 2014-10-26T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q7752538\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                     question  answer  \\\n",
      "249             526    3        True  Who made the movie's music?  Q76364   \n",
      "\n",
      "     domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "249  movies  Q10301427           0.0         0.0    False            1.9   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr   graphqa  \\\n",
      "249          0.0  2014-10-26T00:00:00Z          0.6        0.0  Q7752538   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "249          0.19        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "249          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-250-ic526-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 21:43:31.941459\n",
      "\t>>> Processing 527/2240 -> 5/5 -> Convex=False: (677,463,813) How much did the movie make in USD overall?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: How much did the movie make in USD overall?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How much did the movie make in USD overall \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How much did the movie make in USD overall\n",
      "-> q_themes: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd, Usd Overall])\n",
      "-> q_themes_enhanced: [('usd', ['Q23351886']), ('Overall', ['Q2042277']), ('overall', ['Q13383825'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (make, ['P2010'])]\n",
      "-> q_predicates \tRunning time is 6.15s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (make, ['P2010'])]\n",
      "----> q_themes in context: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd])\n",
      "--> Potential meaningful keywords for the sentence: ['USD', 'the movie', 'usd', 'Overall', 'overall']\n",
      "---> Meaningful keywords enhanced by previous context: ['USD', 'the movie', 'usd', 'Overall', 'overall', '']\n",
      "meaningful_names_no_previous_answer [USD, the movie, usd, Overall, overall]\n",
      "----> Meaningful keywords casted as theme ([(USD, ['Q2468155'])], [])\n",
      "q_focused_parts: [(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.3s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: How much did the movie make in USD overall?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How much did the movie make in USD overall \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How much did the movie make in USD overall\n",
      "-> q_themes: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd, Usd Overall])\n",
      "-> q_themes_enhanced: [('usd', ['Q23351886']), ('Overall', ['Q2042277']), ('overall', ['Q13383825'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "behold: get_most_similar started with: usd\n",
      "behold: get_most_similar started with: overall\n",
      "-> q_predicates: [(did, ['P248']), (make, ['P2010']), (movie, ['P57']), (USD, []), (overall, [])]\n",
      "-> q_predicates \tRunning time is 6.25s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (make, ['P2010']), (movie, ['P57']), (USD, [])]\n",
      "----> q_themes in context: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd])\n",
      "--> Potential meaningful keywords for the sentence: ['USD', 'the movie', 'usd', 'Overall', 'overall']\n",
      "---> Meaningful keywords enhanced by previous context: ['USD', 'the movie', 'usd', 'Overall', 'overall', '']\n",
      "meaningful_names_no_previous_answer [USD, the movie, usd, Overall, overall]\n",
      "----> Meaningful keywords casted as theme ([(USD, ['Q2468155'])], [])\n",
      "q_focused_parts: [(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.77s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: How much did the movie make in USD overall?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How much did the movie make in USD overall \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How much did the movie make in USD overall\n",
      "-> q_themes: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd, Usd Overall])\n",
      "-> q_themes_enhanced: [('usd', ['Q23351886']), ('Overall', ['Q2042277']), ('overall', ['Q13383825'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (make, ['P2010'])]\n",
      "-> q_predicates \tRunning time is 5.84s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (did, ['P248']), (make, ['P2010'])]\n",
      "----> q_themes in context: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd])\n",
      "--> Potential meaningful keywords for the sentence: ['USD', 'the movie', 'usd', 'Overall', 'overall']\n",
      "---> Meaningful keywords enhanced by previous context: ['USD', 'the movie', 'usd', 'Overall', 'overall', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [USD, the movie, usd, Overall, overall, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(USD, ['Q2468155']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(USD, ['Q2468155']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.89s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P106': 5, 'P585': 1, 'P166': 1, 'P1431': 1, 'P2453': 7, 'P805': 4, 'P1411': 7, 'P1686': 3, 'P1013': 1, 'P366': 1, 'P20': 1, 'P19': 2, 'P364': 1, 'P31': 5, 'P361': 1, 'P1480': 1, 'P1810': 2, 'P4900': 2, 'P291': 4, 'P577': 3, 'P180': 3, 'P279': 3, 'P3831': 1, 'P3092': 1, 'P264': 1, 'P1039': 2, 'P1038': 2, 'P1057': 1, 'P644': 1, 'P272': 1, 'P175': 1, 'P580': 1, 'P26': 1, 'P136': 1, 'P735': 1, 'P734': 1, 'P2548': 1, 'P2393': 1, 'P1981': 1, 'P1412': 1, 'P2094': 1, 'P688': 1, 'P702': 1, 'P645': 1}\n",
      "-> paths_keywords: (['usd', 'interstellar', 'christopher nolan', 'the movie', 'make'], {'director': [director, ['P57']], 'stated in': [stated in, ['P248']], 'EXIF make': [EXIF make, ['P2010']]}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 155.65s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.97s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: How much did the movie make in USD overall?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How much did the movie make in USD overall \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How much did the movie make in USD overall\n",
      "-> q_themes: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd, Usd Overall])\n",
      "-> q_themes_enhanced: [('usd', ['Q23351886']), ('Overall', ['Q2042277']), ('overall', ['Q13383825'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behold: get_most_similar started with: movie\n",
      "behold: get_most_similar started with: usd\n",
      "behold: get_most_similar started with: overall\n",
      "-> q_predicates: [(did, ['P248']), (make, ['P2010']), (movie, ['P57']), (USD, []), (overall, [])]\n",
      "-> q_predicates \tRunning time is 6.42s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (did, ['P248']), (make, ['P2010']), (USD, [])]\n",
      "----> q_themes in context: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd])\n",
      "--> Potential meaningful keywords for the sentence: ['USD', 'the movie', 'usd', 'Overall', 'overall']\n",
      "---> Meaningful keywords enhanced by previous context: ['USD', 'the movie', 'usd', 'Overall', 'overall', 'Interstellar', 'Christopher Nolan']\n",
      "meaningful_names_no_previous_answer [USD, the movie, usd, Overall, overall, Interstellar, Christopher Nolan]\n",
      "----> Meaningful keywords casted as theme ([(USD, ['Q2468155']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912'])], [])\n",
      "q_focused_parts: [(USD, ['Q2468155']), (Interstellar, ['Q3153615', 'Q13417189', 'Q21186666']), (Christopher Nolan, ['Q25191', 'Q2375756', 'Q224912']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 36.1s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P57': 14, 'P106': 5, 'P585': 1, 'P166': 1, 'P1431': 1, 'P2453': 7, 'P805': 4, 'P1411': 7, 'P1686': 3, 'P1013': 1, 'P366': 1, 'P20': 1, 'P19': 2, 'P364': 1, 'P31': 5, 'P361': 1, 'P688': 1, 'P702': 1, 'P1480': 1, 'P1810': 2, 'P4900': 2, 'P291': 4, 'P577': 3, 'P180': 3, 'P279': 3, 'P3831': 1, 'P3092': 1, 'P264': 1, 'P1039': 2, 'P1038': 2, 'P1057': 1, 'P644': 1, 'P272': 1, 'P175': 1, 'P580': 1, 'P26': 1, 'P136': 1, 'P2130': 1, 'P735': 1, 'P734': 1, 'P2548': 1, 'P915': 2, 'P27': 1, 'P17': 1, 'P750': 1, 'P2393': 1, 'P1981': 1, 'P1412': 1, 'P2363': 1, 'P3402': 1, 'P2094': 1, 'P645': 1}\n",
      "-> paths_keywords: (['usd', 'interstellar', 'christopher nolan', 'the movie', 'make'], {'director': [director, ['P57']], 'stated in': [stated in, ['P248']], 'EXIF make': [EXIF make, ['P2010']]}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 171.98s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 221.97s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: How much did the movie make in USD overall?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How much did the movie make in USD overall \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How much did the movie make in USD overall\n",
      "-> q_themes: ([(USD, ['Q2468155']), (the movie, ['Q7752538', 'Q16955125'])], [Usd, Usd Overall])\n",
      "-> q_themes_enhanced: [('usd', ['Q23351886']), ('Overall', ['Q2042277']), ('overall', ['Q13383825'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248']), (make, ['P2010'])]\n",
      "-> q_predicates \tRunning time is 6.97s\n",
      "--> Predicates enhanced by previous context: [(director, ['P57']), (did, ['P248']), (make, ['P2010']), (place of birth, ['P19']), (country of origin, ['P495']), (series, ['P179']), (season, ['P4908']), (instance of, ['P31'])]\n",
      "----> q_themes in context: ([(USD, ['Q2468155']), (the movie, ['Q7752538'])], [Usd])\n",
      "--> Potential meaningful keywords for the sentence: ['USD', 'the movie', 'usd', 'Overall', 'overall']\n",
      "---> Meaningful keywords enhanced by previous context: ['USD', 'the movie', 'usd', 'Overall', 'overall', 'Tom Cherones', 'The Pick', '53', 'Seinfeld', 'The Movie', 'The Director', 'TV series episode', 'The Visa', 'United States of America', 'Seinfeld, season 4', 'The Director: Conclusion']\n",
      "meaningful_names_no_previous_answer [USD, the movie, usd, Overall, overall, Tom Cherones, The Pick, 53, Seinfeld, The Movie, The Director, TV series episode, The Visa, United States of America, Seinfeld season 4, The Director Conclusion]\n",
      "----> Meaningful keywords casted as theme ([(USD, ['Q2468155']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (53, ['Q4640335', 'Q26417887', 'Q30440']), (Seinfeld, ['Q7446852', 'Q23733', 'Q36978598']), (The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270']), (The Visa, ['Q7772854']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(USD, ['Q2468155']), (Tom Cherones, ['Q7815268']), (The Pick, ['Q7757033']), (53, ['Q4640335', 'Q26417887', 'Q30440']), (Seinfeld, ['Q7446852', 'Q23733', 'Q36978598']), (The Movie, ['Q16955125', 'Q7752538']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (TV series episode, ['Q21191270']), (The Visa, ['Q7772854']), (United States of America, ['Q30', 'Q19971019']), (the movie, ['Q7752538', 'Q16955125'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 51.75s\n",
      "-->  233 nodes and 334 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 233 nodes and 334 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 233 nodes or 334 edges was above the limit of 100\n",
      "-> predicates_dict: {'P57': 232, 'P1545': 28, 'P179': 393, 'P155': 13, 'P156': 12, 'P31': 21, 'P495': 3, 'P4908': 29, 'P527': 19, 'P19': 2, 'P585': 1, 'P27': 1, 'P642': 1, 'P175': 3, 'P106': 1, 'P17': 1, 'P1441': 4, 'P1013': 2, 'P1191': 1, 'P1011': 1, 'P407': 1, 'P1552': 1, 'P361': 5, 'P131': 1, 'P2437': 1, 'P3744': 1, 'P2002': 1, 'P366': 1, 'P1881': 1, 'P1480': 1, 'P1810': 2, 'P4900': 2, 'P69': 1, 'P1435': 1, 'P735': 1, 'P1216': 1, 'P4312': 1, 'P166': 1, 'P734': 2, 'P279': 3, 'P180': 2, 'P453': 2, 'P161': 2, 'P1346': 1, 'P2094': 1, 'P282': 1, 'P136': 1, 'P625': 1, 'P1057': 1, 'P2548': 1, 'P2364': 3, 'P1705': 1, 'P644': 1, 'P688': 1}\n",
      "-> paths_keywords: (['usd', 'tom cherones', 'the pick', '53', 'seinfeld', 'the movie', 'the director', 'tv series episode', 'the visa', 'united states of america', 'make'], {'director': [director, ['P57']], 'stated in': [stated in, ['P248']], 'EXIF make': [EXIF make, ['P2010']], 'place of birth': [place of birth, ['P19']], 'country of origin': [country of origin, ['P495']], 'series': [series, ['P179']], 'season': [season, ['P4908']], 'instance of': [instance of, ['P31']]}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 39.43s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16000\n",
      "->\tRunning time is 39.14s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q7769201', 1.7015396353834615], ['Q50330271', 1.6729787590338252], ['Q50330314', 1.6712561553198826], ['Q7773337', 1.629660042825996], ['Q7763899', 1.607904432723553], ['Q50330270', 1.607872761175552], ['Q16201727', 1.6010074222334678], ['Q7764902', 1.578249376975436], ['Q3468899', 1.5734213502137766], ['Q7757291', 1.5628994248470873], ['Q7772780', 1.5494552342865635], ['Q7720455', 1.4957584473855163], ['Q7773659', 1.4919170878082668], ['Q7743854', 1.4725997598957499], ['Q7741555', 1.4605161255143206], ['Q7770249', 1.4117844267021198], ['Q7757136', 1.3789619367046901], ['Q7754870', 1.3616934562617222], ['Q7712939', 1.3573301510590445], ['Q2899183', 1.3130416842265253], ['Q3468985', 1.2050346788598814], ['Q3468781', 1.1768388993440562], ['Q7755660', 1.1744319549158095], ['Q7722309', 1.171594971461848], ['Q7755204', 1.1484053194353212], ['9', 0.0983725299785555]]\n",
      "->Computing hypothesises \tRunning time is 2796.05s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 116\n",
      "->\tRunning time is 398.14s\n",
      "--> len(cleared_golden_paths): 84\n",
      "---> First path: ['Q3468899', 'P4908', 'Q7769201', 'P179', 'Q23733', 'P57', 'Q7815268']\n",
      "->\tTotal Running time is 3385.87s\n",
      "\n",
      "df_graphqa Q3468899\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "250             526    4       False   \n",
      "\n",
      "                                        question       answer  domain qanswer  \\\n",
      "250  How much did the movie make in USD overall?  677,463,813  movies   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "250         51.91         0.0    False           4.39          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr   graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "250       419.17        0.0  Q3468899        3386.2        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "250        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-251-ic526-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 527/2240 -> 5/5 -> Convex=True: (677,463,813) How much did the movie make in USD overall?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q10301427\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q13417189\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q7752538\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "251             526    4        True   \n",
      "\n",
      "                                        question       answer  domain  \\\n",
      "251  How much did the movie make in USD overall?  677,463,813  movies   \n",
      "\n",
      "       qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "251  Q10301427           0.0         0.0    False           4.39          0.0   \n",
      "\n",
      "        convex  convex_time  convex_rr   graphqa  graphqa_time graphqa_top2  \\\n",
      "251  Q13417189         0.92        0.0  Q7752538          0.33        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "251        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-252-ic526-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 22:47:59.295446\n",
      "\t>>> Processing 528/2240 -> 1/5 -> Convex=False: (Q268181) Who was the author of Fight Club?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q285048\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q268181\n",
      "df_convex_rr 1.0\n",
      "\n",
      "CORRECT 528 - 1 -> Convex Q268181\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who was the author of Fight Club?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the author of Fight Club \n",
      "-> q_themes: ([(Fight Club, ['Q190050', 'Q837283']), (the author, ['Q21451533', 'Q51159453']), (club, ['Q988108', 'Q1076626']), (Club, ['Q17624983', 'Q1280895']), (author, ['Q482980', 'P50'])], [was the author of Fight])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.91s\n",
      "--> Potential meaningful keywords for the sentence: ['Fight Club', 'the author', 'club', 'Club', 'author', 'Author']\n",
      "q_focused_parts: [(Fight Club, ['Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.98s\n",
      "-->  516 nodes and 518 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 476 nodes and 476 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 476 nodes or 476 edges was above the limit of 350\n",
      "-> predicates_dict: {'P50': 2, 'P39': 2, 'P155': 2, 'P156': 2, 'P3132': 1, 'P31': 201, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P1441': 4, 'P585': 2, 'P166': 4, 'P527': 1, 'P571': 1, 'P582': 1, 'P1308': 2, 'P580': 1, 'P2758': 1, 'P136': 1, 'P291': 1, 'P577': 1, 'P1343': 1, 'P910': 1, 'P856': 1, 'P179': 1, 'P1545': 2, 'P4908': 1}\n",
      "-> paths_keywords: (['fight club', 'author', 'club', 'the author'], {'instance of': [instance of, ['P31']], 'Author': [author, ['P50']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 5312\n",
      "->Computing possible paths \tRunning time is 89.59s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 5304\n",
      "->\tRunning time is 8.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q268181', 21.09228314751555], ['Q1091018', 11.750770286219229], ['Q137544', 11.738528586974649], ['Q453636', 11.477470105696876], ['Q27688870', 1.8247505182309893], ['Q50380586', 1.6910133235076006], ['Q10369531', 1.6535560524047825], ['Q20747410', 1.6380160992974768], ['Q4882304', 1.559306168900442], ['Q54912711', 1.436537192290347], ['Q29479046', 1.2994055086826752], ['Q27862473', 1.2316370070879104], ['Q2925750', 1.2125068337075735], ['Q42272446', 1.1910861681878313], ['Q27999420', 1.1369508065499438], ['Q55293091', 1.1174442945856529], ['Q28135129', 1.1129426756959224], ['Q3481821', 1.109195772107181], ['Q4741153', 1.0987462651499873], ['Q3488190', 1.0792906790261299], ['Q51774782', 1.062661663534369], ['Q16237324', 1.0411835107596352], ['Q11702283', 1.0087639939746689], ['Q56071258', 0.9681212499165925], ['Q7752493', 0.9628681316504406], ['Q5136145', 0.935294410196287], ['Q3179915', 0.9309457290909343], ['Q7929460', 0.9054772559270173], ['Q45855303', 0.8035791715952811], ['Q56474019', 0.7706179675288666], ['Q692936', 0.6890386728466831], ['Q11424', 0.6802641131783516], ['Q29940906', 0.5656036244606113], ['Q28479799', 0.5572470067418394], ['Q5063946', 0.31967268081444256], ['Q16144840', 0.2911929906507666], ['Q11891929', 0.18482471543977588], ['Q55590061', 0.18482471543977588], ['Q49426025', 0.18482471543977588], ['Q7113233', 0.18482471543977588], ['Q1967477', 0.18482471543977588], ['Q49425998', 0.18482471543977588], ['Q11954037', 0.10756316290503588], ['Q1713707', -0.145406244467199], ['Q9261136', -0.41626671276068417], ['Q4833332', -0.47727544333210214]]\n",
      "->Computing hypothesises \tRunning time is 143.52s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 13\n",
      "->\tRunning time is 253.9s\n",
      "--> len(cleared_golden_paths): 7\n",
      "---> First path: ['Q268181', 'P50', 'Q190050', 'P31', 'Q11424']\n",
      "->\tTotal Running time is 568.3s\n",
      "\n",
      "df_graphqa Q268181\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 528 - 1 -> graphqa Q268181\n",
      "\n",
      "PARTIAL_CORRECT 528 - 1 -> graphqa in answers ['Q268181', 'Q1091018', 'Q137544', 'Q453636', 'Q27688870', 'Q50380586', 'Q10369531', 'Q20747410', 'Q4882304', 'Q54912711', 'Q29479046', 'Q27862473', 'Q2925750', 'Q42272446', 'Q27999420', 'Q55293091', 'Q28135129', 'Q3481821', 'Q4741153', 'Q3488190', 'Q51774782', 'Q16237324', 'Q11702283', 'Q56071258', 'Q7752493', 'Q5136145', 'Q3179915', 'Q7929460', 'Q45855303', 'Q56474019', 'Q692936', 'Q11424', 'Q29940906', 'Q28479799', 'Q5063946', 'Q16144840', 'Q11891929', 'Q55590061', 'Q49426025', 'Q7113233', 'Q1967477', 'Q49425998', 'Q11954037', 'Q1713707', 'Q9261136', 'Q4833332']\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "252             527    0       False  Who was the author of Fight Club?   \n",
      "\n",
      "      answer  domain  qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "252  Q268181  movies  Q285048          0.75         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr   convex  convex_time  convex_rr  graphqa  \\\n",
      "252           0.51          0.0  Q268181         1.56        1.0  Q268181   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "252        568.53         True         True         True         True   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "252           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-253-ic527-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 22:57:30.674922\n",
      "\t>>> Processing 528/2240 -> 2/5 -> Convex=False: (Q65) Main filming location in movie?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 7.58s\n",
      "--> Predicates enhanced by previous context: []\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 58.84s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 7.32s\n",
      "--> Predicates enhanced by previous context: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 68.44s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 6.59s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 29.56s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P50': 62, 'P915': 1, 'P625': 1, 'P937': 1, 'P106': 2, 'P969': 1, 'P1411': 3, 'P2453': 4, 'P585': 1, 'P166': 3, 'P31': 5, 'P344': 1, 'P155': 4, 'P156': 1, 'P136': 3, 'P19': 1, 'P1441': 1, 'P291': 1, 'P577': 3, 'P953': 1, 'P361': 2, 'P805': 1, 'P407': 2, 'P642': 1, 'P111': 1, 'P154': 1, 'P1552': 1, 'P69': 1, 'P17': 1, 'P27': 1, 'P138': 1, 'P800': 1, 'P275': 1, 'P2747': 1}\n",
      "-> paths_keywords: (['movie', 'fight club', 'chuck palahniuk', 'location'], {'author': [author, ['P50']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 142.65s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Main author filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.62s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.06s\n",
      "-->  12 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 12 nodes and 14 edges\n",
      "-> predicates_dict: {'P50': 62, 'P915': 1, 'P625': 1, 'P57': 1, 'P910': 1, 'P937': 1, 'P31': 5, 'P155': 4, 'P156': 1, 'P136': 8, 'P106': 3, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P1431': 1, 'P585': 1, 'P166': 3, 'P969': 1, 'P364': 1, 'P407': 2, 'P154': 1, 'P373': 1, 'P131': 1, 'P1441': 3, 'P2747': 1, 'P361': 2, 'P58': 1, 'P19': 1, 'P344': 1, 'P291': 1, 'P577': 3, 'P453': 1, 'P161': 1, 'P642': 1, 'P111': 1, 'P953': 1, 'P1552': 1, 'P138': 1, 'P17': 1, 'P27': 1, 'P69': 1, 'P800': 1, 'P175': 1, 'P275': 1}\n",
      "-> paths_keywords: (['movie', 'fight club', 'chuck palahniuk', 'filming'], {'author': [author, ['P50']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'director': [director, ['P57']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 143.63s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.4s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.14s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 188.74s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 6.52s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Fight Club', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Fight Club, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (film, ['Q11424']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (film, ['Q11424']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.4s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 12, 'P50': 24, 'P915': 1, 'P625': 1, 'P642': 1, 'P111': 1, 'P361': 2, 'P937': 1, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P106': 2, 'P407': 2, 'P154': 1, 'P291': 1, 'P577': 3, 'P19': 1, 'P495': 1, 'P131': 1, 'P1552': 1, 'P969': 1, 'P17': 1, 'P27': 1, 'P585': 1, 'P166': 3, 'P69': 1, 'P344': 1, 'P155': 4, 'P136': 3, 'P156': 1, 'P1441': 1, 'P953': 1, 'P138': 1, 'P800': 1, 'P275': 1, 'P2747': 1}\n",
      "-> paths_keywords: (['movie', 'film', 'fight club', 'chuck palahniuk', 'location'], {'instance of': [instance of, ['P31']], 'author': [author, ['P50']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 146.79s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.73s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Main author filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.83s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'Fight Club', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, Fight Club, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (film, ['Q11424']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (film, ['Q11424']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 34.13s\n",
      "-->  15 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 15 nodes and 18 edges\n",
      "-> predicates_dict: {'P31': 12, 'P50': 24, 'P915': 1, 'P625': 1, 'P57': 1, 'P910': 1, 'P937': 1, 'P642': 1, 'P111': 1, 'P361': 2, 'P155': 4, 'P156': 1, 'P136': 8, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P106': 3, 'P407': 2, 'P154': 1, 'P1431': 1, 'P291': 1, 'P577': 3, 'P19': 1, 'P495': 1, 'P131': 1, 'P585': 1, 'P166': 3, 'P969': 1, 'P373': 1, 'P364': 1, 'P1552': 1, 'P1441': 3, 'P2747': 1, 'P17': 1, 'P27': 1, 'P58': 1, 'P69': 1, 'P344': 1, 'P453': 1, 'P161': 1, 'P953': 1, 'P138': 1, 'P800': 1, 'P175': 1, 'P275': 1}\n",
      "-> paths_keywords: (['movie', 'film', 'fight club', 'chuck palahniuk', 'filming'], {'instance of': [instance of, ['P31']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'director': [director, ['P57']], 'author': [author, ['P50']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 179.83s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.19s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 228.89s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "253             527    1       False  Main filming location in movie?    Q65   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "253  movies   False        142.65         0.0    False           1.31   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "253          0.0  False       372.27        0.0   False        417.58   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "253        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "253         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-254-ic527-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 528/2240 -> 2/5 -> Convex=True: (Q65) Main filming location in movie?                                  \n",
      "qAnswer extended by Convex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer Q18615086\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q6106\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q6106\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "254             527    1        True  Main filming location in movie?    Q65   \n",
      "\n",
      "     domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "254  movies  Q18615086          4.16         0.0    False           1.29   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "254          0.0  Q6106         1.04        0.0   Q6106           1.2   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "254        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "254         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-255-ic527-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:13:12.232725\n",
      "\t>>> Processing 528/2240 -> 3/5 -> Convex=False: (139 minute) How long is movie?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: How long is movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How long is movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How long is movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 4.97s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Movie, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 65.93s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: How long is movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How long is movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How long movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 3.12s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Movie, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 56.61s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: How long is movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How long is movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How long is movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 5.28s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Movie, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 35.27s\n",
      "-->  7 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 8 edges\n",
      "-> predicates_dict: {'P50': 62, 'P57': 1, 'P31': 4, 'P136': 5, 'P106': 3, 'P1431': 1, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P585': 1, 'P166': 3, 'P1441': 3, 'P953': 1, 'P407': 2, 'P131': 1, 'P1877': 2, 'P2047': 1, 'P2758': 1, 'P1552': 1, 'P154': 1, 'P58': 1, 'P453': 1, 'P577': 2, 'P161': 1, 'P138': 1, 'P800': 1, 'P155': 2, 'P291': 1, 'P17': 1, 'P27': 1, 'P21': 1, 'P275': 1, 'P69': 1, 'P2747': 1}\n",
      "-> paths_keywords: (['movie', 'fight club', 'chuck palahniuk'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 120\n",
      "->Computing possible paths \tRunning time is 63.69s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 38\n",
      "->\tRunning time is 3.46s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.31s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: How long is movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How long is movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: How long movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 3.18s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Movie, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.01s\n",
      "-->  7 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 8 edges\n",
      "-> predicates_dict: {'P50': 62, 'P57': 1, 'P31': 4, 'P136': 5, 'P106': 3, 'P1431': 1, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P585': 1, 'P166': 3, 'P1441': 3, 'P953': 1, 'P407': 2, 'P131': 1, 'P1877': 2, 'P2047': 1, 'P2758': 1, 'P1552': 1, 'P154': 1, 'P58': 1, 'P453': 1, 'P161': 1, 'P577': 2, 'P138': 1, 'P800': 1, 'P155': 2, 'P291': 1, 'P17': 1, 'P27': 1, 'P21': 1, 'P275': 1, 'P69': 1, 'P2747': 1}\n",
      "-> paths_keywords: (['movie', 'fight club', 'chuck palahniuk'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 120\n",
      "->Computing possible paths \tRunning time is 63.76s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 38\n",
      "->\tRunning time is 3.43s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.29s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 96.03s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: How long is movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: How long is movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: How long is movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(be, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 3.13s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (long, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'Fight Club', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Movie, Fight Club, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.04s\n",
      "-->  10 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 10 nodes and 12 edges\n",
      "-> predicates_dict: {'P31': 10, 'P50': 5, 'P57': 1, 'P361': 1, 'P136': 4, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P407': 2, 'P154': 1, 'P1431': 1, 'P291': 1, 'P577': 1, 'P19': 1, 'P495': 1, 'P131': 1, 'P585': 1, 'P166': 2, 'P1552': 1, 'P1877': 2, 'P17': 1, 'P27': 1, 'P2047': 1, 'P1441': 1, 'P953': 1, 'P58': 1, 'P106': 2, 'P69': 1, 'P2758': 1, 'P453': 1, 'P161': 1, 'P138': 1, 'P155': 2, 'P800': 1, 'P21': 1, 'P2747': 1}\n",
      "-> paths_keywords: (['movie', 'fight club', 'film', 'chuck palahniuk'], {}, [How])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 234\n",
      "->Computing possible paths \tRunning time is 48.93s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 110\n",
      "->\tRunning time is 3.43s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q30', 0.13955993358849794]]\n",
      "->Computing hypothesises \tRunning time is 7.41s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 6\n",
      "->\tRunning time is 3.7s\n",
      "--> len(cleared_golden_paths): 6\n",
      "---> First path: ['Q30', 'P495', 'Q190050', 'P138', 'Q18614809']\n",
      "->\tTotal Running time is 91.08s\n",
      "\n",
      "df_graphqa Q30\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex            question      answer  domain  \\\n",
      "255             527    2       False  How long is movie?  139 minute  movies   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "255   False        131.41         0.0    False           0.18          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "255  False       205.59        0.0     Q30         91.32        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "255        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-256-ic527-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 528/2240 -> 3/5 -> Convex=True: (139 minute) How long is movie?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q18612956\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex v180767\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 451627\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex            question      answer  domain  \\\n",
      "256             527    2        True  How long is movie?  139 minute  movies   \n",
      "\n",
      "       qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "256  Q18612956         21.48         0.0    False           1.23          0.0   \n",
      "\n",
      "      convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "256  v180767         0.29        0.0  451627          0.32        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "256        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-257-ic527-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:20:44.089838\n",
      "\t>>> Processing 528/2240 -> 4/5 -> Convex=False: (Q35332) Who played Tyler Durden?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 7.14s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (Randall Munroe, ['Q285048']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 56.91s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.25s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'Randall Munroe']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (Randall Munroe, ['Q285048']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 56.52s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.57s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.69s\n",
      "-->  24 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 24 nodes and 30 edges\n",
      "-> predicates_dict: {'P50': 62, 'P373': 1, 'P106': 2, 'P1411': 3, 'P2453': 4, 'P585': 1, 'P166': 3, 'P1877': 2, 'P1441': 4, 'P407': 2, 'P154': 1, 'P138': 1, 'P155': 1, 'P800': 1, 'P953': 1, 'P364': 2, 'P136': 2, 'P453': 1, 'P161': 2, 'P58': 1, 'P2437': 1, 'P31': 9, 'P577': 3, 'P291': 1, 'P805': 1, 'P135': 1, 'P2548': 1, 'P735': 2, 'P1113': 1, 'P674': 1, 'P921': 1, 'P734': 1, 'P86': 1, 'P910': 1, 'P156': 1, 'P462': 1, 'P1057': 1, 'P644': 1, 'P275': 1, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'fight club', 'chuck palahniuk', 'durden'], {'author': [author, ['P50']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 266\n",
      "->Computing possible paths \tRunning time is 11.89s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 266\n",
      "->\tRunning time is 3.48s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 2.73s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.38s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.61s\n",
      "-->  24 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 24 nodes and 30 edges\n",
      "-> predicates_dict: {'P50': 62, 'P373': 1, 'P106': 2, 'P1411': 3, 'P2453': 4, 'P585': 1, 'P166': 3, 'P1877': 2, 'P1441': 4, 'P407': 2, 'P154': 1, 'P138': 1, 'P155': 1, 'P800': 1, 'P953': 1, 'P364': 2, 'P136': 2, 'P453': 1, 'P161': 2, 'P58': 1, 'P2437': 1, 'P31': 9, 'P577': 3, 'P291': 1, 'P805': 1, 'P135': 1, 'P2548': 1, 'P735': 2, 'P1113': 1, 'P674': 1, 'P921': 1, 'P734': 1, 'P86': 1, 'P910': 1, 'P156': 1, 'P462': 1, 'P1057': 1, 'P644': 1, 'P275': 1, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'fight club', 'chuck palahniuk', 'durden'], {'author': [author, ['P50']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 266\n",
      "->Computing possible paths \tRunning time is 12.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 266\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 2.74s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 54.76s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.54s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (played, ['P741']), (named after, ['P138'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'Fight Club', 'Fight Club', 'United States of America', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, Fight Club, Fight Club, United States of America, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 29.82s\n",
      "-->  24 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 24 nodes and 30 edges\n",
      "-> predicates_dict: {'P495': 5, 'P138': 2, 'P31': 14, 'P50': 2, 'P27': 1, 'P17': 1, 'P750': 1, 'P373': 1, 'P19': 1, 'P407': 2, 'P154': 1, 'P361': 1, 'P291': 1, 'P577': 1, 'P1877': 2, 'P735': 3, 'P1411': 3, 'P2453': 4, 'P585': 1, 'P166': 2, 'P734': 1, 'P136': 2, 'P69': 1, 'P1441': 4, 'P155': 1, 'P800': 1, 'P953': 1, 'P364': 2, 'P910': 1, 'P580': 1, 'P453': 1, 'P1552': 1, 'P2437': 1, 'P161': 2, 'P805': 1, 'P2548': 1, 'P135': 1, 'P279': 1, 'P106': 1, 'P1113': 1, 'P674': 1, 'P86': 1, 'P462': 1, 'P156': 1, 'P1057': 1, 'P644': 1, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'fight club', 'united states of america', 'film', 'chuck palahniuk', 'durden'], {'country of origin': [country of origin, ['P495']], 'playing hand': [playing hand, ['P741']], 'named after': [named after, ['P138']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 266\n",
      "->Computing possible paths \tRunning time is 13.07s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 266\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1860', 1.0253918112348253]]\n",
      "->Computing hypothesises \tRunning time is 34.71s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 0\n",
      "->\tRunning time is 3.41s\n",
      "--> len(cleared_golden_paths): 0\n",
      "->\tTotal Running time is 92.76s\n",
      "\n",
      "df_graphqa Q1860\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question  answer  \\\n",
      "257             527    3       False  Who played Tyler Durden?  Q35332   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "257  movies   False        125.27         0.0    False           0.48   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "257          0.0  False       106.79        0.0   Q1860          93.0   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "257        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "257         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-258-ic527-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 528/2240 -> 4/5 -> Convex=True: (Q35332) Who played Tyler Durden?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q28815284\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q4001141\n",
      "df_convex_rr 1.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q12684959\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question  answer  \\\n",
      "258             527    3        True  Who played Tyler Durden?  Q35332   \n",
      "\n",
      "     domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "258  movies  Q28815284         18.26         0.0    False           0.51   \n",
      "\n",
      "     platypus_rr    convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "258          0.0  Q4001141         0.48        1.0  Q12684959          0.56   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "258        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "258         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-259-ic527-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:26:29.494683\n",
      "\t>>> Processing 528/2240 -> 5/5 -> Convex=False: (1999-11-11T00:00:00Z) Date of publication?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.7s\n",
      "--> Predicates enhanced by previous context: []\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.5s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.78s\n",
      "--> Predicates enhanced by previous context: [(Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Randall Munroe']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Randall Munroe]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Randall Munroe, ['Q285048'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Randall Munroe, ['Q285048'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 51.01s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.52s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Fight Club', 'Chuck Palahniuk']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.27s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 63, 'P1932': 3, 'P106': 2, 'P31': 3, 'P136': 2, 'P577': 2, 'P291': 2, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P736': 2, 'P166': 3, 'P407': 2, 'P443': 1, 'P154': 1, 'P585': 1, 'P1672': 1, 'P958': 1, 'P92': 1, 'P527': 2, 'P1013': 1, 'P279': 3, 'P642': 2, 'P275': 1, 'P175': 1, 'P1709': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'fight club', 'chuck palahniuk'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 127.26s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.42s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.03s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.79s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Fight Club', 'Chuck Palahniuk']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Fight Club, Chuck Palahniuk]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Chuck Palahniuk, ['Q268181'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.83s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P50': 63, 'P1932': 3, 'P175': 2, 'P31': 4, 'P577': 3, 'P291': 2, 'P1672': 1, 'P180': 1, 'P186': 1, 'P580': 1, 'P2755': 1, 'P569': 1, 'P571': 1, 'P1411': 3, 'P2453': 4, 'P585': 1, 'P166': 3, 'P279': 5, 'P106': 2, 'P19': 1, 'P805': 1, 'P1013': 3, 'P1104': 1, 'P3245': 1, 'P3250': 2, 'P642': 2, 'P407': 3, 'P443': 1, 'P361': 1, 'P136': 3, 'P1552': 1, 'P27': 1, 'P69': 1, 'P958': 1, 'P155': 1, 'P92': 1, 'P433': 1, 'P1709': 1, 'P953': 1, 'P736': 2, 'P138': 1, 'P154': 1, 'P527': 2, 'P275': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'fight club', 'chuck palahniuk'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 138.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 171.73s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.65s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Fight Club', 'Fight Club', 'English', 'United States of America', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Fight Club, Fight Club, English, United States of America, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.96s\n",
      "-->  14 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 14 nodes and 16 edges\n",
      "-> predicates_dict: {'P407': 6, 'P495': 1, 'P138': 2, 'P31': 12, 'P50': 3, 'P443': 1, 'P154': 1, 'P364': 1, 'P3245': 1, 'P3250': 2, 'P571': 1, 'P1412': 1, 'P735': 1, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P1441': 1, 'P291': 2, 'P577': 1, 'P279': 5, 'P1013': 3, 'P1104': 1, 'P642': 2, 'P1932': 3, 'P136': 1, 'P958': 1, 'P92': 1, 'P1709': 1, 'P27': 1, 'P585': 1, 'P166': 2, 'P69': 1, 'P17': 1, 'P175': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P155': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'fight club', 'english', 'united states of america', 'film', 'chuck palahniuk'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 153.72s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.79s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Fight Club', 'Fight Club', 'English', 'United States of America', 'film', 'Chuck Palahniuk', 'Fight Club']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Fight Club, Fight Club, English, United States of America, film, Chuck Palahniuk, Fight Club]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (Chuck Palahniuk, ['Q268181']), (Fight Club, ['Q294483', 'Q190050', 'Q18614809'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.72s\n",
      "-->  14 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 14 nodes and 16 edges\n",
      "-> predicates_dict: {'P407': 6, 'P495': 1, 'P138': 2, 'P31': 12, 'P50': 6, 'P443': 1, 'P154': 1, 'P175': 2, 'P577': 3, 'P291': 2, 'P1672': 1, 'P180': 1, 'P186': 1, 'P364': 1, 'P1932': 3, 'P580': 1, 'P2755': 1, 'P3245': 1, 'P3250': 2, 'P569': 1, 'P571': 1, 'P1412': 1, 'P735': 1, 'P2453': 4, 'P805': 1, 'P1411': 3, 'P585': 1, 'P166': 3, 'P279': 5, 'P1441': 1, 'P1013': 3, 'P19': 1, 'P1104': 1, 'P642': 2, 'P136': 2, 'P361': 1, 'P958': 1, 'P92': 1, 'P1552': 1, 'P1709': 1, 'P27': 1, 'P69': 1, 'P17': 1, 'P155': 2, 'P433': 1, 'P106': 1, 'P953': 1, 'P736': 1, 'P275': 1, 'P131': 1, 'P910': 1, 'P373': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'fight club', 'english', 'united states of america', 'film', 'chuck palahniuk'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 167.79s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.4s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 203.32s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex              question  \\\n",
      "259             527    4       False  Date of publication?   \n",
      "\n",
      "                   answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "259  1999-11-11T00:00:00Z  movies   False         63.45         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "259           0.34          0.0  False       328.81        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "259        388.91        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "259          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-260-ic527-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 528/2240 -> 5/5 -> Convex=True: (1999-11-11T00:00:00Z) Date of publication?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 2011-04-27T00:00:00Z\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 1999-01-01T00:00:00Z\n",
      "df_convex_rr 0.6666666666666666\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1999-01-01T00:00:00Z\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "PARTIAL_CORRECT 528 - 5 -> graphqa in answers ['1999-01-01T00:00:00Z', '1999-11-11T00:00:00Z']\n",
      "    conversation_id turn plus_convex              question  \\\n",
      "260             527    4        True  Date of publication?   \n",
      "\n",
      "                   answer  domain               qanswer  qanswer_time  \\\n",
      "260  1999-11-11T00:00:00Z  movies  2011-04-27T00:00:00Z          3.83   \n",
      "\n",
      "     qanswer_rr platypus  platypus_time  platypus_rr                convex  \\\n",
      "260         0.0    False           0.38          0.0  1999-01-01T00:00:00Z   \n",
      "\n",
      "     convex_time  convex_rr               graphqa  graphqa_time graphqa_top2  \\\n",
      "260         0.87   0.666667  1999-01-01T00:00:00Z          0.38         True   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "260         True         True         True           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-261-ic527-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:39:36.515416\n",
      "\t>>> Processing 529/2240 -> 1/5 -> Convex=False: (Q30) Country of this team?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q1860\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Country of this team?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Country of this team \n",
      "-> q_themes: ([(Country, ['Q6256', 'Q11070708']), (team, ['Q327245', 'Q15054311']), (Team, ['Q23084914']), (country, ['P17'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(country, [])]\n",
      "-> q_predicates \tRunning time is 4.09s\n",
      "--> Potential meaningful keywords for the sentence: ['Country', 'team', 'Team', 'country']\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 35.18s\n",
      "-->  49 nodes and 44 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 49 nodes and 44 edges\n",
      "---> Rebuilding the graph with k_deep 5 ... Previously: 49 nodes or 44 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.37s\n",
      "-->  67 nodes and 62 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 67 nodes and 62 edges\n",
      "---> Rebuilding the graph with k_deep 7 ... Previously: 67 nodes or 62 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.38s\n",
      "-->  71 nodes and 66 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 71 nodes and 66 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 71 nodes or 66 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.69s\n",
      "-->  86 nodes and 82 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 86 nodes and 82 edges\n",
      "---> Rebuilding the graph with k_deep 10 ... Previously: 86 nodes or 82 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.45s\n",
      "-->  93 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 93 nodes and 90 edges\n",
      "---> Rebuilding the graph with k_deep 11 ... Previously: 93 nodes or 90 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.88s\n",
      "-->  102 nodes and 100 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 102 nodes and 100 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 102 nodes or 100 edges was below the limit of 100\n",
      "->New graph \tRunning time is 35.96s\n",
      "-->  110 nodes and 108 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 110 nodes and 108 edges\n",
      "-> predicates_dict: {'P17': 1, 'P1282': 1, 'P1963': 1, 'P1001': 2, 'P1074': 1, 'P1204': 1, 'P131': 1, 'P2670': 2, 'P361': 2, 'P527': 2, 'P264': 2, 'P360': 4, 'P734': 1, 'P2416': 1, 'P813': 1, 'P973': 1, 'P1709': 1, 'P279': 3, 'P31': 8, 'P106': 1, 'P569': 1, 'P155': 4, 'P136': 1, 'P577': 2, 'P21': 1, 'P156': 3, 'P373': 1, 'P180': 1, 'P1725': 1, 'P2452': 2}\n",
      "-> paths_keywords: (['country', 'team'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 456\n",
      "->Computing possible paths \tRunning time is 44.45s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 194\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q258', 0.22938731141616303], ['Q183366', 0.20045342487572926], ['Q1020994', 0.16314783963101906], ['Q607159', -0.05246405656115172]]\n",
      "->Computing hypothesises \tRunning time is 3.91s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 24\n",
      "->\tRunning time is 5.16s\n",
      "--> len(cleared_golden_paths): 12\n",
      "---> First path: ['Q258', 'P17', 'Q6256', 'P131', 'Q10864048']\n",
      "->\tTotal Running time is 313.26s\n",
      "\n",
      "df_graphqa Q258\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex               question answer  domain  \\\n",
      "261             528    0       False  Country of this team?    Q30  soccer   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "261   False          0.51         0.0    False           0.35          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "261  Q1860         0.94        0.0    Q258        313.51        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "261        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-262-ic528-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:44:51.853151\n",
      "\t>>> Processing 529/2240 -> 2/5 -> Convex=False: (Q2068) When was the club founded?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: When was the club founded?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the club founded \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When was the club founded\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the club, ['Q18959440']), (The Club, ['Q16208041', 'Q15838571']), (club, ['Q988108', 'Q1076626'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (founded, ['P112'])]\n",
      "-> q_predicates \tRunning time is 5.34s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (founded, ['P112'])]\n",
      "----> q_themes in context: ([(the club, ['Q18959440']), (The Club, ['Q16208041', 'Q15838571']), (club, ['Q988108', 'Q1076626'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the club', 'The Club', 'club']\n",
      "---> Meaningful keywords enhanced by previous context: ['the club', 'The Club', 'club', 'Country Music', 'English']\n",
      "meaningful_names_no_previous_answer [the club, The Club, club, Country Music, English]\n",
      "----> Meaningful keywords casted as theme ([(The Club, ['Q15838571', 'Q16208041', 'Q18959440']), (club, ['Q1076626']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(The Club, ['Q15838571', 'Q16208041', 'Q18959440']), (club, ['Q1076626']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (the club, ['Q18959440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.91s\n",
      "-->  14 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 14 nodes and 14 edges\n",
      "-> predicates_dict: {'P407': 532, 'P577': 4, 'P291': 1, 'P571': 1, 'P364': 1, 'P31': 9, 'P495': 1, 'P156': 4, 'P131': 1, 'P108': 1, 'P155': 2, 'P136': 1, 'P17': 5, 'P344': 1, 'P57': 1, 'P910': 1, 'P373': 1}\n",
      "-> paths_keywords: (['the club', 'club', 'country music', 'english'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 164\n",
      "->Computing possible paths \tRunning time is 56.54s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 72\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['2010-04-20T00:00:00Z', 2.911240888734772], ['Q482994', 0.8178751031807311]]\n",
      "->Computing hypothesises \tRunning time is 10.11s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 9\n",
      "->\tRunning time is 3.96s\n",
      "--> len(cleared_golden_paths): 5\n",
      "---> First path: ['2010-04-20T00:00:00Z', 'P577', 'Q5177360', 'P407', 'Q1860']\n",
      "->\tTotal Running time is 97.41s\n",
      "\n",
      "df_convex 2010-04-20T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: When was the club founded?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the club founded \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When was the club founded\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the club, ['Q18959440']), (The Club, ['Q16208041', 'Q15838571']), (club, ['Q988108', 'Q1076626'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (founded, ['P112'])]\n",
      "-> q_predicates \tRunning time is 3.79s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (be, ['P31']), (founded, ['P112']), (is in the administrative unit, ['P131'])]\n",
      "----> q_themes in context: ([(the club, ['Q18959440']), (The Club, ['Q16208041', 'Q15838571']), (club, ['Q988108', 'Q1076626'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the club', 'The Club', 'club']\n",
      "---> Meaningful keywords enhanced by previous context: ['the club', 'The Club', 'club', 'country', 'South Africa', 'country', 'first-level administrative country subdivision']\n",
      "meaningful_names_no_previous_answer [the club, The Club, club, country, South Africa, country, first level administrative country subdivision]\n",
      "----> Meaningful keywords casted as theme ([(The Club, ['Q15838571', 'Q16208041', 'Q18959440']), (club, ['Q1076626']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(The Club, ['Q15838571', 'Q16208041', 'Q18959440']), (club, ['Q1076626']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256']), (the club, ['Q18959440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 47.46s\n",
      "-->  13 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 14 edges\n",
      "-> predicates_dict: {'P17': 5, 'P1963': 7, 'P131': 4, 'P813': 1, 'P973': 1, 'P1709': 1, 'P577': 3, 'P291': 1, 'P1282': 1, 'P1545': 1, 'P279': 1, 'P150': 1, 'P495': 2, 'P360': 2, 'P361': 1, 'P31': 251, 'P364': 1, 'P373': 1, 'P527': 3, 'P921': 1, 'P910': 1, 'P2452': 4, 'P136': 1, 'P138': 1, 'P344': 1, 'P57': 1, 'P1416': 1}\n",
      "-> paths_keywords: (['the club', 'club', 'country', 'south africa'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 214\n",
      "->Computing possible paths \tRunning time is 43.82s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 108\n",
      "->\tRunning time is 3.48s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q10864048', 1.354729066679993]]\n",
      "->Computing hypothesises \tRunning time is 8.22s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 18\n",
      "->\tRunning time is 4.9s\n",
      "--> len(cleared_golden_paths): 9\n",
      "---> First path: ['Q10864048', 'P131', 'Q6256', 'P17', 'Q258', 'P921', 'Q28754705']\n",
      "->\tTotal Running time is 114.43s\n",
      "\n",
      "df_graphqa Q10864048\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                    question answer  \\\n",
      "262             528    1       False  When was the club founded?  Q2068   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "262  soccer   False          0.75         0.0    False           0.71   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr    graphqa  \\\n",
      "262          0.0  2010-04-20T00:00:00Z        97.67        0.0  Q10864048   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "262        114.67        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "262          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-263-ic528-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 529/2240 -> 2/5 -> Convex=True: (Q2068) When was the club founded?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 2010-04-20T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q16820619\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                    question answer  \\\n",
      "263             528    1        True  When was the club founded?  Q2068   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "263  soccer   False          0.91         0.0    False           0.67   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr    graphqa  \\\n",
      "263          0.0  2010-04-20T00:00:00Z         0.04        0.0  Q16820619   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "263          7.74        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "263          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-264-ic528-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:48:35.062184\n",
      "\t>>> Processing 529/2240 -> 3/5 -> Convex=False: (Q509165) Who is the current head coach?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who is the current head coach?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the current head coach \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who is the current head coach\n",
      "-> q_themes: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the current head coach, The Current Head Coach, current head coach, the current Head Coach])\n",
      "-> q_themes_enhanced: [('head coach', ['P286']), ('current', ['Q11651']), ('head', ['Q15824240']), ('The Current', ['Q7728442']), ('The Head', ['Q1163537']), ('The Coach', ['Q22041515']), ('Current', ['Q11056977']), ('Head', ['Q18593093'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "behold: get_most_similar started with: head\n",
      "-> q_predicates: [(be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286'])]\n",
      "-> q_predicates \tRunning time is 8.02s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286']), (date of publication, ['P577'])]\n",
      "----> q_themes in context: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the, The, current])\n",
      "--> Potential meaningful keywords for the sentence: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head']\n",
      "---> Meaningful keywords enhanced by previous context: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head', 'Country Music', 'English', '2010-04-20T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [coach, Coach, head coach, current, head, The Current, The Head, The Coach, Current, Head, Country Music, English, 2010 04 20T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 27.11s\n",
      "-->  11 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 12 edges\n",
      "-> predicates_dict: {'P407': 533, 'P577': 7, 'P1810': 1, 'P3740': 1, 'P734': 1, 'P1056': 1, 'P138': 1, 'P180': 1, 'P279': 3, 'P1441': 1, 'P364': 1, 'P805': 1, 'P1343': 1, 'P569': 1, 'P570': 1, 'P571': 1, 'P1412': 1, 'P735': 1, 'P582': 4, 'P580': 4, 'P937': 5, 'P31': 18, 'P373': 5, 'P495': 2, 'P585': 1, 'P828': 1, 'P361': 2, 'P131': 1, 'P1811': 1, 'P20': 1, 'P27': 1, 'P618': 1, 'P973': 1, 'P425': 1, 'P108': 1, 'P155': 3, 'P156': 4, 'P921': 1, 'P5008': 1, 'P17': 3, 'P453': 1, 'P161': 2, 'P462': 1, 'P195': 2, 'P217': 1, 'P276': 1, 'P2437': 2, 'P1472': 1, 'P910': 3, 'P57': 1, 'P264': 2, 'P69': 1, 'P175': 2, 'P170': 1}\n",
      "-> paths_keywords: (['coach', 'country music', 'english'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'coat of arms image': [coat of arms image, ['P94']], 'head coach': [head coach, ['P286']], 'date of publication': [date of publication, ['P577']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 158\n",
      "->Computing possible paths \tRunning time is 60.11s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 68\n",
      "->\tRunning time is 3.44s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.14s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who is the current head coach?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the current head coach \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who date of publication the current head coach\n",
      "-> q_themes: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the current head coach, The Current Head Coach, current head coach, the current Head Coach])\n",
      "-> q_themes_enhanced: [('head coach', ['P286']), ('current', ['Q11651']), ('head', ['Q15824240']), ('The Current', ['Q7728442']), ('The Head', ['Q1163537']), ('The Coach', ['Q22041515']), ('Current', ['Q11056977']), ('Head', ['Q18593093'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "behold: get_most_similar started with: head\n",
      "-> q_predicates: [(be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286'])]\n",
      "-> q_predicates \tRunning time is 8.01s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286']), (date of publication, ['P577'])]\n",
      "----> q_themes in context: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the, The, current])\n",
      "--> Potential meaningful keywords for the sentence: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head']\n",
      "---> Meaningful keywords enhanced by previous context: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head', 'Country Music', 'English', '2010-04-20T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [coach, Coach, head coach, current, head, The Current, The Head, The Coach, Current, Head, Country Music, English, 2010 04 20T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 27.15s\n",
      "-->  11 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 12 edges\n",
      "-> predicates_dict: {'P407': 533, 'P577': 7, 'P1810': 1, 'P3740': 1, 'P734': 1, 'P1056': 1, 'P138': 1, 'P180': 1, 'P279': 3, 'P1441': 1, 'P364': 1, 'P805': 1, 'P1343': 1, 'P569': 1, 'P570': 1, 'P571': 1, 'P1412': 1, 'P735': 1, 'P582': 4, 'P580': 4, 'P937': 5, 'P31': 18, 'P373': 5, 'P495': 2, 'P585': 1, 'P828': 1, 'P361': 2, 'P131': 1, 'P1811': 1, 'P20': 1, 'P27': 1, 'P618': 1, 'P425': 1, 'P973': 1, 'P108': 1, 'P155': 3, 'P156': 4, 'P17': 3, 'P921': 1, 'P5008': 1, 'P453': 1, 'P161': 2, 'P462': 1, 'P195': 2, 'P217': 1, 'P276': 1, 'P2437': 2, 'P1472': 1, 'P910': 3, 'P57': 1, 'P264': 2, 'P69': 1, 'P175': 2, 'P170': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['coach', 'country music', 'english', 'date'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'coat of arms image': [coat of arms image, ['P94']], 'head coach': [head coach, ['P286']], 'date of publication': [date of publication, ['P577']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 108\n",
      "->Computing possible paths \tRunning time is 50.45s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 44\n",
      "->\tRunning time is 3.42s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.14s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 93.88s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who is the current head coach?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the current head coach \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who is the current head coach\n",
      "-> q_themes: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the current head coach, The Current Head Coach, current head coach, the current Head Coach])\n",
      "-> q_themes_enhanced: [('head coach', ['P286']), ('current', ['Q11651']), ('head', ['Q15824240']), ('The Current', ['Q7728442']), ('The Head', ['Q1163537']), ('The Coach', ['Q22041515']), ('Current', ['Q11056977']), ('Head', ['Q18593093'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: current\n",
      "behold: get_most_similar started with: head\n",
      "-> q_predicates: [(be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286'])]\n",
      "-> q_predicates \tRunning time is 8.1s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (be, ['P31']), (current, []), (head, ['P94']), (coach, ['P286']), (is in the administrative unit, ['P131']), (main subject, ['P921'])]\n",
      "----> q_themes in context: ([(coach, ['Q41583', 'Q4655519']), (Coach, ['Q1248320', 'Q15898649'])], [the, The, current])\n",
      "--> Potential meaningful keywords for the sentence: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head']\n",
      "---> Meaningful keywords enhanced by previous context: ['coach', 'Coach', 'head coach', 'current', 'head', 'The Current', 'The Head', 'The Coach', 'Current', 'Head', 'country', 'South Africa', 'first-level administrative country subdivision', 'South Africa', 'South Africa', 'country']\n",
      "meaningful_names_no_previous_answer [coach, Coach, head coach, current, head, The Current, The Head, The Coach, Current, Head, country, South Africa, first level administrative country subdivision, South Africa, South Africa, country]\n",
      "----> Meaningful keywords casted as theme ([(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(coach, ['Q4655519', 'Q41583']), (Coach, ['Q1248320', 'Q15898649']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 63.12s\n",
      "-->  13 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 14 edges\n",
      "-> predicates_dict: {'P17': 3, 'P131': 4, 'P138': 3, 'P150': 3, 'P921': 7, 'P31': 339, 'P1963': 11, 'P1810': 1, 'P3740': 1, 'P734': 1, 'P1282': 1, 'P1056': 1, 'P180': 1, 'P279': 4, 'P1441': 1, 'P805': 1, 'P1343': 1, 'P1545': 1, 'P910': 3, 'P495': 3, 'P27': 1, 'P360': 2, 'P585': 1, 'P937': 3, 'P361': 3, 'P425': 1, 'P373': 4, 'P407': 1, 'P364': 1, 'P828': 1, 'P20': 1, 'P276': 1, 'P527': 1, 'P735': 1, 'P582': 1, 'P580': 1, 'P618': 1, 'P813': 1, 'P973': 2, 'P1709': 1, 'P5008': 1, 'P1811': 1, 'P1711': 1, 'P69': 1, 'P462': 1, 'P449': 1, 'P217': 1, 'P195': 2, 'P2452': 4, 'P453': 1, 'P2437': 2, 'P1472': 1, 'P161': 2, 'P57': 1, 'P577': 1, 'P1476': 1, 'P170': 1}\n",
      "-> paths_keywords: (['coach', 'country', 'south africa'], {'country': [country, ['P17']], 'instance of': [instance of, ['P31']], 'coat of arms image': [coat of arms image, ['P94']], 'head coach': [head coach, ['P286']], 'is in the administrative unit': [is in the administrative unit, ['P131']], 'main subject': [main subject, ['P921']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 188\n",
      "->Computing possible paths \tRunning time is 48.88s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 124\n",
      "->\tRunning time is 3.47s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q10864048', 5.869931887384605]]\n",
      "->Computing hypothesises \tRunning time is 16.18s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 12\n",
      "->\tRunning time is 4.5s\n",
      "--> len(cleared_golden_paths): 6\n",
      "---> First path: ['Q10864048', 'P131', 'Q6256', 'P17', 'Q258', 'P921', 'Q28754705']\n",
      "->\tTotal Running time is 148.16s\n",
      "\n",
      "df_graphqa Q10864048\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                        question   answer  \\\n",
      "264             528    2       False  Who is the current head coach?  Q509165   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "264  soccer   False           0.6         0.0    False            0.2   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "264          0.0  False       194.63        0.0  Q10864048         148.4   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "264        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "264         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-265-ic528-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 529/2240 -> 3/5 -> Convex=True: (Q509165) Who is the current head coach?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q5177360\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q6256\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                        question   answer  \\\n",
      "265             528    2        True  Who is the current head coach?  Q509165   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "265  soccer   False          0.59         0.0    False           0.24   \n",
      "\n",
      "     platypus_rr    convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "265          0.0  Q5177360         0.04        0.0   Q6256          1.67   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "265        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "265         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-266-ic528-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:54:21.482577\n",
      "\t>>> Processing 529/2240 -> 4/5 -> Convex=False: (Q18543) What league does this club belong to?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What league does this club belong to?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What league does this club belong to \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What league does this club belong to\n",
      "-> q_themes: ([(league, ['Q13530508', 'P118']), (League, ['Q12770238', 'Q37436664']), (club, ['Q988108', 'Q1076626'])], [this club, This Club, this Club])\n",
      "-> q_themes_enhanced: [('Club', ['Q1280895'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "behold: get_most_similar started with: belong\n",
      "-> q_predicates: [(does, []), (belong, []), (league, [])]\n",
      "-> q_predicates \tRunning time is 7.11s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (does, [])]\n",
      "----> q_themes in context: ([(league, ['Q13530508', 'P118']), (League, ['Q12770238', 'Q37436664']), (club, ['Q988108', 'Q1076626'])], [this, This])\n",
      "--> Potential meaningful keywords for the sentence: ['league', 'League', 'club', 'Club']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['league', 'League', 'club', 'Club', 'Country Music', 'English', '2010-04-20T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [league, League, club, Club, Country Music, English, 2010 04 20T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(league, ['P118', 'Q13530508']), (League, ['Q12770238', 'Q37436664']), (club, ['Q1076626']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(league, ['P118', 'Q13530508']), (League, ['Q12770238', 'Q37436664']), (club, ['Q1076626']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.95s\n",
      "-->  14 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 14 nodes and 14 edges\n",
      "-> predicates_dict: {'P407': 532, 'P577': 4, 'P1013': 2, 'P571': 2, 'P31': 10, 'P734': 1, 'P108': 1, 'P155': 3, 'P156': 3, 'P17': 3, 'P131': 1, 'P282': 1, 'P910': 1, 'P641': 1}\n",
      "-> paths_keywords: (['league', 'club', 'country music', 'english', 'belong'], {'language of work or name': [language of work or name, ['P407']], 'league': [league, ['P118']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 192\n",
      "->Computing possible paths \tRunning time is 78.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 68\n",
      "->\tRunning time is 3.47s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q482994', 0.7981966848058079]]\n",
      "->Computing hypothesises \tRunning time is 9.73s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 4.91s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q482994', 'P31', 'Q5177360', 'P156', 'Q4743416']\n",
      "->\tTotal Running time is 129.81s\n",
      "\n",
      "df_convex Q482994\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What league does this club belong to?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What league does this club belong to \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What league does this club belong to\n",
      "-> q_themes: ([(league, ['Q13530508', 'P118']), (League, ['Q12770238', 'Q37436664']), (club, ['Q988108', 'Q1076626'])], [this club, This Club, this Club])\n",
      "-> q_themes_enhanced: [('Club', ['Q1280895'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: do\n",
      "behold: get_most_similar started with: belong\n",
      "-> q_predicates: [(does, []), (belong, []), (league, [])]\n",
      "-> q_predicates \tRunning time is 6.06s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (does, []), (is in the administrative unit, ['P131']), (main subject, ['P921'])]\n",
      "----> q_themes in context: ([(league, ['Q13530508', 'P118']), (League, ['Q12770238', 'Q37436664']), (club, ['Q988108', 'Q1076626'])], [this, This])\n",
      "--> Potential meaningful keywords for the sentence: ['league', 'League', 'club', 'Club']\n",
      "---> Meaningful keywords enhanced by previous context: ['league', 'League', 'club', 'Club', 'country', 'South Africa', 'first-level administrative country subdivision', 'South Africa', 'South Africa', 'country']\n",
      "meaningful_names_no_previous_answer [league, League, club, Club, country, South Africa, first level administrative country subdivision, South Africa, South Africa, country]\n",
      "----> Meaningful keywords casted as theme ([(league, ['P118', 'Q13530508']), (League, ['Q12770238', 'Q37436664']), (club, ['Q1076626']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(league, ['P118', 'Q13530508']), (League, ['Q12770238', 'Q37436664']), (club, ['Q1076626']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 57.04s\n",
      "-->  13 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 14 edges\n",
      "-> predicates_dict: {'P17': 5, 'P131': 4, 'P138': 2, 'P150': 2, 'P921': 6, 'P31': 87, 'P1963': 4, 'P1282': 1, 'P1545': 1, 'P279': 1, 'P910': 2, 'P495': 1, 'P360': 2, 'P361': 1, 'P1013': 2, 'P571': 1, 'P373': 1, 'P282': 1, 'P527': 1, 'P813': 1, 'P973': 1, 'P1709': 1, 'P2341': 1, 'P2452': 4, 'P115': 1, 'P433': 1, 'P641': 1, 'P577': 1, 'P1476': 1}\n",
      "-> paths_keywords: (['league', 'club', 'country', 'south africa', 'belong'], {'country': [country, ['P17']], 'is in the administrative unit': [is in the administrative unit, ['P131']], 'main subject': [main subject, ['P921']], 'league': [league, ['P118']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 106\n",
      "->Computing possible paths \tRunning time is 23.95s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 74\n",
      "->\tRunning time is 3.42s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q10864048', 5.920702215612367]]\n",
      "->Computing hypothesises \tRunning time is 17.17s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 12\n",
      "->\tRunning time is 4.63s\n",
      "--> len(cleared_golden_paths): 6\n",
      "---> First path: ['Q10864048', 'P131', 'Q6256', 'P17', 'Q258', 'P921', 'Q28754705']\n",
      "->\tTotal Running time is 115.76s\n",
      "\n",
      "df_graphqa Q10864048\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                               question  \\\n",
      "266             528    3       False  What league does this club belong to?   \n",
      "\n",
      "     answer  domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "266  Q18543  soccer   False          0.55         0.0    False           1.61   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "266          0.0  Q482994       130.06        0.0  Q10864048        116.01   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "266        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "266         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-267-ic528-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 529/2240 -> 4/5 -> Convex=True: (Q18543) What league does this club belong to?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q5177360\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q6614071\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                               question  \\\n",
      "267             528    3        True  What league does this club belong to?   \n",
      "\n",
      "     answer  domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "267  Q18543  soccer   False          0.47         0.0    False           1.62   \n",
      "\n",
      "     platypus_rr    convex  convex_time  convex_rr   graphqa  graphqa_time  \\\n",
      "267          0.0  Q5177360         0.04        0.0  Q6614071           2.0   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "267        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "267         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-268-ic528-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-06 23:58:33.881044\n",
      "\t>>> Processing 529/2240 -> 5/5 -> Convex=False: (Q1133456) Name of owner?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Name of owner?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name of owner \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Name of owner\n",
      "-> q_themes: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(name, [])]\n",
      "-> q_predicates \tRunning time is 3.2s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (name, []), (followed by, ['P156'])]\n",
      "----> q_themes in context: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Name', 'Owner', 'name']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['Name', 'Owner', 'name', 'Country Music', 'Album', 'Country Music', 'American Classic', 'English', '2010-04-20T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Name, Owner, name, Country Music, Album, Country Music, American Classic, English, 2010 04 20T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (American Classic, ['Q4743416']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (American Classic, ['Q4743416']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.45s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 20, 'P156': 8, 'P407': 533, 'P577': 7, 'P155': 5, 'P1013': 1, 'P734': 1, 'P361': 1, 'P571': 1, 'P279': 1, 'P175': 1, 'P17': 2, 'P282': 1, 'P264': 3, 'P1705': 1, 'P910': 2, 'P108': 1, 'P39': 1, 'P373': 1}\n",
      "-> paths_keywords: (['name', 'owner', 'country music', 'album', 'american classic', 'english'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 130.38s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.47s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Name of owner?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name of owner \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Name instance of of owner\n",
      "-> q_themes: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(name, []), (Name, ['P735', 'P1448']), (owner, ['P127', 'P1830'])]\n",
      "-> q_predicates \tRunning time is 3.21s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (name, []), (Name, ['P735', 'P1448']), (owner, ['P127', 'P1830']), (followed by, ['P156'])]\n",
      "----> q_themes in context: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Name', 'Owner', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Name', 'Owner', 'name', 'Country Music', 'Album', 'Country Music', 'American Classic', 'English', '2010-04-20T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Name, Owner, name, Country Music, Album, Country Music, American Classic, English, 2010 04 20T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (American Classic, ['Q4743416']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])], [])\n",
      "q_focused_parts: [(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (Country Music, ['Q5177361', 'Q5177360', 'Q5177359']), (American Classic, ['Q4743416']), (English, ['Q1219933', 'Q12261586', 'Q11616958'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 15.24s\n",
      "-->  9 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 10 edges\n",
      "-> predicates_dict: {'P31': 20, 'P156': 8, 'P407': 533, 'P577': 10, 'P734': 1, 'P39': 1, 'P155': 6, 'P1013': 1, 'P361': 1, 'P571': 1, 'P279': 1, 'P175': 1, 'P17': 2, 'P282': 1, 'P264': 4, 'P1705': 1, 'P131': 1, 'P910': 2, 'P108': 1, 'P373': 1}\n",
      "-> paths_keywords: (['name', 'owner', 'country music', 'album', 'american classic', 'english', 'instance', 'of'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 140\n",
      "->Computing possible paths \tRunning time is 57.38s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 76\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 5.52s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 88.41s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Name of owner?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name of owner \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Name of owner\n",
      "-> q_themes: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(name, [])]\n",
      "-> q_predicates \tRunning time is 3.13s\n",
      "--> Predicates enhanced by previous context: [(country, ['P17']), (name, []), (is in the administrative unit, ['P131']), (main subject, ['P921'])]\n",
      "----> q_themes in context: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Name', 'Owner', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Name', 'Owner', 'name', 'country', 'South Africa', 'first-level administrative country subdivision', 'South Africa', 'South Africa', 'country']\n",
      "meaningful_names_no_previous_answer [Name, Owner, name, country, South Africa, first level administrative country subdivision, South Africa, South Africa, country]\n",
      "----> Meaningful keywords casted as theme ([(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 45.01s\n",
      "-->  13 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 14 edges\n",
      "-> predicates_dict: {'P17': 3, 'P131': 4, 'P138': 2, 'P150': 2, 'P921': 6, 'P31': 89, 'P1963': 4, 'P155': 1, 'P156': 1, 'P1013': 1, 'P1282': 1, 'P1545': 1, 'P279': 2, 'P734': 1, 'P910': 3, 'P360': 3, 'P361': 2, 'P373': 1, 'P282': 1, 'P39': 1, 'P527': 1, 'P813': 1, 'P1709': 1, 'P973': 1, 'P1476': 1, 'P1705': 1, 'P2452': 4, 'P264': 1, 'P577': 1}\n",
      "-> paths_keywords: (['name', 'owner', 'country', 'south africa'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.16s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.45s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Name of owner?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Name of owner \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Name is in the administrative unit of owner\n",
      "-> q_themes: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(name, []), (Name, ['P735', 'P1448']), (owner, ['P127', 'P1830'])]\n",
      "-> q_predicates \tRunning time is 3.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Predicates enhanced by previous context: [(country, ['P17']), (name, []), (Name, ['P735', 'P1448']), (owner, ['P127', 'P1830']), (is in the administrative unit, ['P131']), (main subject, ['P921'])]\n",
      "----> q_themes in context: ([(Name, ['Q82799', 'Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Name', 'Owner', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Name', 'Owner', 'name', 'country', 'South Africa', 'first-level administrative country subdivision', 'South Africa', 'South Africa', 'country']\n",
      "meaningful_names_no_previous_answer [Name, Owner, name, country, South Africa, first level administrative country subdivision, South Africa, South Africa, country]\n",
      "----> Meaningful keywords casted as theme ([(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])], [])\n",
      "q_focused_parts: [(Name, ['Q11236330']), (Owner, ['Q37498100', 'Q18574339']), (name, ['P2561', 'Q503992']), (country, ['P17', 'Q6256']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (South Africa, ['Q55155433', 'Q258', 'Q28754705']), (country, ['P17', 'Q6256'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 59.05s\n",
      "-->  13 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 14 edges\n",
      "-> predicates_dict: {'P17': 3, 'P131': 4, 'P138': 2, 'P150': 2, 'P921': 6, 'P31': 89, 'P1963': 10, 'P734': 1, 'P39': 1, 'P155': 1, 'P156': 2, 'P1013': 1, 'P1282': 1, 'P1545': 1, 'P279': 2, 'P910': 3, 'P360': 3, 'P361': 2, 'P373': 1, 'P282': 1, 'P577': 2, 'P813': 1, 'P527': 3, 'P973': 1, 'P1709': 1, 'P1476': 1, 'P1705': 1, 'P2452': 4, 'P264': 1}\n",
      "-> paths_keywords: (['name', 'owner', 'country', 'south africa', 'is', 'unit'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 146\n",
      "->Computing possible paths \tRunning time is 36.7s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 88\n",
      "->\tRunning time is 3.41s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q10864048', 0.8586134740101251]]\n",
      "->Computing hypothesises \tRunning time is 13.93s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 3.52s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q10864048', 'P131', 'Q6256', 'P17', 'Q258', 'P921', 'Q28754705']\n",
      "->\tTotal Running time is 123.33s\n",
      "\n",
      "df_graphqa Q10864048\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex        question    answer  domain  \\\n",
      "268             528    4       False  Name of owner?  Q1133456  soccer   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "268   False          0.36         0.0    False           0.78          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr    graphqa  graphqa_time graphqa_top2  \\\n",
      "268  False       239.66        0.0  Q10864048        304.74        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "268        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-269-ic528-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 529/2240 -> 5/5 -> Convex=True: (Q1133456) Name of owner?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q5177360\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa P138\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex        question    answer  domain  \\\n",
      "269             528    4        True  Name of owner?  Q1133456  soccer   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "269   False          0.35         0.0    False           0.84          0.0   \n",
      "\n",
      "       convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "269  Q5177360         0.03        0.0    P138          3.47        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "269        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-270-ic528-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 00:07:44.152052\n",
      "\t>>> Processing 530/2240 -> 1/5 -> Convex=False: (Q483810) When were The Cranberries formed?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q2704746\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q2704746\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: When were The Cranberries formed?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When we 're The Cranberries formed \n",
      "> Time related question detected\n",
      "-> q_themes: ([(The Cranberries, ['Q483810']), (cranberry, ['Q13181']), (Cranberries, ['Q5181883'])], [the cranberry form])\n",
      "-> q_themes_enhanced: [('form', ['Q1335296']), ('The Form', ['Q52926591']), ('Cranberry', ['Q11299097']), ('Form', ['Q52926591'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (formed, ['P571'])]\n",
      "-> q_predicates \tRunning time is 4.85s\n",
      "--> Potential meaningful keywords for the sentence: ['The Cranberries', 'cranberry', 'Cranberries', 'form', 'The Form', 'Cranberry', 'Form']\n",
      "q_focused_parts: [(The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.71s\n",
      "-->  108 nodes and 106 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 108 nodes and 106 edges\n",
      "-> predicates_dict: {'P1686': 2, 'P585': 2, 'P166': 2, 'P405': 1, 'P574': 1, 'P225': 1, 'P2031': 1, 'P2032': 1, 'P571': 3, 'P31': 16, 'P1672': 1, 'P527': 3, 'P101': 1, 'P4000': 1, 'P463': 3, 'P625': 1, 'P159': 1, 'P2096': 1, 'P276': 2, 'P1843': 2, 'P304': 1, 'P478': 1, 'P1343': 1, 'P1454': 1, 'P17': 1, 'P3744': 1, 'P2002': 1}\n",
      "-> paths_keywords: (['the cranberries', 'cranberry', 'cranberries'], {'instance of': [instance of, ['P31']], 'date of foundation or creation': [date of foundation or creation, ['P571']]}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 172\n",
      "->Computing possible paths \tRunning time is 11.73s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 158\n",
      "->\tRunning time is 3.48s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['1995-01-01T00:00:00Z', 7.7833333213099465], ['1996-01-01T00:00:00Z', 7.782811469277821], ['2018-01-01T00:00:00Z', 6.9905483635803884], ['1990-01-01T00:00:00Z', 6.73638454670552], ['2016-01-01T00:00:00Z', 2.503657276669664], ['1977-09-01T00:00:00Z', 2.3194692442168123], ['1989-01-01T00:00:00Z', 2.3190047286979873], ['Q52926591', 1.0298772209202067], ['Q56013707', 0.9304700504076528], ['Q47123453', 0.8958221495161743], ['Q28028217', 0.8093328327694937], ['Q20204912', 0.7977043204815821], ['Q50823049', 0.780234686070477], ['Q5741069', 0.7139794678536351], ['Q1335296', 0.6326191337443399], ['Q4830453', 0.5883402568226785], ['Q5967582', 0.4552030769911952], ['Q655870', 0.4545667432981107], ['Q5424324', 0.43793811402707106], ['Q5974905', 0.2934334867177057], ['Q7117828', 0.2934334867177057]]\n",
      "->Computing hypothesises \tRunning time is 66.09s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 8\n",
      "->\tRunning time is 14.24s\n",
      "--> len(cleared_golden_paths): 4\n",
      "---> First path: ['1995-01-01T00:00:00Z', 'P585', 'Q483810', 'P31', 'Q5741069']\n",
      "->\tTotal Running time is 124.57s\n",
      "\n",
      "df_graphqa 1995-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "270             529    0       False  When were The Cranberries formed?   \n",
      "\n",
      "      answer domain   qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "270  Q483810  music  Q2704746          0.54         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr    convex  convex_time  convex_rr  \\\n",
      "270           0.72          0.0  Q2704746         0.65        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "270  1995-01-01T00:00:00Z        124.82        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "270        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-271-ic529-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 00:09:50.916717\n",
      "\t>>> Processing 530/2240 -> 2/5 -> Convex=False: (Q541599) Who sang?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who sang?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 1.0s\n",
      "--> Predicates enhanced by previous context: [(sang, [])]\n",
      "----> q_themes in context: ([(Noel Hogan, ['Q2704746'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Noel Hogan']\n",
      "---> Meaningful keywords enhanced by previous context: ['Noel Hogan', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [Noel Hogan, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(Noel Hogan, ['Q2704746']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(Noel Hogan, ['Q2704746']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 8.76s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who sang?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 0.99s\n",
      "--> Predicates enhanced by previous context: [(sang, [])]\n",
      "----> q_themes in context: ([(Noel Hogan, ['Q2704746'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Noel Hogan']\n",
      "---> Meaningful keywords enhanced by previous context: ['Noel Hogan', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [Noel Hogan, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(Noel Hogan, ['Q2704746']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(Noel Hogan, ['Q2704746']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 7.73s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who sang?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 1.04s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (sang, [])]\n",
      "----> q_themes in context: ([(Noel Hogan, ['Q2704746'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Noel Hogan']\n",
      "---> Meaningful keywords enhanced by previous context: ['Noel Hogan', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [Noel Hogan, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(Noel Hogan, ['Q2704746']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(Noel Hogan, ['Q2704746']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 17.25s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P463': 50, 'P31': 1, 'P1686': 2, 'P585': 2, 'P166': 2, 'P3744': 1, 'P2002': 1, 'P136': 3, 'P264': 1, 'P106': 2, 'P676': 1, 'P175': 3}\n",
      "-> paths_keywords: (['noel hogan', 'the cranberries'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 128.28s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who sang?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 1.13s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (sang, [])]\n",
      "----> q_themes in context: ([(Noel Hogan, ['Q2704746'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Noel Hogan']\n",
      "---> Meaningful keywords enhanced by previous context: ['Noel Hogan', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [Noel Hogan, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(Noel Hogan, ['Q2704746']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(Noel Hogan, ['Q2704746']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.37s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P463': 50, 'P31': 1, 'P1686': 2, 'P585': 2, 'P166': 2, 'P3744': 1, 'P2002': 1, 'P136': 3, 'P264': 1, 'P106': 2, 'P676': 1, 'P175': 3}\n",
      "-> paths_keywords: (['noel hogan', 'the cranberries'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 118.27s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.51s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 140.83s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who sang?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 1.07s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (sang, []), (instance of, ['P31'])]\n",
      "----> q_themes in context: ([(1995 - 01 01T00:00:00Z, ['1995-01-01T00:00:00Z'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['1995 - 01 01T00:00:00Z']\n",
      "---> Meaningful keywords enhanced by previous context: ['1995 - 01 01T00:00:00Z', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [1995 - 01 01T00:00:00Z, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 62.0s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 2296, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P571': 1, 'P3744': 1, 'P2002': 1, 'P910': 2, 'P279': 1, 'P136': 5, 'P373': 1, 'P175': 3}\n",
      "-> paths_keywords: (['the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 118.46s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who sang?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: Who sang \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who sang\n",
      "-> q_themes: ([], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: sing\n",
      "-> q_predicates: [(sang, [])]\n",
      "-> q_predicates \tRunning time is 1.05s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (sang, []), (instance of, ['P31'])]\n",
      "----> q_themes in context: ([(1995 - 01 01T00:00:00Z, ['1995-01-01T00:00:00Z'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['1995 - 01 01T00:00:00Z']\n",
      "---> Meaningful keywords enhanced by previous context: ['1995 - 01 01T00:00:00Z', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [1995 - 01 01T00:00:00Z, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 60.98s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 2296, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P571': 1, 'P3744': 1, 'P2002': 1, 'P910': 2, 'P279': 1, 'P136': 5, 'P373': 1, 'P175': 3}\n",
      "-> paths_keywords: (['the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 118.25s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 187.34s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex   question   answer domain qanswer  \\\n",
      "271             529    1       False  Who sang?  Q541599  music   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "271         18.94         0.0    False           0.19          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "271       291.54        0.0   False        373.05        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "271        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-272-ic529-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 530/2240 -> 2/5 -> Convex=True: (Q541599) Who sang?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 612941\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 612941\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1989-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex   question   answer domain qanswer  \\\n",
      "272             529    1        True  Who sang?  Q541599  music  612941   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  convex  \\\n",
      "272          0.14         0.0    False           2.02          0.0  612941   \n",
      "\n",
      "     convex_time  convex_rr               graphqa  graphqa_time graphqa_top2  \\\n",
      "272         0.25        0.0  1989-01-01T00:00:00Z          1.63        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "272        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-273-ic529-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 00:21:18.723482\n",
      "\t>>> Processing 530/2240 -> 3/5 -> Convex=False: (Q2704746) Who played guitar?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.87s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741'])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.38s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: guitar\n",
      "-> q_predicates: [(played, ['P741']), (guitar, [])]\n",
      "-> q_predicates \tRunning time is 2.66s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741']), (guitar, [])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.52s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.83s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 15.76s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P31': 2, 'P156': 2, 'P1686': 2, 'P585': 2, 'P166': 2, 'P1013': 1, 'P3744': 1, 'P2002': 1, 'P577': 1, 'P136': 4, 'P1303': 2, 'P2031': 1, 'P527': 5, 'P264': 1, 'P155': 1, 'P106': 2, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries', 'noel hogan'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 122.31s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.53s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: guitar\n",
      "-> q_predicates: [(played, ['P741']), (guitar, [])]\n",
      "-> q_predicates \tRunning time is 2.85s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (played, ['P741']), (guitar, [])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 15.82s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P1303': 2, 'P1013': 1, 'P155': 1, 'P156': 2, 'P106': 3, 'P31': 3, 'P136': 5, 'P1686': 2, 'P585': 2, 'P166': 2, 'P3744': 1, 'P2002': 1, 'P577': 1, 'P2031': 1, 'P527': 5, 'P264': 1, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries', 'noel hogan'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 123.34s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.51s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 149.18s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.95s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 56.99s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 4, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P156': 2, 'P1013': 1, 'P136': 5, 'P1303': 1, 'P373': 1, 'P910': 1, 'P155': 1, 'P527': 3, 'P279': 1, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 121.3s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: guitar\n",
      "-> q_predicates: [(played, ['P741']), (guitar, [])]\n",
      "-> q_predicates \tRunning time is 2.97s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741']), (guitar, [])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 58.17s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 5, 'P1686': 2, 'P166': 2, 'P1013': 1, 'P1303': 1, 'P155': 1, 'P156': 2, 'P2032': 1, 'P2031': 1, 'P136': 6, 'P373': 1, 'P910': 1, 'P527': 3, 'P279': 1, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 127.85s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.59s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 195.6s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex            question    answer domain  \\\n",
      "273             529    2       False  Who played guitar?  Q2704746  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "273   False          28.9         0.0    False           0.52          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "273  False       294.26        0.0   False        381.04        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "273        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-274-ic529-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 530/2240 -> 3/5 -> Convex=True: (Q2704746) Who played guitar?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q6607\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q6607\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q5616814\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex            question    answer domain  \\\n",
      "274             529    2        True  Who played guitar?  Q2704746  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "274   Q6607          0.05         0.0    False           0.47          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr   graphqa  graphqa_time graphqa_top2  \\\n",
      "274  Q6607         0.21        0.0  Q5616814          1.91        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "274        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-275-ic529-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 00:33:06.160024\n",
      "\t>>> Processing 530/2240 -> 4/5 -> Convex=False: (Q653087) Who played drums?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.84s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741'])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.61s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: drum\n",
      "-> q_predicates: [(played, ['P741']), (drums, [])]\n",
      "-> q_predicates \tRunning time is 3.09s\n",
      "--> Predicates enhanced by previous context: [(played, ['P741']), (drums, [])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.47s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.85s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.83s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P373': 4, 'P361': 2, 'P31': 7, 'P805': 1, 'P1343': 1, 'P1686': 2, 'P585': 2, 'P166': 2, 'P3744': 1, 'P2002': 1, 'P577': 1, 'P1303': 1, 'P2031': 1, 'P279': 3, 'P136': 4, 'P527': 6, 'P264': 1, 'P910': 1, 'P935': 1, 'P106': 2, 'P4733': 1, 'P175': 1, 'P5008': 1}\n",
      "-> paths_keywords: (['drums', 'play', 'drum', 'the cranberries', 'noel hogan'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 142.61s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.67s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: drum\n",
      "-> q_predicates: [(played, ['P741']), (drums, [])]\n",
      "-> q_predicates \tRunning time is 3.08s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (played, ['P741']), (drums, [])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'The Cranberries', 'Noel Hogan']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.98s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P373': 4, 'P935': 1, 'P31': 8, 'P361': 2, 'P1303': 2, 'P805': 1, 'P1343': 1, 'P1686': 2, 'P585': 2, 'P166': 2, 'P3744': 1, 'P2002': 1, 'P577': 1, 'P106': 3, 'P136': 4, 'P2031': 1, 'P279': 3, 'P527': 6, 'P4733': 1, 'P264': 1, 'P910': 1, 'P175': 1, 'P5008': 1}\n",
      "-> paths_keywords: (['drums', 'play', 'drum', 'the cranberries', 'noel hogan'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.29s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 176.22s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.71s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 66.49s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 10, 'P1686': 2, 'P166': 2, 'P373': 5, 'P2032': 1, 'P2031': 1, 'P805': 1, 'P1343': 1, 'P910': 2, 'P577': 1, 'P136': 5, 'P279': 3, 'P5008': 1, 'P527': 4, 'P935': 1, 'P4733': 1, 'P175': 1}\n",
      "-> paths_keywords: (['drums', 'play', 'drum', 'the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 136.71s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.67s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played drums?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played drums \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played drums\n",
      "-> q_themes: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: drum\n",
      "-> q_predicates: [(played, ['P741']), (drums, [])]\n",
      "-> q_predicates \tRunning time is 3.0s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741']), (drums, [])]\n",
      "----> q_themes in context: ([(drums, ['Q3715553', 'Q1740029']), (Drums, ['Q30668018']), (play, ['Q25379', 'Q1150958']), (drum, ['Q11404', 'Q2738285'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['drums', 'Drums', 'play', 'drum']\n",
      "---> Meaningful keywords enhanced by previous context: ['drums', 'Drums', 'play', 'drum', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [drums, Drums, play, drum, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(drums, ['Q1740029']), (Drums, ['Q3715553', 'Q30668018']), (play, ['Q1150958']), (drum, ['Q11404', 'Q2738285']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 67.43s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 11, 'P373': 5, 'P935': 1, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P805': 1, 'P1343': 1, 'P910': 2, 'P577': 1, 'P136': 5, 'P279': 3, 'P4733': 1, 'P5008': 1, 'P1303': 1, 'P527': 4, 'P175': 1}\n",
      "-> paths_keywords: (['drums', 'play', 'drum', 'the cranberries', 'rock band'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 136.08s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 213.13s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex           question   answer domain  \\\n",
      "275             529    3       False  Who played drums?  Q653087  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "275   False         46.59         0.0    False           0.47          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "275  False       349.89        0.0   False        423.53        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "275        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-276-ic529-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 530/2240 -> 4/5 -> Convex=True: (Q653087) Who played drums?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q2704746\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q2704746\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q5309187\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex           question   answer domain  \\\n",
      "276             529    3        True  Who played drums?  Q653087  music   \n",
      "\n",
      "      qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "276  Q2704746          0.06         0.0    False           0.47          0.0   \n",
      "\n",
      "       convex  convex_time  convex_rr   graphqa  graphqa_time graphqa_top2  \\\n",
      "276  Q2704746         0.23        0.0  Q5309187          1.94        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "276        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-277-ic529-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 00:46:49.376448\n",
      "\t>>> Processing 530/2240 -> 5/5 -> Convex=False: (2019-01-01T00:00:00Z) What year did they disband?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did Noel Hogan disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 5.02s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.95s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did Noel Hogan disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.54s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.59s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 4.71s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.77s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P1686': 2, 'P585': 2, 'P166': 2, 'P571': 2, 'P2031': 1, 'P2032': 1, 'P569': 1, 'P642': 2, 'P279': 4, 'P31': 2, 'P740': 1, 'P3245': 1, 'P3250': 2, 'P19': 1, 'P527': 7, 'P407': 1, 'P443': 1, 'P3744': 1, 'P2002': 1, 'P1013': 2, 'P576': 1, 'P1672': 1, 'P180': 1, 'P1709': 1, 'P106': 3, 'P186': 1, 'P373': 1, 'P136': 1}\n",
      "-> paths_keywords: (['date', 'the cranberries', 'noel hogan'], {'member of': [member of, ['P463']], 'stated in': [stated in, ['P248']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.79s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.69s\n",
      "--> Predicates enhanced by previous context: [(member of, ['P463']), (did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', 'Noel Hogan']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, Noel Hogan]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (Noel Hogan, ['Q2704746'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 25.36s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P463': 50, 'P1686': 2, 'P585': 2, 'P166': 2, 'P571': 2, 'P2031': 1, 'P2032': 1, 'P569': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P642': 2, 'P279': 4, 'P19': 1, 'P3245': 1, 'P3250': 2, 'P31': 2, 'P740': 1, 'P407': 1, 'P443': 1, 'P1013': 2, 'P527': 7, 'P3744': 1, 'P2002': 1, 'P1709': 1, 'P576': 1, 'P106': 3, 'P136': 1, 'P373': 1}\n",
      "-> paths_keywords: (['date', 'the cranberries', 'noel hogan'], {'member of': [member of, ['P463']], 'stated in': [stated in, ['P248']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.22s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 178.77s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 4.59s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 67.92s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 5, 'P1686': 2, 'P166': 2, 'P571': 2, 'P2031': 1, 'P2032': 1, 'P3245': 1, 'P3250': 2, 'P407': 1, 'P443': 1, 'P740': 1, 'P527': 4, 'P642': 2, 'P279': 4, 'P1013': 2, 'P910': 1, 'P1709': 1, 'P373': 2, 'P1672': 1, 'P180': 1, 'P186': 1, 'P576': 1, 'P136': 3}\n",
      "-> paths_keywords: (['date', 'the cranberries', 'rock band'], {'point in time': [point in time, ['P585']], 'stated in': [stated in, ['P248']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.18s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.55s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', '1995-01-01T00:00:00Z', 'rock band']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, 1995 - 01 01T00:00:00Z, rock band]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810']), (rock band, ['Q5741069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 67.54s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P585': 3, 'P31': 5, 'P1686': 2, 'P166': 2, 'P571': 2, 'P2031': 1, 'P2032': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P3245': 1, 'P3250': 2, 'P407': 1, 'P443': 1, 'P740': 1, 'P1013': 2, 'P279': 4, 'P527': 4, 'P642': 2, 'P910': 1, 'P1709': 1, 'P373': 2, 'P3744': 1, 'P2002': 1, 'P576': 1, 'P136': 3}\n",
      "-> paths_keywords: (['date', 'the cranberries', 'rock band'], {'point in time': [point in time, ['P585']], 'stated in': [stated in, ['P248']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 136.43s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.11s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 215.91s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                     question  \\\n",
      "277             529    4       False  What year did they disband?   \n",
      "\n",
      "                   answer domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "277  2019-01-01T00:00:00Z  music   False         50.58         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "277           1.04          0.0  False       354.27        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "277        426.83        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "277          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-278-ic529-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 530/2240 -> 5/5 -> Convex=True: (2019-01-01T00:00:00Z) What year did they disband?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 1971-12-25T00:00:00Z\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q6314083\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q630808\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                     question  \\\n",
      "278             529    4        True  What year did they disband?   \n",
      "\n",
      "                   answer domain               qanswer  qanswer_time  \\\n",
      "278  2019-01-01T00:00:00Z  music  1971-12-25T00:00:00Z          0.04   \n",
      "\n",
      "     qanswer_rr platypus  platypus_time  platypus_rr    convex  convex_time  \\\n",
      "278         0.0    False           1.04          0.0  Q6314083         0.18   \n",
      "\n",
      "     convex_rr  graphqa  graphqa_time graphqa_top2 graphqa_top3 graphqa_top4  \\\n",
      "278        0.0  Q630808          1.54        False        False        False   \n",
      "\n",
      "    graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "278        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-279-ic529-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:00:44.935995\n",
      "\t>>> Processing 531/2240 -> 1/5 -> Convex=False: (1994-01-01T00:00:00Z) What year did Friends air?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q408\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What year did Friends air?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What date did Friends air \n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (air, ['Q7391292', 'Q318452']), (Air, ['Q11189065', 'Q11189067']), (Date, ['Q36603893', 'Q10467097']), (friends, ['Q79784']), (Friends, ['Q10717397', 'Q11092244'])], [Air date, What date did Friends, Did Friends, Friends air])\n",
      "-> q_themes_enhanced: [('air date', ['P577'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248'])]\n",
      "-> q_predicates \tRunning time is 7.04s\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'air', 'Air', 'Date', 'friends', 'Friends', 'air date']\n",
      "q_focused_parts: [(date, ['P837', 'Q1652093', 'Q3016931'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 45.25s\n",
      "-->  171 nodes and 166 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 171 nodes and 166 edges\n",
      "-> predicates_dict: {'P1686': 1, 'P585': 3, 'P1411': 4, 'P577': 1, 'P571': 3, 'P580': 1, 'P582': 1, 'P1441': 3, 'P1672': 1, 'P180': 1, 'P186': 3, 'P428': 1, 'P740': 1, 'P642': 3, 'P279': 5, 'P31': 10, 'P3245': 1, 'P3250': 2, 'P361': 4, 'P276': 1, 'P407': 2, 'P443': 1, 'P1114': 2, 'P1552': 1, 'P1011': 4, 'P3744': 1, 'P2002': 1, 'P1013': 3, 'P518': 2, 'P527': 7, 'P800': 1, 'P195': 1, 'P175': 2, 'P910': 1, 'P217': 1, 'P373': 1, 'P1709': 1, 'P136': 1}\n",
      "-> paths_keywords: (['date', 'air', 'friends'], {'stated in': [stated in, ['P248']], 'air date': [date of publication, ['P577']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 216\n",
      "->Computing possible paths \tRunning time is 58.74s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 352\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q516527', 6.115821745601731], ['Q388769', 5.789200388741708], ['Q436803', 5.560813353684561], ['Q10850896', 2.190084287752972], ['Q10375174', 1.59920471756563], ['01.22.13.000', 1.5170646903686889], ['Q134556', 1.3571840541614073], ['Q861259', 1.3113606742664803], ['Q652', 1.2596169171983107], ['Q3305213', 1.231182756091233], ['Q79529', 1.197149512283361], ['Q1860', 1.1601675694172064], ['Q12203234', 1.1401116583545632], ['Q215380', 1.1313812855832461], ['Q19184926', 1.0232095887487191], ['Q10346302', 1.012995446326372], ['Q11432', 0.9824302622699114], ['Q190120', 0.9312559235507178], ['Q169336', 0.8574254023863265], ['Q12310006', 0.7947351503989175], ['Q25292', 0.7495162831254991], ['Q36603893', 0.6843073987696071], ['Q5', 0.6843073987696071], ['Q27685', 0.6841957174276686], ['2004-05-06T00:00:00Z', 0.41420157560158555], ['1994-09-22T00:00:00Z', 0.3843216427236396], ['2000-01-01T00:00:00Z', 0.38140642952942133], ['1999-01-01T00:00:00Z', 0.355763382696002], ['2004-01-01T00:00:00Z', 0.2826740460159731], ['2011-04-27T00:00:00Z', 0.2566434102468053], ['01.13.21.111', 0.23987240166140375], ['Q696', 0.23456845764461853], ['Q1886522', 0.20778722307096328], ['1900-01-01T00:00:00Z', 0.1982895250142561], ['1995-01-01T00:00:00Z', 0.1947168233812232], ['1993-01-01T00:00:00Z', 0.1898100428480689], ['Q2370426', -0.27444435342952717]]\n",
      "->Computing hypothesises \tRunning time is 191.17s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 25\n",
      "->\tRunning time is 9.07s\n",
      "--> len(cleared_golden_paths): 12\n",
      "---> First path: ['2004-05-06T00:00:00Z', 'P582', 'Q79784', 'P585', '1999-01-01T00:00:00Z']\n",
      "->\tTotal Running time is 318.48s\n",
      "\n",
      "df_graphqa 2004-05-06T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                    question  \\\n",
      "279             530    0       False  What year did Friends air?   \n",
      "\n",
      "                   answer     domain qanswer  qanswer_time  qanswer_rr  \\\n",
      "279  1994-01-01T00:00:00Z  tv_series   False          0.78         0.0   \n",
      "\n",
      "    platypus  platypus_time  platypus_rr convex  convex_time  convex_rr  \\\n",
      "279    False           0.19          0.0   Q408         3.25        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "279  2004-05-06T00:00:00Z        318.74        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "279        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-280-ic530-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:06:07.928519\n",
      "\t>>> Processing 531/2240 -> 2/5 -> Convex=False: (Q32522) Who acted as Rachel Green?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who acted as Rachel Green?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Rachel Green \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Rachel Green\n",
      "-> q_themes: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted as Rachel])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 6.45s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Rachel Green', 'Green', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Rachel Green', 'Green', 'act', 'Act', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Rachel Green, Green, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Rachel Green, ['Q581353', 'Q47211943']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Rachel Green, ['Q581353', 'Q47211943']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533']), (Green, ['Q3133', 'Q2703137'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.11s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P495': 182, 'P31': 10, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1534': 1, 'P2842': 1, 'P26': 1, 'P364': 2, 'P569': 2, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P4908': 1, 'P21': 1, 'P161': 1, 'P136': 2, 'P155': 1, 'P1542': 1, 'P449': 1, 'P57': 2, 'P22': 1, 'P138': 1, 'P25': 1, 'P156': 1, 'P580': 1}\n",
      "-> paths_keywords: (['rachel green', 'australia', 'green'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.02s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.82s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Rachel Green?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Rachel Green \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Rachel Green\n",
      "-> q_themes: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted as Rachel])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.39s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Rachel Green', 'Green', 'act', 'Act']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['Rachel Green', 'Green', 'act', 'Act', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Rachel Green, Green, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Rachel Green, ['Q581353', 'Q47211943']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Rachel Green, ['Q581353', 'Q47211943']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533']), (Green, ['Q3133', 'Q2703137'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.52s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P495': 182, 'P31': 10, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1534': 1, 'P2842': 1, 'P26': 1, 'P364': 2, 'P569': 2, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P4908': 1, 'P21': 1, 'P161': 1, 'P136': 2, 'P155': 1, 'P1542': 1, 'P449': 1, 'P57': 2, 'P138': 1, 'P25': 1, 'P22': 1, 'P156': 1, 'P580': 1}\n",
      "-> paths_keywords: (['rachel green', 'australia', 'green'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.57s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 168.06s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who acted as Rachel Green?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Rachel Green \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Rachel Green\n",
      "-> q_themes: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted as Rachel])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.57s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453']), (end date, ['P582'])]\n",
      "----> q_themes in context: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Rachel Green', 'Green', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Rachel Green', 'Green', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Rachel Green, Green, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Rachel Green, ['Q581353', 'Q47211943']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Rachel Green, ['Q581353', 'Q47211943']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244']), (Green, ['Q3133', 'Q2703137'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 40.12s\n",
      "-->  8 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 10 edges\n",
      "-> predicates_dict: {'P585': 12, 'P582': 2, 'P1411': 27, 'P3831': 3, 'P453': 10, 'P161': 10, 'P580': 1, 'P1441': 4, 'P1011': 4, 'P407': 1, 'P1552': 1, 'P1114': 2, 'P1545': 3, 'P527': 3, 'P942': 1, 'P569': 1, 'P361': 2, 'P577': 2, 'P1534': 1, 'P2842': 1, 'P26': 1, 'P518': 1, 'P186': 2, 'P674': 4, 'P571': 1, 'P31': 5, 'P642': 1, 'P180': 1, 'P279': 2, 'P800': 1, 'P1542': 1, 'P1881': 1, 'P735': 1, 'P495': 1, 'P156': 3, 'P138': 1, 'P155': 1, 'P217': 1, 'P195': 1, 'P175': 1, 'P166': 10, 'P1346': 16}\n",
      "-> paths_keywords: (['rachel green', 'friends', 'green'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']], 'end date': [end date, ['P582']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 139.93s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Rachel Green?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Rachel Green \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Rachel Green\n",
      "-> q_themes: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted as Rachel])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.41s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453']), (end date, ['P582'])]\n",
      "----> q_themes in context: ([(Rachel Green, ['Q47211943', 'Q581353']), (Green, ['Q3133', 'Q2703137'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Rachel Green', 'Green', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Rachel Green', 'Green', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Rachel Green, Green, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Rachel Green, ['Q581353', 'Q47211943']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Rachel Green, ['Q581353', 'Q47211943']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244']), (Green, ['Q3133', 'Q2703137'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 40.17s\n",
      "-->  8 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 10 edges\n",
      "-> predicates_dict: {'P585': 12, 'P582': 2, 'P1411': 27, 'P3831': 3, 'P453': 10, 'P161': 10, 'P580': 1, 'P1441': 4, 'P1011': 4, 'P407': 1, 'P1552': 1, 'P1114': 2, 'P1545': 3, 'P527': 3, 'P942': 1, 'P569': 1, 'P361': 2, 'P577': 2, 'P1534': 1, 'P2842': 1, 'P26': 1, 'P518': 1, 'P186': 2, 'P674': 4, 'P571': 1, 'P31': 5, 'P642': 1, 'P180': 1, 'P279': 2, 'P800': 1, 'P1542': 1, 'P1881': 1, 'P495': 1, 'P735': 1, 'P156': 3, 'P138': 1, 'P155': 1, 'P195': 1, 'P217': 1, 'P175': 1, 'P166': 10, 'P1346': 16}\n",
      "-> paths_keywords: (['rachel green', 'friends', 'green'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']], 'end date': [end date, ['P582']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 140.74s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.83s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 192.92s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                    question  answer  \\\n",
      "280             530    1       False  Who acted as Rachel Green?  Q32522   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "280  tv_series   False           0.7         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "280          0.0  False        334.2        0.0   False        382.06   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "280        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "280         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-281-ic530-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 531/2240 -> 2/5 -> Convex=True: (Q32522) Who acted as Rachel Green?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q408\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q50758786\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                    question  answer  \\\n",
      "281             530    1        True  Who acted as Rachel Green?  Q32522   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "281  tv_series   False           0.7         0.0    False           0.23   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "281          0.0   Q408         0.03        0.0  Q50758786           1.1   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "281        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "281         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-282-ic530-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:18:07.181784\n",
      "\t>>> Processing 531/2240 -> 3/5 -> Convex=False: (Q58912) Who acted as Monica Geller?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who acted as Monica Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Monica Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Monica Geller\n",
      "-> q_themes: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Monica])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 6.72s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Monica Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Monica Geller', 'Geller', 'act', 'Act', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Monica Geller, Geller, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.67s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 181, 'P27': 1, 'P31': 10, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1013': 2, 'P364': 2, 'P569': 1, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P282': 1, 'P4908': 1, 'P21': 1, 'P161': 2, 'P136': 2, 'P734': 1, 'P155': 1, 'P1542': 1, 'P57': 2, 'P22': 2, 'P25': 1, 'P156': 1}\n",
      "-> paths_keywords: (['monica geller', 'geller', 'australia'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 131.13s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Monica Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Monica Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Monica Geller\n",
      "-> q_themes: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Monica])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.22s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Monica Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Monica Geller', 'Geller', 'act', 'Act', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Monica Geller, Geller, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.58s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 181, 'P27': 1, 'P31': 10, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1013': 2, 'P364': 2, 'P569': 1, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P282': 1, 'P4908': 1, 'P21': 1, 'P161': 2, 'P136': 2, 'P734': 1, 'P155': 1, 'P1542': 1, 'P57': 2, 'P22': 2, 'P156': 1, 'P25': 1}\n",
      "-> paths_keywords: (['monica geller', 'geller', 'australia'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 131.31s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 164.63s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who acted as Monica Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Monica Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Monica Geller\n",
      "-> q_themes: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Monica])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.5s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Monica Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Monica Geller', 'Geller', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Monica Geller, Geller, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 21.63s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P1441': 1, 'P361': 2, 'P1013': 2, 'P518': 1, 'P186': 2, 'P674': 1, 'P31': 6, 'P642': 1, 'P571': 1, 'P180': 1, 'P279': 1, 'P800': 1, 'P282': 1, 'P1542': 1, 'P27': 1, 'P495': 1, 'P156': 3, 'P161': 1, 'P734': 1, 'P22': 1, 'P155': 1, 'P195': 1, 'P217': 1, 'P175': 1}\n",
      "-> paths_keywords: (['monica geller', 'geller', 'friends'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.72s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Monica Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Monica Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Monica Geller\n",
      "-> q_themes: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Monica])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.12s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Monica Geller, ['Q719866']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Monica Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Monica Geller', 'Geller', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Monica Geller, Geller, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Monica Geller, ['Q719866']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.8s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P1441': 1, 'P361': 2, 'P1013': 2, 'P518': 1, 'P186': 2, 'P674': 1, 'P31': 6, 'P642': 1, 'P571': 1, 'P180': 1, 'P279': 1, 'P800': 1, 'P282': 1, 'P1542': 1, 'P27': 1, 'P495': 1, 'P156': 3, 'P161': 1, 'P734': 1, 'P22': 1, 'P155': 1, 'P195': 1, 'P217': 1, 'P175': 1}\n",
      "-> paths_keywords: (['monica geller', 'geller', 'friends'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.21s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.7s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 166.55s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                     question  answer  \\\n",
      "282             530    2       False  Who acted as Monica Geller?  Q58912   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "282  tv_series   False          0.61         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "282          0.0  False       328.56        0.0   False        330.93   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "282        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "282         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-283-ic530-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 531/2240 -> 3/5 -> Convex=True: (Q58912) Who acted as Monica Geller?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q408\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q747424\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                     question  answer  \\\n",
      "283             530    2        True  Who acted as Monica Geller?  Q58912   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "283  tv_series   False          0.55         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr  graphqa  graphqa_time  \\\n",
      "283          0.0   Q408         0.02        0.0  Q747424          1.63   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "283        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "283         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-284-ic530-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:29:09.915438\n",
      "\t>>> Processing 531/2240 -> 4/5 -> Convex=False: (Q186896) Who played as Joey Tribbiani?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q186896\n",
      "df_qanswer_rr 1.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played as Joey Tribbiani?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played as Joey Tribbiani \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played as Joey Tribbiani\n",
      "-> q_themes: ([(Joey Tribbiani, ['Q746277'])], [played as Joey])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 6.01s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Joey Tribbiani, ['Q746277'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Joey Tribbiani', 'play', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Joey Tribbiani', 'play', 'Played', 'Play', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Joey Tribbiani, play, Played, Play, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Joey Tribbiani, ['Q746277']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Joey Tribbiani, ['Q746277']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.89s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 183, 'P27': 1, 'P373': 1, 'P31': 10, 'P569': 1, 'P577': 1, 'P2868': 1, 'P1441': 2, 'P1545': 3, 'P179': 1, 'P155': 1, 'P4908': 1, 'P21': 1, 'P364': 4, 'P910': 1, 'P2437': 1, 'P22': 1, 'P106': 2, 'P136': 2, 'P138': 3, 'P279': 1, 'P156': 1, 'P1113': 1, 'P86': 2, 'P161': 2, 'P25': 1, 'P462': 1, 'P2047': 1, 'P735': 1}\n",
      "-> paths_keywords: (['joey tribbiani', 'australia'], {'country of origin': [country of origin, ['P495']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.79s\n",
      "-> Filtering paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played as Joey Tribbiani?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played as Joey Tribbiani \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played as Joey Tribbiani\n",
      "-> q_themes: ([(Joey Tribbiani, ['Q746277'])], [played as Joey])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.45s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Joey Tribbiani, ['Q746277'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Joey Tribbiani', 'play', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Joey Tribbiani', 'play', 'Played', 'Play', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Joey Tribbiani, play, Played, Play, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Joey Tribbiani, ['Q746277']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Joey Tribbiani, ['Q746277']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.95s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 183, 'P27': 1, 'P373': 1, 'P31': 10, 'P569': 1, 'P577': 1, 'P2868': 1, 'P1441': 2, 'P1545': 3, 'P179': 1, 'P155': 1, 'P4908': 1, 'P21': 1, 'P364': 4, 'P910': 1, 'P2437': 1, 'P22': 1, 'P106': 2, 'P136': 2, 'P138': 3, 'P279': 1, 'P156': 1, 'P1113': 1, 'P86': 2, 'P161': 2, 'P25': 1, 'P462': 1, 'P2047': 1, 'P735': 1}\n",
      "-> paths_keywords: (['joey tribbiani', 'australia'], {'country of origin': [country of origin, ['P495']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.64s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.73s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 161.8s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "CORRECT 531 - 4 -> qAnswer Q186896\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played as Joey Tribbiani?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played as Joey Tribbiani \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played as Joey Tribbiani\n",
      "-> q_themes: ([(Joey Tribbiani, ['Q746277'])], [played as Joey])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.43s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Joey Tribbiani, ['Q746277'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Joey Tribbiani', 'play', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Joey Tribbiani', 'play', 'Played', 'Play', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Joey Tribbiani, play, Played, Play, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Joey Tribbiani, ['Q746277']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Joey Tribbiani, ['Q746277']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.72s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P2868': 1, 'P1441': 2, 'P373': 1, 'P361': 2, 'P518': 1, 'P186': 2, 'P31': 8, 'P364': 2, 'P571': 1, 'P910': 1, 'P155': 2, 'P27': 1, 'P495': 1, 'P106': 3, 'P156': 2, 'P2437': 1, 'P800': 1, 'P138': 3, 'P1113': 1, 'P136': 1, 'P175': 2, 'P86': 1, 'P462': 1, 'P161': 1, 'P195': 1, 'P217': 1, 'P1545': 2, 'P735': 2}\n",
      "-> paths_keywords: (['joey tribbiani', 'friends'], {'point in time': [point in time, ['P585']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.25s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played as Joey Tribbiani?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played as Joey Tribbiani \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played as Joey Tribbiani\n",
      "-> q_themes: ([(Joey Tribbiani, ['Q746277'])], [played as Joey])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.3s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Joey Tribbiani, ['Q746277'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Joey Tribbiani', 'play', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Joey Tribbiani', 'play', 'Played', 'Play', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Joey Tribbiani, play, Played, Play, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Joey Tribbiani, ['Q746277']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Joey Tribbiani, ['Q746277']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.83s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P2868': 1, 'P1441': 2, 'P373': 1, 'P361': 2, 'P518': 1, 'P186': 2, 'P31': 8, 'P364': 2, 'P571': 1, 'P910': 1, 'P155': 2, 'P27': 1, 'P495': 1, 'P106': 3, 'P156': 2, 'P2437': 1, 'P800': 1, 'P138': 3, 'P1113': 1, 'P136': 1, 'P175': 2, 'P86': 1, 'P161': 1, 'P195': 1, 'P462': 1, 'P217': 1, 'P1545': 2, 'P735': 2}\n",
      "-> paths_keywords: (['joey tribbiani', 'friends'], {'point in time': [point in time, ['P585']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 130.09s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.9s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 163.52s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                       question   answer  \\\n",
      "284             530    3       False  Who played as Joey Tribbiani?  Q186896   \n",
      "\n",
      "        domain  qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "284  tv_series  Q186896          0.76         1.0    False           0.18   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "284          0.0  False       322.96        0.0   False        322.36   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "284        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "284         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-285-ic530-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 531/2240 -> 4/5 -> Convex=True: (Q186896) Who played as Joey Tribbiani?                                  \n",
      "qAnswer extended by Convex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer Q319817\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q408\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q319817\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                       question   answer  \\\n",
      "285             530    3        True  Who played as Joey Tribbiani?  Q186896   \n",
      "\n",
      "        domain  qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "285  tv_series  Q319817           0.5         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr  graphqa  graphqa_time  \\\n",
      "285          0.0   Q408         0.03        0.0  Q319817          1.85   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "285        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "285         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-286-ic530-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:39:58.788934\n",
      "\t>>> Processing 531/2240 -> 5/5 -> Convex=False: (Q188792) Who acted as Ross Geller?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 5.35s\n",
      "--> Predicates enhanced by previous context: [(acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'Matt LeBlanc']\n",
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, Matt LeBlanc]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Matt LeBlanc, ['Q186896'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Matt LeBlanc, ['Q186896'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.94s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.05s\n",
      "--> Predicates enhanced by previous context: [(acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'Matt LeBlanc']\n",
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, Matt LeBlanc]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Matt LeBlanc, ['Q186896'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Matt LeBlanc, ['Q186896'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.71s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.04s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'What a Year', 'Australia']\n",
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.38s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 181, 'P27': 1, 'P31': 11, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1534': 1, 'P2842': 2, 'P26': 3, 'P1013': 2, 'P364': 2, 'P569': 1, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P282': 1, 'P4908': 1, 'P21': 1, 'P161': 2, 'P136': 2, 'P734': 1, 'P1542': 1, 'P155': 1, 'P57': 2, 'P22': 2, 'P25': 1, 'P156': 1}\n",
      "-> paths_keywords: (['ross geller', 'geller', 'australia'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.4s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.19s\n",
      "--> Predicates enhanced by previous context: [(country of origin, ['P495']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'What a Year', 'Australia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, What a date, Australia]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Australia, ['Q16246845', 'Q16746529', 'Q28734832', 'Q16835533'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.32s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P495': 181, 'P27': 1, 'P31': 11, 'P642': 1, 'P1441': 1, 'P674': 1, 'P1534': 1, 'P2842': 2, 'P26': 3, 'P1013': 2, 'P364': 2, 'P569': 1, 'P180': 1, 'P279': 1, 'P577': 1, 'P1545': 2, 'P179': 1, 'P282': 1, 'P4908': 1, 'P21': 1, 'P161': 2, 'P136': 2, 'P155': 1, 'P734': 1, 'P1542': 1, 'P57': 2, 'P22': 2, 'P25': 1, 'P156': 1}\n",
      "-> paths_keywords: (['ross geller', 'geller', 'australia'], {'country of origin': [country of origin, ['P495']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.77s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.72s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 166.91s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.12s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.11s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P1441': 1, 'P361': 2, 'P31': 7, 'P1534': 1, 'P2842': 2, 'P26': 3, 'P1013': 2, 'P518': 1, 'P186': 2, 'P674': 1, 'P642': 1, 'P571': 1, 'P180': 1, 'P279': 1, 'P800': 1, 'P282': 1, 'P1542': 1, 'P27': 1, 'P495': 1, 'P156': 3, 'P161': 1, 'P734': 1, 'P22': 1, 'P195': 1, 'P155': 1, 'P217': 1, 'P175': 1}\n",
      "-> paths_keywords: (['ross geller', 'geller', 'friends'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.12s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who acted as Ross Geller?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who acted as Ross Geller \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who acted as Ross Geller\n",
      "-> q_themes: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted as Ross])\n",
      "-> q_themes_enhanced: [('act', ['Q13200882']), ('Act', ['Q12961262'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: act\n",
      "-> q_predicates: [(acted, ['P2868', 'P453'])]\n",
      "-> q_predicates \tRunning time is 4.08s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (acted, ['P2868', 'P453'])]\n",
      "----> q_themes in context: ([(Ross Geller, ['Q747424']), (Geller, ['Q1008955', 'Q21507050'])], [acted])\n",
      "--> Potential meaningful keywords for the sentence: ['Ross Geller', 'Geller', 'act', 'Act']\n",
      "---> Meaningful keywords enhanced by previous context: ['Ross Geller', 'Geller', 'act', 'Act', 'Friends', '1999-01-01T00:00:00Z', '2004-05-06T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Ross Geller, Geller, act, Act, Friends, 1999 - 01 01T00:00:00Z, 2004 - 05 06T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])], [])\n",
      "q_focused_parts: [(Ross Geller, ['Q747424']), (Geller, ['Q21507050', 'Q1008955']), (Friends, ['Q10717397', 'Q11092245', 'Q11092244'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.13s\n",
      "-->  4 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 4 nodes and 4 edges\n",
      "-> predicates_dict: {'P585': 2, 'P582': 1, 'P1441': 1, 'P361': 2, 'P31': 7, 'P1534': 1, 'P2842': 2, 'P26': 3, 'P1013': 2, 'P518': 1, 'P186': 2, 'P674': 1, 'P642': 1, 'P571': 1, 'P180': 1, 'P279': 1, 'P800': 1, 'P282': 1, 'P1542': 1, 'P27': 1, 'P495': 1, 'P156': 3, 'P161': 1, 'P734': 1, 'P22': 1, 'P155': 1, 'P195': 1, 'P217': 1, 'P175': 1}\n",
      "-> paths_keywords: (['ross geller', 'geller', 'friends'], {'point in time': [point in time, ['P585']], 'subject has role': [subject has role, ['P2868']], 'character role': [character role, ['P453']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.07s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.64s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.12s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 166.61s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                   question   answer  \\\n",
      "286             530    4       False  Who acted as Ross Geller?  Q188792   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "286  tv_series   False         67.52         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "286          0.0  False        331.2        0.0   False        331.46   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "286        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "286         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-287-ic530-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 531/2240 -> 5/5 -> Convex=True: (Q188792) Who acted as Ross Geller?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 27222\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q408\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q188792\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 531 - 5 -> graphqa Q188792\n",
      "\n",
      "PARTIAL_CORRECT 531 - 5 -> graphqa in answers ['Q188792', 'Q2043428', 'Q1765879']\n",
      "    conversation_id turn plus_convex                   question   answer  \\\n",
      "287             530    4        True  Who acted as Ross Geller?  Q188792   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "287  tv_series   27222          0.76         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr  graphqa  graphqa_time  \\\n",
      "287          0.0   Q408         0.03        0.0  Q188792          2.68   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "287         True         True         True         True           True   \n",
      "\n",
      "     graphqa_rr  \n",
      "287         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-288-ic530-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:52:12.880313\n",
      "\t>>> Processing 532/2240 -> 1/5 -> Convex=False: (Q483810) What is the creation date of The Cranberries?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex urn:lsid:ipni.org:names:261956-2\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What is the creation date of The Cranberries?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the creation date of The Cranberries \n",
      "> Time related question detected\n",
      "-> q_themes: ([(The Cranberries, ['Q483810']), (Cranberries, ['Q5181883']), (the cranberry, ['Q51460792'])], [the creation date, is the creation date of The, The Creation Date, the Creation Date])\n",
      "-> q_themes_enhanced: [('creation date', ['P571']), ('creation', ['Q11398090']), ('date', ['Q1652093']), ('The Creation', ['Q1456447']), ('Creation', ['Q17001317']), ('Date', ['Q10467097'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: cranberry\n",
      "-> q_predicates: [(be, ['P31']), (creation, ['P571']), (date, ['P837']), (Cranberries, [])]\n",
      "-> q_predicates \tRunning time is 7.46s\n",
      "--> Potential meaningful keywords for the sentence: ['The Cranberries', 'Cranberries', 'the cranberry', 'creation date', 'creation', 'date', 'The Creation', 'Creation', 'Date']\n",
      "q_focused_parts: [(date, ['P837', 'Q1652093', 'Q3016931']), (creation, ['Q11398090', 'Q20004056', 'Q386724', 'Q16686448']), (The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.99s\n",
      "-->  127 nodes and 124 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 106 nodes and 104 edges\n",
      "-> predicates_dict: {'P1686': 2, 'P585': 2, 'P166': 2, 'P2031': 1, 'P2032': 1, 'P571': 3, 'P577': 2, 'P101': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P156': 1, 'P175': 1, 'P3712': 1, 'P407': 2, 'P443': 1, 'P3245': 1, 'P3250': 2, 'P31': 5, 'P642': 2, 'P279': 6, 'P1932': 2, 'P291': 1, 'P1013': 3, 'P1104': 1, 'P1476': 1, 'P527': 3, 'P1557': 1, 'P155': 1, 'P856': 1, 'P3744': 1, 'P2002': 1, 'P264': 1, 'P2093': 1, 'P136': 1, 'P576': 1, 'P366': 1, 'P1582': 1, 'P828': 1}\n",
      "-> paths_keywords: (['date', 'creation', 'the cranberries', 'cranberries', 'the cranberry', 'creative work', 'artificial entity'], {'instance of': [instance of, ['P31']], 'creation date': [date of foundation or creation, ['P571']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']], 'date of foundation or creation': [date of foundation or creation, ['P571']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 103\n",
      "->Computing possible paths \tRunning time is 63.41s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 122\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q2704746', 2.9276542429851617], ['Q541599', 2.8785341943267206], ['Q629995', 1.258521662987343], ['Q169298', 0.6286876690259295], ['Q836575', 0.4568213195697885], ['Q190', 0.40162503331044375], ['Q692096', 0.27815223031653624], ['1995-01-01T00:00:00Z', 0.2098521832349753], ['1996-01-01T00:00:00Z', 0.19983731407426183], ['1990-01-01T00:00:00Z', 0.19731294459693802], ['Q653087', 0.11150616515856157], ['1989-01-01T00:00:00Z', 0.06597673913254821], ['2018-01-01T00:00:00Z', 0.017861277784498125]]\n",
      "->Computing hypothesises \tRunning time is 54.58s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 21\n",
      "->\tRunning time is 7.2s\n",
      "--> len(cleared_golden_paths): 10\n",
      "---> First path: ['1995-01-01T00:00:00Z', 'P585', 'Q483810', 'P571', '1989-01-01T00:00:00Z']\n",
      "->\tTotal Running time is 165.41s\n",
      "\n",
      "df_graphqa 1995-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "288             531    0       False   \n",
      "\n",
      "                                          question   answer domain qanswer  \\\n",
      "288  What is the creation date of The Cranberries?  Q483810  music   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "288          0.83         0.0    False           0.69          0.0   \n",
      "\n",
      "                               convex  convex_time  convex_rr  \\\n",
      "288  urn:lsid:ipni.org:names:261956-2         2.13        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "288  1995-01-01T00:00:00Z        165.66        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "288        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-289-ic531-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 01:55:02.230324\n",
      "\t>>> Processing 532/2240 -> 2/5 -> Convex=False: (Q541599) Who was the singer?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who was the singer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the singer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was the singer\n",
      "-> q_themes: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: singer\n",
      "-> q_predicates: [(be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "-> q_predicates \tRunning time is 3.25s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "----> q_themes in context: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the singer', 'singer', 'Singer', 'The Singer']\n",
      "---> Meaningful keywords enhanced by previous context: ['the singer', 'singer', 'Singer', 'The Singer', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [the singer, singer, Singer, The Singer, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (Vaccinium oxycoccos, ['Q374399']), (the singer, ['Q2414234', 'Q3482673'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.91s\n",
      "-->  19 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 18 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P180': 3, 'P1013': 1, 'P800': 1, 'P31': 4, 'P571': 1, 'P407': 1, 'P1476': 1, 'P141': 1, 'P136': 3, 'P405': 1, 'P574': 1, 'P225': 1, 'P973': 1, 'P186': 1, 'P495': 1, 'P1843': 1, 'P195': 1, 'P217': 1, 'P170': 1, 'P734': 3, 'P1705': 1, 'P921': 1, 'P105': 1}\n",
      "-> paths_keywords: (['singer', 'the singer', 'vaccinium oxycoccos'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 131.33s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.48s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who was the singer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the singer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who Plants of the World online ID the singer\n",
      "-> q_themes: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: singer\n",
      "-> q_predicates: [(be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "-> q_predicates \tRunning time is 3.07s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "----> q_themes in context: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the singer', 'singer', 'Singer', 'The Singer']\n",
      "---> Meaningful keywords enhanced by previous context: ['the singer', 'singer', 'Singer', 'The Singer', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [the singer, singer, Singer, The Singer, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (Vaccinium oxycoccos, ['Q374399']), (the singer, ['Q2414234', 'Q3482673'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.22s\n",
      "-->  19 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 18 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P180': 3, 'P1013': 1, 'P800': 1, 'P31': 4, 'P571': 1, 'P407': 1, 'P1476': 1, 'P141': 1, 'P136': 3, 'P405': 1, 'P574': 1, 'P225': 1, 'P973': 1, 'P186': 1, 'P495': 1, 'P1843': 1, 'P195': 1, 'P217': 1, 'P170': 1, 'P734': 3, 'P1705': 1, 'P921': 1, 'P105': 1}\n",
      "-> paths_keywords: (['singer', 'the singer', 'vaccinium oxycoccos', 'plants'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.83s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.58s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 161.49s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who was the singer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the singer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was the singer\n",
      "-> q_themes: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: singer\n",
      "-> q_predicates: [(be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "-> q_predicates \tRunning time is 3.2s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (be, ['P31']), (singer, ['P86', 'P4757']), (date of foundation or creation, ['P571'])]\n",
      "----> q_themes in context: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the singer', 'singer', 'Singer', 'The Singer']\n",
      "---> Meaningful keywords enhanced by previous context: ['the singer', 'singer', 'Singer', 'The Singer', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [the singer, singer, Singer, The Singer, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (The Cranberries, ['Q483810']), (the singer, ['Q2414234', 'Q3482673'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.14s\n",
      "-->  45 nodes and 44 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 45 nodes and 44 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 3, 'P1686': 2, 'P166': 2, 'P180': 3, 'P1013': 1, 'P800': 1, 'P407': 1, 'P2032': 1, 'P2031': 1, 'P31': 4, 'P1476': 1, 'P527': 3, 'P136': 6, 'P175': 3, 'P973': 1, 'P186': 1, 'P495': 1, 'P264': 1, 'P3744': 1, 'P2002': 1, 'P195': 1, 'P217': 1, 'P170': 1, 'P734': 3, 'P1705': 1}\n",
      "-> paths_keywords: (['singer', 'the singer', 'the cranberries'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.39s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.17s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who was the singer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the singer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who point in time the singer\n",
      "-> q_themes: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: singer\n",
      "-> q_predicates: [(be, ['P31']), (singer, ['P86', 'P4757'])]\n",
      "-> q_predicates \tRunning time is 3.05s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (be, ['P31']), (singer, ['P86', 'P4757']), (date of foundation or creation, ['P571'])]\n",
      "----> q_themes in context: ([(the singer, ['Q2414234', 'Q3482673']), (singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the singer', 'singer', 'Singer', 'The Singer']\n",
      "---> Meaningful keywords enhanced by previous context: ['the singer', 'singer', 'Singer', 'The Singer', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [the singer, singer, Singer, The Singer, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(singer, ['Q177220']), (Singer, ['Q1260201', 'Q20607618']), (The Singer, ['Q18086751', 'Q19099180']), (The Cranberries, ['Q483810']), (the singer, ['Q2414234', 'Q3482673'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.75s\n",
      "-->  45 nodes and 44 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 45 nodes and 44 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 3, 'P1686': 2, 'P166': 2, 'P180': 3, 'P1013': 1, 'P800': 1, 'P407': 1, 'P2032': 1, 'P2031': 1, 'P31': 4, 'P1476': 1, 'P527': 3, 'P136': 6, 'P175': 3, 'P973': 1, 'P186': 1, 'P495': 1, 'P264': 1, 'P3744': 1, 'P2002': 1, 'P195': 1, 'P217': 1, 'P170': 1, 'P734': 3, 'P1705': 1}\n",
      "-> paths_keywords: (['singer', 'the singer', 'the cranberries', 'point'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 272\n",
      "->Computing possible paths \tRunning time is 32.13s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 210\n",
      "->\tRunning time is 3.84s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 61.48s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex             question   answer domain  \\\n",
      "289             531    1       False  Who was the singer?  Q541599  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "289   False          0.33         0.0    False           0.19          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "289  False       317.08        0.0   False        221.53        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "289        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-290-ic531-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 532/2240 -> 2/5 -> Convex=True: (Q541599) Who was the singer?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q47705693\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q1382258\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex             question   answer domain  \\\n",
      "290             531    1        True  Who was the singer?  Q541599  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "290   False          0.27         0.0    False           0.19          0.0   \n",
      "\n",
      "        convex  convex_time  convex_rr   graphqa  graphqa_time graphqa_top2  \\\n",
      "290  Q47705693         0.11        0.0  Q1382258          0.11        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "290        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-291-ic531-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:04:02.084177\n",
      "\t>>> Processing 532/2240 -> 3/5 -> Convex=False: (Q2704746) Who played guitar?                                  \n",
      "Asking qAnswer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer Q855091\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.69s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Vaccinium oxycoccos, ['Q374399'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.15s\n",
      "-->  13 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 12 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P1013': 1, 'P31': 1, 'P156': 2, 'P405': 1, 'P574': 1, 'P225': 1, 'P141': 1, 'P136': 1, 'P1843': 1, 'P1303': 1, 'P155': 1, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'vaccinium oxycoccos'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 124.48s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: guitar\n",
      "-> q_predicates: [(played, ['P741']), (guitar, [])]\n",
      "-> q_predicates \tRunning time is 3.06s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (played, ['P741']), (guitar, [])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (Vaccinium oxycoccos, ['Q374399'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.52s\n",
      "-->  13 nodes and 12 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 13 nodes and 12 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P1013': 1, 'P1303': 1, 'P155': 1, 'P156': 2, 'P31': 1, 'P405': 1, 'P574': 1, 'P225': 1, 'P141': 1, 'P136': 2, 'P1843': 1, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'vaccinium oxycoccos'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 124.31s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 147.42s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 2.95s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.57s\n",
      "-->  29 nodes and 28 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 29 nodes and 28 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 1, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P156': 2, 'P1013': 1, 'P136': 3, 'P1303': 1, 'P155': 1, 'P527': 3, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 123.83s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played guitar?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played guitar \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played guitar\n",
      "-> q_themes: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "behold: get_most_similar started with: guitar\n",
      "-> q_predicates: [(played, ['P741']), (guitar, [])]\n",
      "-> q_predicates \tRunning time is 3.09s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (played, ['P741']), (guitar, [])]\n",
      "----> q_themes in context: ([(guitar, ['Q6607', 'Q1028626']), (Guitar, ['Q1204835'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['guitar', 'Guitar']\n",
      "---> Meaningful keywords enhanced by previous context: ['guitar', 'Guitar', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [guitar, Guitar, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(guitar, ['Q6607']), (Guitar, ['Q1204835', 'Q1028626']), (The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 14.79s\n",
      "-->  31 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 31 nodes and 30 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 1, 'P1686': 2, 'P166': 2, 'P1013': 1, 'P1303': 1, 'P155': 1, 'P156': 2, 'P2032': 1, 'P2031': 1, 'P136': 4, 'P31': 1, 'P527': 3, 'P175': 2}\n",
      "-> paths_keywords: (['guitar', 'the cranberries'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 124.14s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 148.49s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex            question    answer domain  \\\n",
      "291             531    2       False  Who played guitar?  Q2704746  music   \n",
      "\n",
      "     qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "291  Q855091          0.56         0.0    False           0.47          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "291  False       291.11        0.0   False        294.19        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "291        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-292-ic531-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 532/2240 -> 3/5 -> Convex=True: (Q2704746) Who played guitar?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q855091\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 2017-11-09T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 2012-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex            question    answer domain  \\\n",
      "292             531    2        True  Who played guitar?  Q2704746  music   \n",
      "\n",
      "     qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "292  Q855091           0.0         0.0    False           0.52          0.0   \n",
      "\n",
      "                   convex  convex_time  convex_rr               graphqa  \\\n",
      "292  2017-11-09T00:00:00Z         0.14        0.0  2012-01-01T00:00:00Z   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "292          0.32        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "292          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-293-ic531-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:13:49.433704\n",
      "\t>>> Processing 532/2240 -> 4/5 -> Convex=False: (Q653087) Who was the drummer?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was the drummer\n",
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.26s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'Guitarist']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, Guitarist]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.99s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who the drummer\n",
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.26s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'Guitarist']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, Guitarist]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.81s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was the drummer\n",
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.11s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (Vaccinium oxycoccos, ['Q374399']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.33s\n",
      "-->  15 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 15 nodes and 14 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P1013': 1, 'P141': 1, 'P405': 1, 'P574': 1, 'P225': 1, 'P1843': 1, 'P31': 1}\n",
      "-> paths_keywords: (['drummer', 'vaccinium oxycoccos', 'the drummer'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 123.79s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.89s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who the drummer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.08s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (Vaccinium oxycoccos, ['Q374399']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.06s\n",
      "-->  15 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 15 nodes and 14 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P1013': 1, 'P141': 1, 'P405': 1, 'P574': 1, 'P225': 1, 'P1843': 1, 'P31': 1}\n",
      "-> paths_keywords: (['drummer', 'vaccinium oxycoccos', 'the drummer'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 122.49s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.78s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 145.03s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who was the drummer\n",
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.09s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (The Cranberries, ['Q483810']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.23s\n",
      "-->  37 nodes and 36 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 37 nodes and 36 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 1, 'P1013': 1, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P527': 3, 'P31': 1, 'P136': 2, 'P175': 3}\n",
      "-> paths_keywords: (['drummer', 'the cranberries', 'the drummer'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 123.74s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who was the drummer?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who was the drummer \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who the drummer\n",
      "-> q_themes: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: drummer\n",
      "-> q_predicates: [(be, ['P31']), (drummer, [])]\n",
      "-> q_predicates \tRunning time is 3.19s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (be, ['P31']), (drummer, [])]\n",
      "----> q_themes in context: ([(Drummer, ['Q386854', 'Q1261283']), (the drummer, ['Q7731085', 'Q28038453'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Drummer', 'the drummer']\n",
      "---> Meaningful keywords enhanced by previous context: ['Drummer', 'the drummer', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [Drummer, the drummer, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(Drummer, ['Q1261283']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(Drummer, ['Q1261283']), (The Cranberries, ['Q483810']), (the drummer, ['Q7731085', 'Q28038453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.17s\n",
      "-->  37 nodes and 36 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 37 nodes and 36 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 1, 'P1013': 1, 'P1686': 2, 'P166': 2, 'P2032': 1, 'P2031': 1, 'P527': 3, 'P31': 1, 'P136': 2, 'P175': 3}\n",
      "-> paths_keywords: (['drummer', 'the cranberries', 'the drummer'], {}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 122.65s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.58s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 147.16s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex              question   answer domain  \\\n",
      "293             531    3       False  Who was the drummer?  Q653087  music   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "293   False          30.8         0.0    False            0.2          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "293  False       288.77        0.0   False         291.5        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "293        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-294-ic531-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 532/2240 -> 4/5 -> Convex=True: (Q653087) Who was the drummer?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q855091\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q47705693\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q483810\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex              question   answer domain  \\\n",
      "294             531    3        True  Who was the drummer?  Q653087  music   \n",
      "\n",
      "     qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "294  Q855091           0.0         0.0    False           2.09          0.0   \n",
      "\n",
      "        convex  convex_time  convex_rr  graphqa  graphqa_time graphqa_top2  \\\n",
      "294  Q47705693         0.08        0.0  Q483810           0.2        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "294        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-295-ic531-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:24:03.120681\n",
      "\t>>> Processing 532/2240 -> 5/5 -> Convex=False: (2019-01-01T00:00:00Z) What year did they disband?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did Guitarist disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 4.55s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Guitarist']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Guitarist]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.79s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did Guitarist disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.58s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Guitarist']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Guitarist]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Guitarist, ['Q11871827', 'Q5616858', 'Q50670069'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.0s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did Vaccinium oxycoccos disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 4.53s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Vaccinium oxycoccos, ['Q374399'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.5s\n",
      "-->  19 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 18 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P405': 1, 'P574': 1, 'P225': 1, 'P571': 1, 'P3245': 1, 'P3250': 2, 'P31': 2, 'P407': 1, 'P443': 1, 'P1013': 2, 'P279': 5, 'P642': 2, 'P141': 1, 'P527': 3, 'P1843': 1, 'P1709': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P815': 1, 'P373': 1, 'P136': 1, 'P105': 1}\n",
      "-> paths_keywords: (['date', 'vaccinium oxycoccos'], {'Plants of the World online ID': [Plants of the World online ID, ['P5037']], 'stated in': [stated in, ['P248']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 132.81s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did Vaccinium oxycoccos disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.45s\n",
      "--> Predicates enhanced by previous context: [(Plants of the World online ID, ['P5037']), (did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'Vaccinium oxycoccos', 'urn:lsid:ipni.org:names:261956-2']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, Vaccinium oxycoccos, urn lsid ipni.org names:261956 2]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Vaccinium oxycoccos, ['Q374399'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (Vaccinium oxycoccos, ['Q374399'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.92s\n",
      "-->  19 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 19 nodes and 18 edges\n",
      "-> predicates_dict: {'P5037': 0, 'P405': 1, 'P574': 1, 'P225': 1, 'P571': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P3245': 1, 'P3250': 2, 'P31': 2, 'P407': 1, 'P443': 1, 'P1013': 2, 'P279': 5, 'P642': 2, 'P141': 1, 'P527': 3, 'P1843': 1, 'P1709': 1, 'P815': 1, 'P373': 1, 'P136': 1, 'P105': 1}\n",
      "-> paths_keywords: (['date', 'vaccinium oxycoccos'], {'Plants of the World online ID': [Plants of the World online ID, ['P5037']], 'stated in': [stated in, ['P248']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 133.01s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.63s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.11s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 164.93s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, [])]\n",
      "-> q_predicates \tRunning time is 4.5s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (did, ['P248']), (disband, [])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 22.82s\n",
      "-->  25 nodes and 24 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 25 nodes and 24 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 3, 'P1686': 2, 'P166': 2, 'P2031': 1, 'P2032': 1, 'P3245': 1, 'P3250': 2, 'P407': 1, 'P443': 1, 'P740': 1, 'P527': 4, 'P31': 1, 'P642': 2, 'P279': 4, 'P1013': 2, 'P1709': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P576': 1, 'P373': 1, 'P136': 1}\n",
      "-> paths_keywords: (['date', 'the cranberries'], {'point in time': [point in time, ['P585']], 'stated in': [stated in, ['P248']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 36.33s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 90\n",
      "->\tRunning time is 3.75s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What year did they disband?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What date did they disband \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What date did The Cranberries disband\n",
      "> Time related question detected\n",
      "-> q_themes: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date Disband])\n",
      "-> q_themes_enhanced: [('Disband', ['Q5281370'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: disband\n",
      "-> q_predicates: [(did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "-> q_predicates \tRunning time is 4.74s\n",
      "--> Predicates enhanced by previous context: [(point in time, ['P585']), (did, ['P248']), (disband, []), (date, ['P837'])]\n",
      "----> q_themes in context: ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q36603893', 'Q10467097'])], [date])\n",
      "--> Potential meaningful keywords for the sentence: ['date', 'Date', 'Disband']\n",
      "---> Meaningful keywords enhanced by previous context: ['date', 'Date', 'Disband', 'The Cranberries', '1995-01-01T00:00:00Z', '1989-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [date, Date, Disband, The Cranberries, 1995 - 01 01T00:00:00Z, 1989 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810'])], [])\n",
      "q_focused_parts: [(date, ['Q1652093', 'Q3016931']), (Date, ['Q10467097']), (The Cranberries, ['Q483810'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.51s\n",
      "-->  29 nodes and 28 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 29 nodes and 28 edges\n",
      "-> predicates_dict: {'P585': 3, 'P571': 3, 'P1686': 2, 'P166': 2, 'P2031': 1, 'P2032': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P3245': 1, 'P3250': 2, 'P407': 1, 'P443': 1, 'P740': 1, 'P31': 1, 'P1013': 2, 'P279': 4, 'P527': 4, 'P642': 2, 'P1709': 1, 'P3744': 1, 'P2002': 1, 'P576': 1, 'P373': 1, 'P136': 1}\n",
      "-> paths_keywords: (['date', 'the cranberries'], {'point in time': [point in time, ['P585']], 'stated in': [stated in, ['P248']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 36.52s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 90\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 72.06s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                     question  \\\n",
      "295             531    4       False  What year did they disband?   \n",
      "\n",
      "                   answer domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "295  2019-01-01T00:00:00Z  music   False         49.38         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "295           1.03          0.0  False       327.24        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "295        140.11        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "295          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-296-ic531-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 532/2240 -> 5/5 -> Convex=True: (2019-01-01T00:00:00Z) What year did they disband?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q855091\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q15750183\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q483810\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                     question  \\\n",
      "296             531    4        True  What year did they disband?   \n",
      "\n",
      "                   answer domain  qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "296  2019-01-01T00:00:00Z  music  Q855091           0.0         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr     convex  convex_time  convex_rr  graphqa  \\\n",
      "296           1.07          0.0  Q15750183         0.08        0.0  Q483810   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "296          0.21        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "296          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-297-ic531-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:32:42.297846\n",
      "\t>>> Processing 533/2240 -> 1/5 -> Convex=False: (Q268181) Who is the author of the book that this movie was adapted from?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q590870\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who is the author of the book that this movie was adapted from?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the author of the book that this movie was adapted from \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (the book, ['Q3794440']), (The Book, ['Q11250715', 'Q10695431']), (author, ['Q482980', 'P50'])], [book movie])\n",
      "-> q_themes_enhanced: [('movie', ['Q11424']), ('Movie', ['Q2512663']), ('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (adapted, ['P5202']), (author, [])]\n",
      "-> q_predicates \tRunning time is 9.04s\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'the book', 'The Book', 'author', 'movie', 'Movie', 'Author']\n",
      "q_focused_parts: [(book, ['Q571', 'Q4942925', 'Q997698']), (movie, ['Q11424'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.86s\n",
      "-->  52 nodes and 54 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 23 nodes and 22 edges\n",
      "---> Rebuilding the graph with k_deep 6 ... Previously: 23 nodes or 22 edges was below the limit of 100\n",
      "->New graph \tRunning time is 20.17s\n",
      "-->  54 nodes and 56 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 25 nodes and 24 edges\n",
      "---> Rebuilding the graph with k_deep 9 ... Previously: 25 nodes or 24 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.43s\n",
      "-->  60 nodes and 62 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 29 nodes and 28 edges\n",
      "---> Rebuilding the graph with k_deep 12 ... Previously: 29 nodes or 28 edges was below the limit of 100\n",
      "->New graph \tRunning time is 19.67s\n",
      "-->  60 nodes and 62 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 29 nodes and 28 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "-> predicates_dict: {'P50': 2, 'P39': 2, 'P155': 2, 'P156': 2, 'P31': 5, 'P407': 2, 'P136': 2, 'P582': 1, 'P1308': 3, 'P580': 1, 'P577': 2, 'P495': 1, 'P1104': 1, 'P110': 1, 'P1545': 2, 'P4908': 1, 'P179': 1}\n",
      "-> paths_keywords: (['book', 'movie', 'author', 'adapted', 'the book', 'book movie', 'the author', 'book graph', 'film'], {'instance of': [instance of, ['P31']], 'adapted by': [adapted by, ['P5202']], 'author': [author, ['P50']], 'Author': [author, ['P50']]}, [Who, that])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 204\n",
      "->Computing possible paths \tRunning time is 64.72s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 112\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q169566', 21.22222942538256], ['Q906814', 20.958573277457102]]\n",
      "->Computing hypothesises \tRunning time is 15.57s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 8\n",
      "->\tRunning time is 4.43s\n",
      "--> len(cleared_golden_paths): 4\n",
      "---> First path: ['Q169566', 'P50', 'Q3794440', 'P31', 'Q49084']\n",
      "->\tTotal Running time is 181.39s\n",
      "\n",
      "df_graphqa Q169566\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "297             532    0       False   \n",
      "\n",
      "                                              question   answer  domain  \\\n",
      "297  Who is the author of the book that this movie ...  Q268181  movies   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "297   False          1.25         0.0    False           0.52          0.0   \n",
      "\n",
      "      convex  convex_time  convex_rr  graphqa  graphqa_time graphqa_top2  \\\n",
      "297  Q590870         3.57        0.0  Q169566        181.64        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "297        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-298-ic532-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:35:49.311511\n",
      "\t>>> Processing 533/2240 -> 2/5 -> Convex=False: (Q65) Main filming location in movie?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 6.4s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 26.91s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P625': 1, 'P805': 2, 'P1343': 3, 'P131': 1, 'P31': 5, 'P361': 1, 'P642': 1, 'P111': 1, 'P2184': 1, 'P969': 1, 'P17': 1, 'P1056': 1, 'P155': 1, 'P156': 1, 'P2888': 1, 'P425': 6, 'P910': 1, 'P3095': 1, 'P279': 2, 'P304': 1, 'P478': 1, 'P136': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['movie', 'cinema', 'cinematography', 'location'], {'said to be the same as': [said to be the same as, ['P460']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 135.5s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.74s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Main said to be the same as filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.79s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'cinema', 'cinematography']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.02s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P625': 1, 'P921': 32, 'P910': 2, 'P805': 2, 'P1343': 3, 'P1056': 1, 'P155': 2, 'P156': 1, 'P131': 1, 'P31': 5, 'P361': 3, 'P969': 1, 'P2184': 1, 'P373': 1, 'P642': 1, 'P111': 1, 'P17': 1, 'P304': 1, 'P478': 1, 'P2888': 1, 'P425': 6, 'P136': 7, 'P3095': 1, 'P138': 2, 'P279': 2, 'P175': 1, 'P2650': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['movie', 'cinema', 'cinematography', 'location'], {'said to be the same as': [said to be the same as, ['P460']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'director': [director, ['P57']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 139.27s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.71s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.14s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 183.14s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Main filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 6.58s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (instance of, ['P31'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.24s\n",
      "-->  10 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 10 nodes and 10 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 15, 'P136': 6, 'P625': 1, 'P642': 1, 'P111': 1, 'P361': 2, 'P937': 1, 'P800': 4, 'P1455': 1, 'P407': 6, 'P856': 1, 'P571': 1, 'P495': 3, 'P131': 1, 'P106': 2, 'P518': 1, 'P364': 1, 'P969': 1, 'P17': 1, 'P793': 1, 'P156': 2, 'P19': 1, 'P155': 2, 'P580': 1, 'P582': 1, 'P26': 1, 'P110': 1, 'P577': 4, 'P57': 1, 'P527': 1, 'P854': 2, 'P1343': 2, 'P483': 1, 'P264': 2, 'P462': 1}\n",
      "-> paths_keywords: (['movie', 'the book', 'h. p. lovecraft', 'short story', 'location'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 148.77s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Main filming location in movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Main filming location in movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Main author filming location in movie\n",
      "-> q_themes: ([(Movie, ['Q2512663', 'Q43262595'])], [Main filming location, Main Filming Location, main filming location, main Filming Location])\n",
      "-> q_themes_enhanced: [('filming location', ['P915']), ('Main', ['Q10575454']), ('location', ['P625']), ('main', ['Q3278265']), ('Location', ['Q1051594']), ('film', ['Q11424']), ('Film', ['Q11332514'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 6.8s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (Main, ['P921', 'P301']), (filming, ['P915']), (location, ['P625']), (movie, ['P57']), (instance of, ['P31'])]\n",
      "----> q_themes in context: ([(Movie, ['Q2512663', 'Q43262595'])], [Main, main])\n",
      "--> Potential meaningful keywords for the sentence: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film']\n",
      "---> Meaningful keywords enhanced by previous context: ['Movie', 'filming location', 'Main', 'location', 'main', 'Location', 'film', 'Film', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Movie, filming location, Main, location, main, Location, film, Film, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Movie, ['Q2512663', 'Q43262595']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Movie, ['Q2512663', 'Q43262595']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 38.16s\n",
      "-->  10 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 10 nodes and 10 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 15, 'P136': 9, 'P625': 1, 'P57': 1, 'P921': 3, 'P910': 1, 'P937': 1, 'P642': 1, 'P111': 1, 'P361': 2, 'P155': 2, 'P156': 2, 'P800': 5, 'P971': 1, 'P1455': 1, 'P407': 7, 'P856': 1, 'P571': 1, 'P131': 1, 'P495': 3, 'P793': 1, 'P106': 3, 'P518': 1, 'P364': 1, 'P969': 1, 'P527': 1, 'P17': 1, 'P58': 3, 'P119': 1, 'P19': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P110': 1, 'P577': 5, 'P272': 1, 'P2096': 1, 'P175': 3, 'P483': 1, 'P854': 2, 'P1343': 2, 'P264': 2, 'P462': 1}\n",
      "-> paths_keywords: (['movie', 'the book', 'h. p. lovecraft', 'short story', 'filming'], {'author': [author, ['P50']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'filming location': [filming location, ['P915']], 'coordinate location': [coordinate location, ['P625']], 'director': [director, ['P57']], 'instance of': [instance of, ['P31']], 'location': [coordinate location, ['P625']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 156.82s\n",
      "-> Filtering paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.73s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.16s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 209.82s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "298             532    1       False  Main filming location in movie?    Q65   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "298  movies   False          1.63         0.0    False           1.28   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "298          0.0  False       356.71        0.0   False        401.99   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "298        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "298         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-299-ic532-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 533/2240 -> 2/5 -> Convex=True: (Q65) Main filming location in movie?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q1204804\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q4750016\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question answer  \\\n",
      "299             532    1        True  Main filming location in movie?    Q65   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "299  movies   False          1.55         0.0    False           0.98   \n",
      "\n",
      "     platypus_rr    convex  convex_time  convex_rr   graphqa  graphqa_time  \\\n",
      "299          0.0  Q1204804         0.73        0.0  Q4750016           0.6   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "299        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "299         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-300-ic532-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:48:34.820147\n",
      "\t>>> Processing 533/2240 -> 3/5 -> Convex=False: (139 minute) Length of movie?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Length of movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Length of movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Length of movie\n",
      "-> q_themes: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(length, [])]\n",
      "-> q_predicates \tRunning time is 4.31s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (length, [])]\n",
      "----> q_themes in context: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Length', 'Movie', 'length']\n",
      "---> Meaningful keywords enhanced by previous context: ['Length', 'Movie', 'length', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Length, Movie, length, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.34s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P805': 2, 'P1343': 3, 'P131': 1, 'P31': 2, 'P2184': 1, 'P17': 1, 'P910': 1, 'P3095': 1, 'P2888': 1, 'P101': 4, 'P304': 1, 'P478': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['length', 'movie', 'cinema', 'cinematography'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 128.01s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.92s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Length of movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Length of movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Length of movie\n",
      "-> q_themes: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(length, []), (Length, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 3.39s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (length, []), (Length, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Length', 'Movie', 'length']\n",
      "---> Meaningful keywords enhanced by previous context: ['Length', 'Movie', 'length', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Length, Movie, length, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.43s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P805': 2, 'P1343': 3, 'P1056': 1, 'P131': 1, 'P31': 2, 'P2184': 1, 'P373': 1, 'P17': 1, 'P910': 1, 'P136': 6, 'P3095': 1, 'P138': 2, 'P2888': 1, 'P101': 4, 'P304': 1, 'P478': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['length', 'movie', 'cinema', 'cinematography'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 132.07s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.89s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 163.4s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Length of movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Length of movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Length of movie\n",
      "-> q_themes: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(length, [])]\n",
      "-> q_predicates \tRunning time is 3.3s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (length, [])]\n",
      "----> q_themes in context: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Length', 'Movie', 'length']\n",
      "---> Meaningful keywords enhanced by previous context: ['Length', 'Movie', 'length', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Length, Movie, length, The Book, H. P. Lovecraft, Short story]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Meaningful keywords casted as theme ([(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.97s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 11, 'P136': 3, 'P106': 2, 'P110': 1, 'P577': 2, 'P57': 1, 'P800': 2, 'P407': 5, 'P856': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P2061': 1, 'P1104': 1, 'P518': 1, 'P364': 1, 'P921': 1, 'P793': 1, 'P361': 1, 'P571': 1, 'P131': 1, 'P462': 1, 'P17': 1, 'P495': 1, 'P854': 2, 'P1343': 2, 'P156': 1}\n",
      "-> paths_keywords: (['length', 'movie', 'the book', 'h. p. lovecraft', 'short story'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 142.25s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.68s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Length of movie?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Length of movie \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Length of movie\n",
      "-> q_themes: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: movie\n",
      "-> q_predicates: [(length, []), (Length, ['P2043']), (movie, ['P57'])]\n",
      "-> q_predicates \tRunning time is 3.26s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (length, []), (Length, ['P2043']), (movie, ['P57'])]\n",
      "----> q_themes in context: ([(Length, ['Q36253', 'Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Length', 'Movie', 'length']\n",
      "---> Meaningful keywords enhanced by previous context: ['Length', 'Movie', 'length', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Length, Movie, length, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Length, ['Q296993']), (Movie, ['Q2512663', 'Q43262595']), (length, ['Q1761084', 'P2043']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.88s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 11, 'P136': 7, 'P57': 1, 'P793': 1, 'P106': 3, 'P58': 3, 'P110': 1, 'P577': 2, 'P272': 1, 'P407': 5, 'P800': 2, 'P856': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P2096': 1, 'P527': 1, 'P131': 1, 'P1104': 1, 'P2061': 1, 'P518': 1, 'P364': 1, 'P921': 1, 'P175': 2, 'P361': 1, 'P571': 1, 'P462': 1, 'P17': 1, 'P495': 1, 'P854': 2, 'P1343': 2, 'P156': 1}\n",
      "-> paths_keywords: (['length', 'movie', 'the book', 'h. p. lovecraft', 'short story'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 146.91s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.53s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 182.25s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex          question      answer  domain  \\\n",
      "300             532    2       False  Length of movie?  139 minute  movies   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "300   False           0.4         0.0    False           0.35          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "300  False       319.64        0.0   False        356.17        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "300        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-301-ic532-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 533/2240 -> 3/5 -> Convex=True: (139 minute) Length of movie?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q11424\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1938-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex          question      answer  domain  \\\n",
      "301             532    2        True  Length of movie?  139 minute  movies   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "301   False          0.35         0.0    False           0.35          0.0   \n",
      "\n",
      "     convex  convex_time  convex_rr               graphqa  graphqa_time  \\\n",
      "301  Q11424         0.45        0.0  1938-01-01T00:00:00Z          0.35   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "301        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "301         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-302-ic532-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 02:59:52.951826\n",
      "\t>>> Processing 533/2240 -> 4/5 -> Convex=False: (Q35332) Who played Tyler Durden?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q35332\n",
      "df_qanswer_rr 1.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.61s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 27.37s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P805': 2, 'P1343': 3, 'P373': 2, 'P1441': 4, 'P31': 6, 'P364': 2, 'P2184': 1, 'P910': 2, 'P2548': 1, 'P2437': 1, 'P3095': 1, 'P138': 2, 'P136': 1, 'P1113': 1, 'P279': 1, 'P674': 1, 'P462': 1, 'P304': 1, 'P478': 1, 'P86': 1, 'P161': 1, 'P1056': 1, 'P1057': 1, 'P644': 1, 'P5429': 4, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'cinema', 'cinematography', 'durden'], {'said to be the same as': [said to be the same as, ['P460']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 137.6s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.82s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.45s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.1s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P805': 2, 'P1343': 3, 'P373': 2, 'P1441': 4, 'P31': 6, 'P364': 2, 'P2184': 1, 'P910': 2, 'P2548': 1, 'P2437': 1, 'P3095': 1, 'P138': 2, 'P136': 1, 'P1113': 1, 'P279': 1, 'P674': 1, 'P462': 1, 'P304': 1, 'P478': 1, 'P86': 1, 'P161': 1, 'P1056': 1, 'P1057': 1, 'P644': 1, 'P5429': 4, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'cinema', 'cinematography', 'durden'], {'said to be the same as': [said to be the same as, ['P460']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 138.71s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 178.84s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "CORRECT 533 - 4 -> qAnswer Q35332\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.45s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.76s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 18, 'P136': 6, 'P373': 1, 'P106': 2, 'P800': 2, 'P1877': 3, 'P1441': 4, 'P407': 5, 'P856': 1, 'P518': 1, 'P364': 3, 'P527': 1, 'P58': 1, 'P2437': 1, 'P361': 1, 'P462': 2, 'P110': 1, 'P483': 1, 'P577': 4, 'P793': 1, 'P57': 1, 'P138': 2, 'P2548': 1, 'P735': 2, 'P1113': 1, 'P674': 1, 'P175': 2, 'P495': 1, 'P921': 1, 'P734': 1, 'P69': 1, 'P86': 1, 'P161': 1, 'P910': 1, 'P2096': 1, 'P1057': 1, 'P644': 1, 'P854': 2, 'P1343': 2, 'P156': 1, 'P580': 1, 'P582': 1, 'P645': 1, 'P26': 1}\n",
      "-> paths_keywords: (['tyler durden', 'the book', 'h. p. lovecraft', 'short story', 'durden'], {'author': [author, ['P50']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 155.98s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.77s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who played Tyler Durden?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who played Tyler Durden \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who played Tyler Durden\n",
      "-> q_themes: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played Tyler])\n",
      "-> q_themes_enhanced: [('play', ['Q1150958']), ('tyler', ['Q29731589']), ('Played', ['Q15613907']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(played, ['P741'])]\n",
      "-> q_predicates \tRunning time is 4.49s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (played, ['P741'])]\n",
      "----> q_themes in context: ([(Tyler Durden, ['Q4001141', 'Q12684959']), (durden, ['Q21494451', 'Q5316331'])], [played])\n",
      "--> Potential meaningful keywords for the sentence: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Tyler Durden', 'durden', 'play', 'tyler', 'Played', 'Play', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Tyler Durden, durden, play, tyler, Played, Play, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Tyler Durden, ['Q4001141', 'Q12684959']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Tyler Durden, ['Q4001141', 'Q12684959']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795']), (durden, ['Q21494451', 'Q5316331'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 32.52s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P50': 143, 'P31': 18, 'P136': 6, 'P373': 1, 'P106': 2, 'P800': 2, 'P1877': 3, 'P1441': 4, 'P407': 5, 'P856': 1, 'P518': 1, 'P364': 3, 'P527': 1, 'P58': 1, 'P2437': 1, 'P361': 1, 'P462': 2, 'P483': 1, 'P577': 4, 'P110': 1, 'P793': 1, 'P57': 1, 'P138': 2, 'P2548': 1, 'P735': 2, 'P1113': 1, 'P674': 1, 'P175': 2, 'P495': 1, 'P921': 1, 'P734': 1, 'P69': 1, 'P86': 1, 'P161': 1, 'P910': 1, 'P2096': 1, 'P1057': 1, 'P644': 1, 'P854': 2, 'P1343': 2, 'P580': 1, 'P156': 1, 'P582': 1, 'P26': 1, 'P645': 1}\n",
      "-> paths_keywords: (['tyler durden', 'the book', 'h. p. lovecraft', 'short story', 'durden'], {'author': [author, ['P50']], 'playing hand': [playing hand, ['P741']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 154.9s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.76s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 198.85s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                  question  answer  \\\n",
      "302             532    3       False  Who played Tyler Durden?  Q35332   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "302  movies  Q35332           0.5         1.0    False           0.48   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "302          0.0  False       353.02        0.0   False        396.72   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "302        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "302         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-303-ic532-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 533/2240 -> 4/5 -> Convex=True: (Q35332) Who played Tyler Durden?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 25584\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 1987-01-01T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 83626\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question  answer  \\\n",
      "303             532    3        True  Who played Tyler Durden?  Q35332   \n",
      "\n",
      "     domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "303  movies   25584          0.41         0.0    False           0.47   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr graphqa  \\\n",
      "303          0.0  1987-01-01T00:00:00Z         0.52        0.0   83626   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "303          0.57        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "303          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-304-ic532-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 03:12:25.687216\n",
      "\t>>> Processing 533/2240 -> 5/5 -> Convex=False: (1999-11-11T00:00:00Z) Date of publication?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.83s\n",
      "--> Predicates enhanced by previous context: []\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Brad Pitt']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Brad Pitt]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Brad Pitt, ['Q12304239', 'Q35332', 'Q373912'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Brad Pitt, ['Q12304239', 'Q35332', 'Q373912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 4.82s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.76s\n",
      "--> Predicates enhanced by previous context: [(Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'Brad Pitt']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, Brad Pitt]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Brad Pitt, ['Q12304239', 'Q35332', 'Q373912'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (Brad Pitt, ['Q12304239', 'Q35332', 'Q373912'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.9s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.71s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'cinema', 'cinematography']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.91s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P1932': 3, 'P291': 1, 'P50': 1, 'P3245': 1, 'P3250': 2, 'P279': 5, 'P805': 2, 'P1343': 3, 'P407': 2, 'P443': 1, 'P571': 1, 'P31': 3, 'P1013': 3, 'P1104': 1, 'P642': 2, 'P2184': 1, 'P958': 1, 'P92': 1, 'P1709': 1, 'P910': 1, 'P175': 1, 'P1672': 1, 'P180': 1, 'P3095': 1, 'P186': 1, 'P304': 1, 'P478': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['date', 'publication', 'cinema', 'cinematography'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 136.63s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.51s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.04s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.77s\n",
      "--> Predicates enhanced by previous context: [(said to be the same as, ['P460']), (Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'cinema', 'cinematography']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, cinema, cinematography]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (cinema, ['Q16144339', 'Q41253']), (cinematography, ['Q590870'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 25.59s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P460': 87, 'P175': 2, 'P31': 6, 'P1672': 1, 'P180': 1, 'P186': 1, 'P1932': 3, 'P291': 1, 'P50': 1, 'P3245': 1, 'P3250': 2, 'P279': 6, 'P805': 2, 'P1343': 3, 'P407': 2, 'P443': 1, 'P571': 1, 'P1013': 3, 'P1104': 1, 'P425': 6, 'P2184': 1, 'P642': 3, 'P958': 1, 'P92': 1, 'P304': 1, 'P478': 1, 'P1709': 1, 'P2888': 1, 'P812': 1, 'P3095': 1, 'P921': 3, 'P910': 1, 'P736': 1, 'P5429': 4}\n",
      "-> paths_keywords: (['date', 'publication', 'cinema', 'cinematography'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.6s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 178.13s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: []\n",
      "-> q_predicates \tRunning time is 3.76s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n",
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.93s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 144, 'P31': 11, 'P136': 4, 'P1932': 3, 'P106': 2, 'P110': 1, 'P577': 2, 'P736': 2, 'P57': 1, 'P291': 1, 'P407': 4, 'P443': 1, 'P856': 1, 'P793': 1, 'P1672': 1, 'P958': 1, 'P92': 1, 'P527': 2, 'P518': 1, 'P364': 1, 'P1013': 1, 'P279': 3, 'P495': 1, 'P642': 2, 'P854': 2, 'P1343': 2, 'P175': 1, 'P1709': 1, 'P156': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'the book', 'h. p. lovecraft', 'short story'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.74s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.84s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Date of publication?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Date of publication \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Date of publication\n",
      "-> q_themes: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(Date, ['P837']), (publication, ['P577'])]\n",
      "-> q_predicates \tRunning time is 3.9s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (Date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(Date, ['Q36603893', 'Q10467097']), (publication, ['Q732577', 'Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['Date', 'publication', 'Publication', 'date']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['Date', 'publication', 'Publication', 'date', 'The Book', 'H. P. Lovecraft', 'Short story']\n",
      "meaningful_names_no_previous_answer [Date, publication, Publication, date, The Book, H. P. Lovecraft, Short story]\n",
      "----> Meaningful keywords casted as theme ([(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])], [])\n",
      "q_focused_parts: [(Date, ['Q10467097']), (publication, ['Q15852766']), (Publication, ['Q51523527', 'Q15728967']), (date, ['Q1652093', 'Q3016931']), (The Book, ['Q15865293', 'Q11250715', 'Q10695431']), (H. P. Lovecraft, ['Q169566', 'Q5628460', 'Q371642']), (Short story, ['Q2297795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 26.28s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P50': 144, 'P31': 13, 'P136': 5, 'P1932': 3, 'P175': 2, 'P577': 3, 'P1672': 1, 'P180': 1, 'P186': 1, 'P291': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P569': 1, 'P570': 1, 'P571': 2, 'P279': 5, 'P1013': 3, 'P1104': 2, 'P106': 2, 'P3245': 1, 'P3250': 2, 'P800': 3, 'P642': 2, 'P518': 1, 'P364': 1, 'P407': 7, 'P443': 1, 'P856': 1, 'P361': 1, 'P495': 1, 'P958': 1, 'P92': 1, 'P1709': 1, 'P110': 1, 'P736': 2, 'P57': 1, 'P793': 1, 'P527': 2, 'P264': 2, 'P854': 2, 'P1343': 2, 'P156': 1}\n",
      "-> paths_keywords: (['date', 'publication', 'the book', 'h. p. lovecraft', 'short story'], {}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 154.15s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.72s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.05s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 191.77s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex              question  \\\n",
      "304             532    4       False  Date of publication?   \n",
      "\n",
      "                   answer  domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "304  1999-11-11T00:00:00Z  movies   False         36.78         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "304           0.35          0.0  False       343.53        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "304        366.75        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "304          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-305-ic532-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 533/2240 -> 5/5 -> Convex=True: (1999-11-11T00:00:00Z) Date of publication?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 1963-12-18T00:00:00Z\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q649\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1991-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex              question  \\\n",
      "305             532    4        True  Date of publication?   \n",
      "\n",
      "                   answer  domain               qanswer  qanswer_time  \\\n",
      "305  1999-11-11T00:00:00Z  movies  1963-12-18T00:00:00Z          0.36   \n",
      "\n",
      "     qanswer_rr platypus  platypus_time  platypus_rr convex  convex_time  \\\n",
      "305         0.0    False           2.37          0.0   Q649         0.38   \n",
      "\n",
      "     convex_rr               graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "305        0.0  1991-01-01T00:00:00Z          0.37        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "305        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-306-ic532-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 03:24:56.638829\n",
      "\t>>> Processing 534/2240 -> 1/5 -> Convex=False: (Q838742) In which episode did Homer Simpson visit a store called Sneed's Feed & Seed?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q5944\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q151076\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: In which episode did Homer Simpson visit a store called Sneed's Feed & Seed?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: In which episode did Homer Simpson visit a store called Sneed Feed & Seed \n",
      "-> q_themes: ([(Homer Simpson, ['Q7810']), (episode, ['Q1983062', 'Q900962']), (sneed, ['Q20165754', 'Q2295799']), (seed, ['Q40763', 'Q257204']), (Seed, ['Q11308858', 'Q11308860']), (Episode, ['Q23705710', 'Q11290527'])], [Sneed Seed, Seed Sneed, In which episode did Homer, Simpson visit a store called Sneed, Sneed Feed, Homer Simpson Visit, a store call, Homer Simpson visit store])\n",
      "-> q_themes_enhanced: [('Sneed', ['Q20165754']), ('Feed', ['Q1400892']), ('Visit', ['Q17126187']), ('homer', ['Q28974925']), ('visit', ['Q6163881']), ('store', ['Q1800324']), ('Store A', ['Q16065193']), ('Store', ['Q1137469'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: visit\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(did, ['P248']), (visit, []), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 13.88s\n",
      "--> Potential meaningful keywords for the sentence: ['Homer Simpson', 'episode', 'sneed', 'seed', 'Seed', 'Episode', 'Sneed', 'Feed', 'Visit', 'homer', 'visit', 'store', 'Store A', 'Store']\n",
      "q_focused_parts: []\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 60.0s\n",
      "-->  248 nodes and 240 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 248 nodes and 240 edges\n",
      "-> predicates_dict: {'P180': 2, 'P1441': 1, 'P1039': 2, 'P1038': 2, 'P1810': 1, 'P4900': 1, 'P495': 3, 'P1013': 4, 'P138': 1, 'P27': 2, 'P2670': 2, 'P19': 1, 'P360': 3, 'P527': 6, 'P364': 2, 'P31': 18, 'P3744': 1, 'P2002': 1, 'P1545': 2, 'P735': 2, 'P571': 2, 'P3225': 2, 'P361': 5, 'P1324': 1, 'P3831': 1, 'P175': 1, 'P577': 10, 'P348': 6, 'P793': 1, 'P856': 3, 'P3373': 1, 'P161': 1, 'P279': 2, 'P734': 5, 'P366': 2, 'P155': 3, 'P159': 2, 'P136': 2, 'P264': 1, 'P304': 1, 'P478': 1, 'P1343': 1, 'P915': 1, 'P569': 1, 'P156': 2, 'P1963': 1, 'P3499': 1, 'P282': 1, 'P1709': 1, 'P21': 1}\n",
      "-> paths_keywords: (['did', 'in which episode did homer', 'homer simpson', 'episode', 'sneed', 'seed'], {'stated in': [stated in, ['P248']], 'country calling code': [country calling code, ['P474']]}, [which])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 570\n",
      "->Computing possible paths \tRunning time is 41.19s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 416\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q20', 5.313804187354153], ['Q886', 2.9970446810844313], ['Q7805143', 2.4815577090829977], ['Q7805141', 2.4758962036427543], ['Q30', 2.3283699348623608], ['Q408', 2.011209557085136], ['Q188', 1.9593021977348366], ['Q1028', 1.9201172052636482], ['Q10861569', 1.6222716072068861], ['Q1400892', 1.4231240462231418], ['Q16065193', 1.2749269572072295], ['Q7000725', 1.138693148939345], ['Q4830453', 1.0607316571775622], ['Q10953163', 1.022308607397772], ['Q2217063', 0.9877933562843194], ['Q862054', 0.805464577230688], ['Q6163881', 0.8030641412255649], ['Q2554550', 0.800663705220442], ['Q482994', 0.7524207653381881], ['Q245025', 0.7235554919928454], ['Q11424', 0.7185003016481103], ['1957-10-09T00:00:00Z', 0.7064356249893824], ['Q15709880', 0.6569841128785299], ['Q5', 0.6297367091508108], ['Q15773317', 0.60760557765254], ['Q15632617', 0.5711936630906594], ['Q101352', 0.47436505849237026], ['Q28378282', 0.46748161101583346], ['Q1860', 0.37026817672891277], ['1915-09-01T00:00:00Z', 0.3590150886045247], ['Q17104079', 0.2078031940157975], ['Q25624', 0.17261239571399872], ['Q151076', 0.08020817537587349], ['Q1648541', 0.07007434923703558], ['Q193026', -0.015942753765366326]]\n",
      "->Computing hypothesises \tRunning time is 283.44s\n",
      "-> Computing golden paths...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(golden_paths): 1\n",
      "->\tRunning time is 22.37s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q886', 'P1441', 'Q7810', 'P27', 'Q30', 'P495', 'Q1400892', 'P31', 'Q11424']\n",
      "->\tTotal Running time is 428.63s\n",
      "\n",
      "df_graphqa Q886\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "306             533    0       False   \n",
      "\n",
      "                                              question   answer     domain  \\\n",
      "306  In which episode did Homer Simpson visit a sto...  Q838742  tv_series   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "306   Q5944          0.99         0.0    False           3.23          0.0   \n",
      "\n",
      "      convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "306  Q151076         3.21        0.0    Q886        428.89        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "306        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-307-ic533-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 03:32:12.994237\n",
      "\t>>> Processing 534/2240 -> 2/5 -> Convex=False: (11) What season was E-I-E-I-(Annoyed Grunt)?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What season was E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What season was e I I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What season was e List of The Simpsons episodes List of The Simpsons episodes E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e E I'annoyed Grunt, i e i-(annoyed, Grunt E, What season was e E, E I'annoyed Grunt, E E I'annoyed Grunt, e e i'annoyed grunt, e e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(be, ['P31']), (E, []), (season, [])]\n",
      "-> q_predicates \tRunning time is 41.58s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (E, [])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e, i, Grunt, What, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, Season, season, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.14s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What season was E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What season was e I I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What season e List of The Simpsons episodes List of The Simpsons episodes E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e E I'annoyed Grunt, i e i-(annoyed, Grunt E, What season was e E, E I'annoyed Grunt, E E I'annoyed Grunt, e e i'annoyed grunt, e e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(be, ['P31']), (E, []), (season, ['P4908']), (e, [])]\n",
      "-> q_predicates \tRunning time is 40.37s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (E, []), (season, ['P4908'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e, i, Grunt, What, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, Season, season, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 13.2s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What season was E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What season was e I I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What season was e Springfield Springfield E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e E I'annoyed Grunt, i e i-(annoyed, Grunt E, What season was e E, E I'annoyed Grunt, E E I'annoyed Grunt, e e i'annoyed grunt, e e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(be, ['P31']), (E, []), (season, [])]\n",
      "-> q_predicates \tRunning time is 40.6s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (be, ['P31']), (E, [])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e, i, Grunt, What, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, Season, season, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 26.58s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P31': 26, 'P361': 1, 'P585': 1, 'P1082': 1, 'P3744': 2, 'P2002': 1, 'P1545': 2, 'P735': 2, 'P407': 1, 'P3984': 1, 'P577': 2, 'P1441': 2, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P1465': 1, 'P571': 2, 'P27': 1, 'P17': 4, 'P3831': 1, 'P175': 2, 'P279': 1, 'P1482': 1, 'P856': 1}\n",
      "-> paths_keywords: (['e', 'grunt', 'season', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 145.76s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What season was E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What season was e I I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What place of birth season e Springfield Springfield E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e E I'annoyed Grunt, i e i-(annoyed, Grunt E, What season was e E, E I'annoyed Grunt, E E I'annoyed Grunt, e e i'annoyed grunt, e e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(be, ['P31']), (E, []), (season, ['P4908']), (e, [])]\n",
      "-> q_predicates \tRunning time is 40.83s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (be, ['P31']), (E, []), (season, ['P4908'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e, i, Grunt, What, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, Season, season, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 26.71s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P31': 26, 'P361': 1, 'P144': 1, 'P585': 1, 'P1082': 1, 'P3744': 2, 'P2002': 1, 'P1545': 2, 'P735': 2, 'P407': 1, 'P3984': 1, 'P577': 2, 'P1441': 2, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P1465': 1, 'P571': 2, 'P27': 1, 'P17': 4, 'P3831': 1, 'P175': 2, 'P279': 1, 'P1482': 1, 'P856': 1, 'P138': 3}\n",
      "-> paths_keywords: (['e', 'grunt', 'season', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt', 'place'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 153.36s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.74s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 228.69s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What season was E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What season was e I I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What season was e United States of America United States of America E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e E I'annoyed Grunt, i e i-(annoyed, Grunt E, What season was e E, E I'annoyed Grunt, E E I'annoyed Grunt, e e i'annoyed grunt, e e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(be, ['P31']), (E, []), (season, [])]\n",
      "-> q_predicates \tRunning time is 40.04s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (be, ['P31']), (E, []), (country of citizenship, ['P27']), (country of origin, ['P495'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908'])], [e, i, Grunt, What, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'Season', 'season', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'film']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, Season, season, Homer Simpson, The Simpsons, Feed, United States of America, film]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Season, ['Q11242814', 'Q11242815']), (season, ['Q24384', 'P4908']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (film, ['Q11424']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 65.93s\n",
      "-->  18 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 18 nodes and 20 edges\n",
      "-> predicates_dict: {'P1441': 178, 'P495': 7, 'P27': 2, 'P31': 46, 'P585': 7, 'P1113': 1, 'P1411': 3, 'P17': 1, 'P364': 3, 'P19': 1, 'P406': 1, 'P3744': 2, 'P407': 1, 'P3984': 1, 'P361': 2, 'P2002': 1, 'P1545': 3, 'P735': 2, 'P1039': 1, 'P1038': 2, 'P1476': 2, 'P1433': 1, 'P3831': 1, 'P175': 2, 'P577': 3, 'P166': 3, 'P279': 1, 'P136': 1, 'P453': 8, 'P1482': 1, 'P725': 1, 'P161': 1, 'P1346': 56, 'P1431': 1, 'P856': 1, 'P910': 1, 'P2093': 1}\n",
      "-> paths_keywords: (['e', 'grunt', 'season', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'film', 'e i e i-(annoyed grunt', 'states'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 168\n",
      "->Computing possible paths \tRunning time is 30.28s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 124\n",
      "->\tRunning time is 3.83s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1860', 0.7319067157156575]]\n",
      "->Computing hypothesises \tRunning time is 59.22s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 10\n",
      "->\tRunning time is 5.09s\n",
      "--> len(cleared_golden_paths): 5\n",
      "---> First path: ['Q1860', 'P407', 'Q886', 'P1441', 'Q7810', 'P27', 'Q30', 'P495', 'Q1400892']\n",
      "->\tTotal Running time is 208.56s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_graphqa Q1860\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "307             533    1       False   \n",
      "\n",
      "                                     question answer     domain qanswer  \\\n",
      "307  What season was E-I-E-I-(Annoyed Grunt)?     11  tv_series   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "307        108.76         0.0    False            0.8          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "307       446.07        0.0   Q1860        208.81        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "307        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-308-ic533-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 534/2240 -> 2/5 -> Convex=True: (11) What season was E-I-E-I-(Annoyed Grunt)?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q22906506\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 109a53ec-73e7-44e8-81cd-484114849a02\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 10.5240/96D1-06D3-4BBB-E664-722B-U\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "308             533    1        True   \n",
      "\n",
      "                                     question answer     domain    qanswer  \\\n",
      "308  What season was E-I-E-I-(Annoyed Grunt)?     11  tv_series  Q22906506   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "308          0.03         0.0    False           0.79          0.0   \n",
      "\n",
      "                                   convex  convex_time  convex_rr  \\\n",
      "308  109a53ec-73e7-44e8-81cd-484114849a02         0.25        0.0   \n",
      "\n",
      "                                graphqa  graphqa_time graphqa_top2  \\\n",
      "308  10.5240/96D1-06D3-4BBB-E664-722B-U         13.59        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "308        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-309-ic533-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 03:45:12.134411\n",
      "\t>>> Processing 534/2240 -> 3/5 -> Convex=False: (Q3106628) Who wrote E-I-E-I-(Annoyed Grunt)?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(wrote, ['P1412'])]\n",
      "-> q_predicates \tRunning time is 7.19s\n",
      "--> Predicates enhanced by previous context: [(wrote, ['P1412'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.83s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: i\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(wrote, ['P1412']), (e, []), (I, []), (E, [])]\n",
      "-> q_predicates \tRunning time is 7.06s\n",
      "--> Predicates enhanced by previous context: [(wrote, ['P1412']), (e, [])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.33s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(wrote, ['P1412'])]\n",
      "-> q_predicates \tRunning time is 7.13s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (wrote, ['P1412'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'Homer Simpson', 'Springfield']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.13s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P3744': 2, 'P407': 2, 'P3984': 1, 'P571': 3, 'P361': 1, 'P31': 13, 'P585': 1, 'P1082': 1, 'P2002': 1, 'P1545': 2, 'P735': 2, 'P1013': 1, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P27': 1, 'P17': 4, 'P1464': 1, 'P1441': 1, 'P3831': 1, 'P175': 1, 'P856': 1, 'P1465': 1, 'P22': 2, 'P138': 1, 'P3912': 1, 'P625': 1}\n",
      "-> paths_keywords: (['e', 'grunt', 'i', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt'], {'place of birth': [place of birth, ['P19']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 147.88s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.64s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: i\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(wrote, ['P1412']), (e, []), (I, []), (E, [])]\n",
      "-> q_predicates \tRunning time is 6.96s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (wrote, ['P1412']), (e, [])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 32.38s\n",
      "-->  6 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 6 nodes and 6 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P31': 13, 'P3744': 2, 'P407': 2, 'P3984': 1, 'P571': 3, 'P361': 1, 'P585': 1, 'P1082': 1, 'P2002': 1, 'P1545': 2, 'P735': 2, 'P1013': 1, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P27': 1, 'P17': 4, 'P1464': 1, 'P1441': 2, 'P175': 1, 'P3831': 1, 'P856': 1, 'P1465': 1, 'P22': 2, 'P138': 1, 'P3912': 1, 'P625': 1, 'P1482': 1}\n",
      "-> paths_keywords: (['e', 'grunt', 'i', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt'], {'place of birth': [place of birth, ['P19']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 151.29s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.08s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 198.2s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(wrote, ['P1412'])]\n",
      "-> q_predicates \tRunning time is 7.77s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (wrote, ['P1412']), (language of work or name, ['P407']), (country of citizenship, ['P27']), (country of origin, ['P495'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 68.29s\n",
      "-->  25 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 25 nodes and 30 edges\n",
      "-> predicates_dict: {'P1441': 178, 'P495': 11, 'P27': 2, 'P364': 6, 'P407': 3, 'P31': 31, 'P3744': 2, 'P3984': 1, 'P1013': 1, 'P585': 8, 'P1113': 1, 'P1411': 4, 'P571': 1, 'P17': 3, 'P131': 1, 'P1545': 3, 'P735': 2, 'P2002': 1, 'P19': 1, 'P1686': 1, 'P406': 1, 'P361': 2, 'P1039': 1, 'P1038': 2, 'P1476': 2, 'P1433': 1, 'P2093': 1, 'P3831': 1, 'P175': 1, 'P577': 3, 'P1346': 28, 'P166': 3, 'P856': 1, 'P453': 8, 'P725': 1, 'P136': 1, 'P161': 1, 'P674': 1, 'P1482': 1, 'P910': 1, 'P22': 2, 'P373': 1, 'P941': 1, 'P272': 1, 'P3912': 1, 'P625': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['e', 'grunt', 'i', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film', 'e i e i-(annoyed grunt'], {'present in work': [present in work, ['P1441']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']], 'language of work or name': [language of work or name, ['P407']], 'country of citizenship': [country of citizenship, ['P27']], 'country of origin': [country of origin, ['P495']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 120\n",
      "->Computing possible paths \tRunning time is 11.59s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 118\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 17.7s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: Who wrote E-I-E-I-(Annoyed Grunt)?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who wrote e I E I'annoyed Grunt \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Who wrote e I E I'annoyed Grunt\n",
      "-> q_themes: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I E I'annoyed Grunt, i e i-(annoyed, Grunt E, wrote e I, I E, E I'annoyed Grunt, i e I'annoyed Grunt])\n",
      "-> q_themes_enhanced: [('write', ['Q29465908']), ('Write', ['Q1215628'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: i\n",
      "behold: get_most_similar started with: e\n",
      "-> q_predicates: [(wrote, ['P1412']), (e, []), (I, []), (E, [])]\n",
      "-> q_predicates \tRunning time is 7.21s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (wrote, ['P1412']), (e, []), (language of work or name, ['P407']), (country of citizenship, ['P27']), (country of origin, ['P495'])]\n",
      "----> q_themes in context: ([(grunt, ['Q1499903']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (E i e i-(annoyed Grunt, ['Q838742']), (I, ['Q9893', 'Q10299520'])], [I, i, Grunt, wrote, E])\n",
      "--> Potential meaningful keywords for the sentence: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write']\n",
      "---> Meaningful keywords enhanced by previous context: ['grunt', 'E', 'Grunt', 'E i e i-(annoyed Grunt', 'I', 'write', 'Write', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [grunt, E, Grunt, E i e i-(annoyed Grunt, I, write, Write, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (I, ['Q10299520']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (grunt, ['Q1499903']), (E i e i-(annoyed Grunt, ['Q838742'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 68.71s\n",
      "-->  25 nodes and 30 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 25 nodes and 30 edges\n",
      "-> predicates_dict: {'P1441': 178, 'P495': 11, 'P27': 2, 'P364': 6, 'P407': 3, 'P31': 31, 'P3744': 2, 'P3984': 1, 'P1013': 1, 'P585': 10, 'P1113': 1, 'P1411': 4, 'P571': 1, 'P17': 3, 'P131': 1, 'P1545': 3, 'P735': 2, 'P2002': 1, 'P19': 1, 'P1686': 1, 'P406': 1, 'P361': 2, 'P1039': 1, 'P1038': 2, 'P1476': 2, 'P1433': 1, 'P2093': 1, 'P3831': 1, 'P175': 1, 'P577': 3, 'P1346': 49, 'P166': 3, 'P856': 1, 'P453': 8, 'P136': 1, 'P725': 1, 'P161': 1, 'P674': 1, 'P1482': 1, 'P1431': 1, 'P373': 1, 'P910': 1, 'P22': 2, 'P941': 1, 'P272': 1, 'P3912': 1, 'P625': 1}\n",
      "-> paths_keywords: (['e', 'grunt', 'i', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film', 'e i e i-(annoyed grunt'], {'present in work': [present in work, ['P1441']], 'languages spoken, written or signed': [languages spoken written or signed, ['P1412']], 'language of work or name': [language of work or name, ['P407']], 'country of citizenship': [country of citizenship, ['P27']], 'country of origin': [country of origin, ['P495']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 120\n",
      "->Computing possible paths \tRunning time is 11.6s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 118\n",
      "->\tRunning time is 3.46s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 17.8s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 112.96s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                            question  \\\n",
      "309             533    2       False  Who wrote E-I-E-I-(Annoyed Grunt)?   \n",
      "\n",
      "       answer     domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "309  Q3106628  tv_series   False         54.89         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "309           2.79          0.0  False       388.88        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "309        223.18        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "309          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-310-ic533-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 534/2240 -> 3/5 -> Convex=True: (Q3106628) Who wrote E-I-E-I-(Annoyed Grunt)?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q838742\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q7810\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q7810\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                            question  \\\n",
      "310             533    2        True  Who wrote E-I-E-I-(Annoyed Grunt)?   \n",
      "\n",
      "       answer     domain  qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "310  Q3106628  tv_series  Q838742          3.56         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "310           2.84          0.0  Q7810          0.4        0.0   Q7810   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "310          3.14        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "310          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-311-ic533-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 03:56:31.862835\n",
      "\t>>> Processing 534/2240 -> 4/5 -> Convex=False: (1999-11-07T00:00:00Z) When did E-I-E-I-(Annoyed Grunt) first air?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When did E List of The Simpsons episodes E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248'])]\n",
      "-> q_predicates \tRunning time is 10.54s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.79s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When did E List of The Simpsons episodes E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n",
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: air\n",
      "-> q_predicates: [(did, ['P248']), (E, []), (first, ['P577']), (air, [])]\n",
      "-> q_predicates \tRunning time is 10.67s\n",
      "--> Predicates enhanced by previous context: [(did, ['P248']), (E, []), (first, ['P577'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 11.91s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When did E Homer Simpson E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n",
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248'])]\n",
      "-> q_predicates \tRunning time is 10.46s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (did, ['P248'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.09s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P585': 1, 'P1082': 1, 'P571': 3, 'P1441': 2, 'P642': 1, 'P279': 2, 'P361': 3, 'P31': 14, 'P3744': 2, 'P2002': 1, 'P1545': 2, 'P735': 1, 'P131': 5, 'P407': 1, 'P3984': 1, 'P1039': 2, 'P1038': 2, 'P1557': 1, 'P27': 1, 'P1465': 1, 'P17': 2, 'P3831': 1, 'P175': 3, 'P910': 1, 'P138': 2, 'P1464': 1, 'P3373': 1, 'P373': 1, 'P856': 1, 'P1114': 1, 'P1552': 1}\n",
      "-> paths_keywords: (['first', 'e', 'grunt', 'air', 'first air', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt'], {'place of birth': [place of birth, ['P19']], 'stated in': [stated in, ['P248']]}, [When])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 158.91s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When did E Homer Simpson E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n",
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: air\n",
      "-> q_predicates: [(did, ['P248']), (E, []), (first, ['P577']), (air, [])]\n",
      "-> q_predicates \tRunning time is 10.78s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (did, ['P248']), (E, []), (first, ['P577'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.78s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P585': 1, 'P1082': 1, 'P571': 3, 'P31': 14, 'P1557': 2, 'P291': 3, 'P1441': 2, 'P642': 1, 'P279': 2, 'P361': 3, 'P3744': 2, 'P2002': 1, 'P1545': 2, 'P735': 1, 'P131': 5, 'P407': 1, 'P373': 1, 'P3984': 1, 'P1039': 2, 'P1038': 2, 'P138': 3, 'P1465': 1, 'P27': 1, 'P17': 4, 'P3831': 1, 'P175': 3, 'P910': 1, 'P856': 1, 'P1464': 1, 'P3373': 1, 'P1114': 1, 'P1552': 1, 'P1482': 1}\n",
      "-> paths_keywords: (['first', 'e', 'grunt', 'air', 'first air', 'homer simpson', 'springfield', 'e i e i-(annoyed grunt'], {'place of birth': [place of birth, ['P19']], 'stated in': [stated in, ['P248']], 'date of publication': [date of publication, ['P577']]}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 163.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.54s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 206.07s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When did E United States of America E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n",
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(did, ['P248'])]\n",
      "-> q_predicates \tRunning time is 10.76s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (did, ['P248'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.6s\n",
      "-->  16 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 16 nodes and 18 edges\n",
      "-> predicates_dict: {'P1441': 2, 'P495': 9, 'P27': 2, 'P364': 5, 'P407': 1, 'P31': 31, 'P571': 1, 'P577': 3, 'P131': 1, 'P1433': 1, 'P1039': 2, 'P1038': 2, 'P19': 1, 'P361': 3, 'P1476': 1, 'P3744': 1, 'P2002': 1, 'P1545': 3, 'P735': 1, 'P3831': 1, 'P175': 3, 'P642': 1, 'P279': 2, 'P1557': 1, 'P910': 2, 'P138': 1, 'P373': 2, 'P3373': 1, 'P17': 1, 'P161': 1, 'P856': 1, 'P1482': 1, 'P433': 1, 'P1114': 1, 'P1552': 1, 'P2093': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['first', 'e', 'grunt', 'air', 'first air', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film', 'e i e i-(annoyed grunt', 'states'], {'present in work': [present in work, ['P1441']], 'stated in': [stated in, ['P248']]}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 128\n",
      "->Computing possible paths \tRunning time is 15.7s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 122\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 19.17s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: When did E-I-E-I-(Annoyed Grunt) first air?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When did E I E I'annoyed Grunt first air \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When did E United States of America E I'annoyed Grunt first air\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt first air, i e i-(annoyed, Grunt E, Grunt Air, Air E i e i-(annoyed, Air Grunt, Grunt E i e i-(annoyed Air, Grunt Air E i e i-(annoyed, Air E i e i-(annoyed Grunt, Air Grunt E, E E, E I'annoyed Grunt, Did E E I'annoyed Grunt First Air, e e i'annoyed, do e e I'annoyed Grunt first air, Grunt first Air])\n",
      "-> q_themes_enhanced: [('First Air', ['Q1419271'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: e\n",
      "behold: get_most_similar started with: air\n",
      "-> q_predicates: [(did, ['P248']), (E, []), (first, ['P577']), (air, [])]\n",
      "-> q_predicates \tRunning time is 10.81s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (did, ['P248']), (E, []), (first, ['P577'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E, ['Q9907', 'Q12630381']), (Grunt, ['Q24576808']), (Air, ['Q11189065', 'Q11189067']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])], [Grunt, i, Air, E, Did, e, do])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'grunt', 'air', 'E', 'Grunt', 'Air', 'E i e i-(annoyed Grunt', 'first air', 'First Air', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [first, grunt, air, E, Grunt, Air, E i e i-(annoyed Grunt, first air, First Air, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (E, ['Q12630381']), (Grunt, ['Q1499903', 'Q24576808']), (Air, ['Q11189067', 'Q11189065']), (First Air, ['Q1419271']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (grunt, ['Q1499903']), (air, ['Q7391292', 'Q318452']), (E i e i-(annoyed Grunt, ['Q838742']), (first air, ['Q1419271'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.07s\n",
      "-->  16 nodes and 18 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 16 nodes and 18 edges\n",
      "-> predicates_dict: {'P1441': 2, 'P495': 9, 'P27': 2, 'P364': 5, 'P407': 1, 'P31': 34, 'P571': 1, 'P577': 3, 'P1557': 2, 'P131': 1, 'P1433': 1, 'P373': 2, 'P1039': 2, 'P1038': 2, 'P19': 1, 'P361': 3, 'P1476': 1, 'P642': 1, 'P279': 2, 'P3744': 1, 'P2002': 1, 'P1545': 3, 'P735': 1, 'P3831': 1, 'P175': 3, 'P138': 1, 'P856': 1, 'P910': 2, 'P3373': 1, 'P17': 3, 'P161': 1, 'P1482': 1, 'P433': 1, 'P2093': 1, 'P1114': 1, 'P1552': 1, 'P625': 1}\n",
      "-> paths_keywords: (['first', 'e', 'grunt', 'air', 'first air', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film', 'e i e i-(annoyed grunt', 'states'], {'present in work': [present in work, ['P1441']], 'stated in': [stated in, ['P248']], 'date of publication': [date of publication, ['P577']]}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 128\n",
      "->Computing possible paths \tRunning time is 15.72s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 124\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 19.05s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 73.3s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex  \\\n",
      "311             533    3       False   \n",
      "\n",
      "                                        question                answer  \\\n",
      "311  When did E-I-E-I-(Annoyed Grunt) first air?  1999-11-07T00:00:00Z   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "311  tv_series   False         45.37         0.0    False           1.39   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "311          0.0  False       404.12        0.0   False        142.66   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "311        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "311         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-312-ic533-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 534/2240 -> 4/5 -> Convex=True: (1999-11-07T00:00:00Z) When did E-I-E-I-(Annoyed Grunt) first air?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer 2015-05-10T00:00:00Z\n",
      "df_qanswer_rr 1.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q7810\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 2005-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "312             533    3        True   \n",
      "\n",
      "                                        question                answer  \\\n",
      "312  When did E-I-E-I-(Annoyed Grunt) first air?  1999-11-07T00:00:00Z   \n",
      "\n",
      "        domain               qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "312  tv_series  2015-05-10T00:00:00Z          3.23         1.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr  \\\n",
      "312           1.43          0.0  Q7810         0.28        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "312  2005-01-01T00:00:00Z          3.68        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "312        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-313-ic533-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 04:06:34.056321\n",
      "\t>>> Processing 534/2240 -> 5/5 -> Convex=False: (Q129577) What was the previous episode?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.36s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.16s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n",
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.46s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'List of The Simpsons episodes']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, List of The Simpsons episodes]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.41s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n",
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.27s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the, The])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 29.93s\n",
      "-->  12 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 12 nodes and 14 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P155': 2, 'P156': 2, 'P361': 1, 'P577': 2, 'P31': 11, 'P3744': 2, 'P2002': 1, 'P407': 1, 'P3984': 1, 'P495': 1, 'P585': 1, 'P1082': 1, 'P1545': 2, 'P735': 2, 'P1792': 1, 'P1441': 2, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P1465': 1, 'P571': 2, 'P17': 2, 'P27': 1, 'P3831': 1, 'P175': 1, 'P856': 2, 'P144': 1, 'P275': 1, 'P674': 1, 'P170': 1, 'P20': 3, 'P138': 1, 'P154': 1}\n",
      "-> paths_keywords: (['episode', 'homer simpson', 'springfield'], {'place of birth': [place of birth, ['P19']], 'instance of': [instance of, ['P31']], 'latest date': [latest date, ['P1326']], 'number of episodes': [number of episodes, ['P1113']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 129.73s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.11s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n",
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.14s\n",
      "--> Predicates enhanced by previous context: [(place of birth, ['P19']), (be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the, The])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'Homer Simpson', 'Springfield']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, Homer Simpson, Springfield]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (Springfield, ['Q135615', 'Q151076', 'Q1661391']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.11s\n",
      "-->  12 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 12 nodes and 14 edges\n",
      "-> predicates_dict: {'P19': 2893, 'P155': 2, 'P156': 2, 'P361': 1, 'P577': 2, 'P31': 11, 'P3744': 2, 'P2002': 1, 'P407': 1, 'P3984': 1, 'P495': 1, 'P585': 1, 'P1082': 1, 'P1545': 2, 'P735': 2, 'P1792': 1, 'P1441': 2, 'P131': 2, 'P1039': 1, 'P1038': 2, 'P1465': 1, 'P571': 2, 'P27': 1, 'P17': 2, 'P3831': 1, 'P175': 1, 'P856': 2, 'P275': 1, 'P144': 1, 'P674': 1, 'P170': 1, 'P20': 3, 'P138': 1, 'P154': 1}\n",
      "-> paths_keywords: (['episode', 'homer simpson', 'springfield'], {'place of birth': [place of birth, ['P19']], 'instance of': [instance of, ['P31']], 'latest date': [latest date, ['P1326']], 'number of episodes': [number of episodes, ['P1113']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 130.1s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.48s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 170.76s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n",
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.36s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the, The])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.09s\n",
      "-->  20 nodes and 24 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 20 nodes and 24 edges\n",
      "-> predicates_dict: {'P1441': 2, 'P495': 10, 'P27': 2, 'P364': 5, 'P407': 1, 'P31': 31, 'P155': 2, 'P156': 2, 'P361': 1, 'P131': 1, 'P577': 5, 'P3744': 1, 'P2002': 1, 'P19': 1, 'P1039': 1, 'P1038': 2, 'P1545': 3, 'P735': 2, 'P1476': 2, 'P1433': 1, 'P3831': 1, 'P175': 1, 'P856': 1, 'P17': 1, 'P275': 1, 'P136': 1, 'P2093': 1, 'P161': 1, 'P674': 1, 'P2860': 1, 'P170': 1, 'P910': 1, 'P154': 1, 'P373': 1}\n",
      "-> paths_keywords: (['episode', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film'], {'present in work': [present in work, ['P1441']], 'instance of': [instance of, ['P31']], 'latest date': [latest date, ['P1326']], 'number of episodes': [number of episodes, ['P1113']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 122\n",
      "->Computing possible paths \tRunning time is 13.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 122\n",
      "->\tRunning time is 3.52s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 15.48s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What was the previous episode?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the previous episode \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the previous episode\n",
      "-> q_themes: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the previous episode, The Previous Episode, the previous Episode])\n",
      "-> q_themes_enhanced: [('Previous', ['Q7242420'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: previous\n",
      "-> q_predicates: [(be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "-> q_predicates \tRunning time is 4.44s\n",
      "--> Predicates enhanced by previous context: [(present in work, ['P1441']), (be, ['P31']), (previous, ['P1326']), (episode, ['P1113'])]\n",
      "----> q_themes in context: ([(episode, ['Q1983062', 'Q900962']), (Episode, ['Q23705710', 'Q11290527'])], [the, The])\n",
      "--> Potential meaningful keywords for the sentence: ['episode', 'Episode', 'Previous']\n",
      "---> Meaningful keywords enhanced by previous context: ['episode', 'Episode', 'Previous', 'Homer Simpson', 'The Simpsons', 'Feed', 'United States of America', 'Feed', 'English', 'film']\n",
      "meaningful_names_no_previous_answer [episode, Episode, Previous, Homer Simpson, The Simpsons, Feed, United States of America, Feed, English, film]\n",
      "----> Meaningful keywords casted as theme ([(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(Episode, ['Q23705710', 'Q11290527']), (Homer Simpson, ['Q7810']), (The Simpsons, ['Q2608462', 'Q56095030', 'Q7764349']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (United States of America, ['Q30', 'Q19971019']), (Feed, ['Q39073791', 'Q258692', 'Q1400892']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (film, ['Q11424']), (episode, ['Q1983062', 'Q900962'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 24.14s\n",
      "-->  20 nodes and 24 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 20 nodes and 24 edges\n",
      "-> predicates_dict: {'P1441': 2, 'P495': 10, 'P27': 2, 'P364': 5, 'P407': 1, 'P31': 31, 'P155': 2, 'P156': 2, 'P361': 1, 'P131': 1, 'P577': 5, 'P3744': 1, 'P2002': 1, 'P19': 1, 'P1039': 1, 'P1038': 2, 'P1545': 3, 'P735': 2, 'P1476': 2, 'P1433': 1, 'P3831': 1, 'P175': 1, 'P856': 1, 'P17': 1, 'P275': 1, 'P136': 1, 'P2860': 1, 'P2093': 1, 'P161': 1, 'P674': 1, 'P170': 1, 'P910': 1, 'P154': 1, 'P373': 1}\n",
      "-> paths_keywords: (['episode', 'homer simpson', 'the simpsons', 'feed', 'united states of america', 'english', 'film'], {'present in work': [present in work, ['P1441']], 'instance of': [instance of, ['P31']], 'latest date': [latest date, ['P1326']], 'number of episodes': [number of episodes, ['P1113']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 122\n",
      "->Computing possible paths \tRunning time is 13.18s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 122\n",
      "->\tRunning time is 3.53s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 15.83s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 64.84s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                        question   answer  \\\n",
      "313             533    4       False  What was the previous episode?  Q129577   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "313  tv_series   False         45.86         0.0    False            0.2   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "313          0.0  False       338.97        0.0   False        126.14   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "313        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "313         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-314-ic533-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 534/2240 -> 5/5 -> Convex=True: (Q129577) What was the previous episode?                                  \n",
      "qAnswer extended by Convex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer Q886\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q11084270\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q30\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                        question   answer  \\\n",
      "314             533    4        True  What was the previous episode?  Q129577   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "314  tv_series    Q886          2.59         0.0    False           0.23   \n",
      "\n",
      "     platypus_rr     convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "314          0.0  Q11084270         0.16        0.0     Q30          4.44   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "314        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "314         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-315-ic533-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 04:15:12.690909\n",
      "\t>>> Processing 535/2240 -> 1/5 -> Convex=False: (Q79904) What is the name of the author of The Catcher in the Rye?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q79904\n",
      "df_qanswer_rr 1.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q79904\n",
      "df_convex_rr 1.0\n",
      "\n",
      "CORRECT 535 - 1 -> qAnswer Q79904\n",
      "\n",
      "CORRECT 535 - 1 -> Convex Q79904\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What is the name of the author of The Catcher in the Rye?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the author of The Catcher in the Rye \n",
      "-> q_themes: ([(The Catcher in the Rye, ['Q183883']), (the name, ['Q50929476', 'Q25217641']), (the author, ['Q21451533', 'Q51159453']), (The Catcher, ['Q7721701']), (the Rye, ['Q7761917', 'Q7761918']), (rye, ['Q1020800', 'Q1379757']), (Rye, ['Q1228965']), (Catcher, ['Q1050571', 'Q41888721']), (Catcher in the Rye, ['Q16184712', 'Q5051738']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561']), (author, ['Q482980', 'P50'])], [is the name of the author of The])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: rye\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (author, ['P50']), (Rye, [])]\n",
      "-> q_predicates \tRunning time is 9.27s\n",
      "--> Potential meaningful keywords for the sentence: ['The Catcher in the Rye', 'the name', 'the author', 'The Catcher', 'the Rye', 'rye', 'Rye', 'Catcher', 'Catcher in the Rye', 'The Name', 'name', 'author', 'Author']\n",
      "q_focused_parts: [(author, ['Q482980', 'P50'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 62.71s\n",
      "-->  2019 nodes and 2022 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 214 nodes and 216 edges\n",
      "-> predicates_dict: {'P50': 3, 'P1071': 2, 'P131': 9, 'P1552': 1, 'P155': 8, 'P156': 7, 'P527': 1, 'P800': 1, 'P39': 2, 'P1013': 1, 'P1810': 2, 'P856': 2, 'P407': 3, 'P31': 892, 'P2868': 2, 'P1441': 2, 'P953': 1, 'P138': 1, 'P585': 3, 'P1082': 3, 'P1465': 1, 'P364': 1, 'P1464': 2, 'P569': 1, 'P136': 2, 'P421': 2, 'P582': 1, 'P1308': 2, 'P813': 1, 'P973': 1, 'P1709': 1, 'P1476': 4, 'P123': 1, 'P577': 4, 'P580': 1, 'P495': 2, 'P2521': 1, 'P360': 3, 'P291': 1, 'P1433': 1, 'P1792': 1, 'P27': 1, 'P58': 1, 'P17': 4, 'P625': 1, 'P921': 1, 'P279': 1, 'P106': 3, 'P1545': 6, 'P4908': 3, 'P179': 3, 'P21': 1, 'P47': 1, 'P161': 1, 'P94': 1, 'P1036': 2, 'P373': 1}\n",
      "-> paths_keywords: (['author', 'name', 'catcher', 'the catcher in the rye', 'the author', 'the catcher', 'the rye', 'rye', 'the name'], {'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'Author': [author, ['P50']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 688\n",
      "->Computing possible paths \tRunning time is 76.21s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 872\n",
      "->\tRunning time is 3.7s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q571', 1.475755750658494], ['Q25379', 1.3970392771482665], ['Q5185279', 1.2211903376629365], ['Q45077201', 1.1368623349575253], ['Q1860', 1.049899222897138], ['Q15063611', 0.9889909933036268], ['Q3957', 0.9877180690945323], ['Q21191270', 0.9436168093389394], ['Q1115575', 0.8098704084235182], ['Q11424', 0.7024320629667359], ['Rye CP/AP', 0.4548265701486875], ['Rye, Sussex', 0.28912386014955305], ['Q25164', -0.12055089151722918]]\n",
      "->Computing hypothesises \tRunning time is 256.8s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 12\n",
      "->\tRunning time is 16.16s\n",
      "--> len(cleared_golden_paths): 6\n",
      "---> First path: ['Q571', 'P31', 'Q183883', 'P407', 'Q1860', 'P364', 'Q7721701', 'P495', 'Q30', 'P17', 'Q1379757', 'P1465', 'Q32653524']\n",
      "->\tTotal Running time is 428.97s\n",
      "\n",
      "df_graphqa Q571\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "315             534    0       False   \n",
      "\n",
      "                                              question  answer domain qanswer  \\\n",
      "315  What is the name of the author of The Catcher ...  Q79904  books  Q79904   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  convex  \\\n",
      "315          1.04         1.0    False          40.53          0.0  Q79904   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "315         1.19        1.0    Q571        429.22        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "315        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-316-ic534-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 04:23:04.704045\n",
      "\t>>> Processing 535/2240 -> 2/5 -> Convex=False: (Q8441) And the writer is male or female?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And the writer is male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 4.88s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.1s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And the writer male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 4.94s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 27.25s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And the writer is male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 5.18s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.34s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 15754, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P21': 1, 'P58': 2, 'P106': 2, 'P156': 1, 'P31': 10, 'P1441': 2, 'P953': 1, 'P571': 1, 'P407': 1, 'P136': 3, 'P580': 1, 'P582': 1, 'P26': 1, 'P800': 1, 'P364': 2, 'P123': 1, 'P19': 1, 'P973': 1, 'P361': 2, 'P607': 1, 'P1476': 1, 'P69': 1, 'P170': 2, 'P495': 2, 'P155': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P840': 1, 'P577': 2, 'P175': 2, 'P2438': 1, 'P2437': 1, 'P161': 1, 'P1113': 1, 'P1545': 2, 'P735': 2}\n",
      "-> paths_keywords: (['the writer', 'male', 'the catcher in the rye', 'j. d. salinger', 'writer'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'screenwriter': [screenwriter, ['P58']], 'female': [sex or gender, ['P21']], 'male population': [male population, ['P1540']], 'female population': [female population, ['P1539']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 155.71s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.75s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And author the writer male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 4.77s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.06s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 15754, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P21': 1, 'P58': 2, 'P106': 2, 'P156': 1, 'P31': 10, 'P1441': 2, 'P953': 1, 'P571': 1, 'P407': 1, 'P136': 3, 'P580': 1, 'P582': 1, 'P26': 1, 'P800': 1, 'P364': 2, 'P123': 1, 'P19': 1, 'P973': 1, 'P361': 2, 'P607': 1, 'P1476': 1, 'P69': 1, 'P170': 2, 'P495': 2, 'P155': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P840': 1, 'P577': 2, 'P175': 2, 'P2438': 1, 'P2437': 1, 'P161': 1, 'P1113': 1, 'P1545': 2, 'P735': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['the writer', 'male', 'the catcher in the rye', 'j. d. salinger', 'writer'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'screenwriter': [screenwriter, ['P58']], 'female': [sex or gender, ['P21']], 'male population': [male population, ['P1540']], 'female population': [female population, ['P1539']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 159.77s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 5.98s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 205.77s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And the writer is male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 8.17s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539']), (original language of work, ['P364']), (country of origin, ['P495']), (country, ['P17']), (category for people who died here, ['P1465'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 63.35s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 2, 'P31': 18, 'P1465': 2, 'P364': 4, 'P1464': 4, 'P495': 5, 'P17': 7, 'P50': 1, 'P58': 1, 'P156': 1, 'P1013': 2, 'P585': 3, 'P1082': 3, 'P1441': 2, 'P1792': 1, 'P20': 1, 'P361': 2, 'P131': 6, 'P291': 1, 'P840': 1, 'P19': 2, 'P2868': 2, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P166': 1, 'P136': 5, 'P155': 1, 'P47': 3, 'P170': 1, 'P373': 2, 'P2437': 1, 'P282': 1, 'P1810': 2, 'P577': 3, 'P175': 2, 'P2438': 1, 'P910': 2, 'P138': 1, 'P161': 4, 'P921': 1, 'P1113': 1, 'P856': 1, 'P1705': 1, 'P915': 1}\n",
      "-> paths_keywords: (['the writer', 'male', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'book', 'united states of america', 'writer'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'author': [author, ['P50']], 'screenwriter': [screenwriter, ['P58']], 'female': [sex or gender, ['P21']], 'male population': [male population, ['P1540']], 'female population': [female population, ['P1539']], 'original language of work': [original language of work, ['P364']], 'country of origin': [country of origin, ['P495']], 'country': [country, ['P17']], 'category for people who died here': [category for people who died here, ['P1465']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 92\n",
      "->Computing possible paths \tRunning time is 149.56s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14\n",
      "->\tRunning time is 3.87s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 4.43s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: And the writer is male or female?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And the writer is male or female \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And instance of the writer language of work or name male or female\n",
      "-> q_themes: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "-> q_themes_enhanced: [('female', ['P21'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539'])]\n",
      "-> q_predicates \tRunning time is 5.93s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (writer, ['P50', 'P58']), (male, ['P21', 'P1540']), (female, ['P21', 'P1539']), (original language of work, ['P364']), (country of origin, ['P495']), (country, ['P17']), (category for people who died here, ['P1465'])]\n",
      "----> q_themes in context: ([(the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180']), (The Writer, ['Q30923680', 'Q26772387']), (Male, ['Q6581097', 'Q1887095']), (Female, ['Q6581072', 'Q47128284'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female']\n",
      "---> Meaningful keywords enhanced by previous context: ['the writer', 'Writer', 'The Writer', 'Male', 'Female', 'female', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the writer, Writer, The Writer, Male, Female, female, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(The Writer, ['Q684509', 'Q30923680', 'Q26772387']), (Male, ['Q1887095']), (Female, ['Q47128284']), (female, ['Q6581072']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the writer, ['Q684509', 'Q7776323']), (Writer, ['Q36180'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 46.39s\n",
      "-->  8 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 8 nodes and 8 edges\n",
      "-> predicates_dict: {'P407': 2, 'P31': 18, 'P1465': 2, 'P364': 4, 'P1464': 4, 'P495': 5, 'P17': 7, 'P50': 1, 'P58': 1, 'P156': 1, 'P1013': 2, 'P585': 3, 'P1082': 3, 'P1441': 2, 'P1792': 1, 'P20': 1, 'P361': 2, 'P131': 6, 'P291': 1, 'P840': 1, 'P19': 2, 'P2868': 2, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P166': 1, 'P136': 5, 'P155': 1, 'P47': 3, 'P170': 1, 'P373': 2, 'P2437': 1, 'P282': 1, 'P577': 3, 'P1810': 2, 'P175': 2, 'P2438': 1, 'P910': 2, 'P138': 1, 'P161': 4, 'P921': 1, 'P1113': 1, 'P856': 1, 'P1705': 1, 'P915': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> paths_keywords: (['the writer', 'male', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'book', 'united states of america', 'writer', 'instance', 'language'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'author': [author, ['P50']], 'screenwriter': [screenwriter, ['P58']], 'female': [sex or gender, ['P21']], 'male population': [male population, ['P1540']], 'female population': [female population, ['P1539']], 'original language of work': [original language of work, ['P364']], 'country of origin': [country of origin, ['P495']], 'country': [country, ['P17']], 'category for people who died here': [category for people who died here, ['P1465']]}, [])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 92\n",
      "->Computing possible paths \tRunning time is 164.32s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14\n",
      "->\tRunning time is 3.87s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 4.5s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 229.26s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "316             534    1       False  And the writer is male or female?   \n",
      "\n",
      "    answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "316  Q8441  books   False         65.64         0.0    False           0.34   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "316          0.0  False       399.96        0.0   False        459.74   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "316        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "316         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-317-ic534-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 535/2240 -> 2/5 -> Convex=True: (Q8441) And the writer is male or female?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q36180\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q36180\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q79904\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "317             534    1        True  And the writer is male or female?   \n",
      "\n",
      "    answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "317  Q8441  books  Q36180          0.86         0.0    False           0.37   \n",
      "\n",
      "     platypus_rr  convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "317          0.0  Q36180         0.27        0.0  Q79904          0.62   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "317        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "317         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-318-ic534-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 04:38:32.567145\n",
      "\t>>> Processing 535/2240 -> 3/5 -> Convex=False: (Q60) And where is the author from originally?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And where is the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.24s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.49s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And where the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.51s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 16.63s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And where is the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.52s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 18.82s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 15754, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P106': 2, 'P31': 4, 'P1441': 2, 'P953': 1, 'P571': 1, 'P136': 2, 'P580': 1, 'P582': 1, 'P26': 1, 'P800': 1, 'P123': 1, 'P973': 1, 'P607': 1, 'P1476': 1, 'P170': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P1545': 1, 'P735': 1}\n",
      "-> paths_keywords: (['author', 'the catcher in the rye', 'j. d. salinger', 'the author'], {'Author': [author, ['P50']], 'instance of': [instance of, ['P31']]}, [where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 143.09s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And where the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.32s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.92s\n",
      "-->  3 nodes and 2 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 3 nodes and 2 edges\n",
      "-> predicates_dict: {'P50': 15754, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P106': 2, 'P31': 4, 'P1441': 2, 'P953': 1, 'P571': 1, 'P136': 2, 'P580': 1, 'P582': 1, 'P26': 1, 'P800': 1, 'P123': 1, 'P973': 1, 'P607': 1, 'P1476': 1, 'P170': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P1545': 1, 'P735': 1}\n",
      "-> paths_keywords: (['author', 'the catcher in the rye', 'j. d. salinger', 'the author'], {'Author': [author, ['P50']], 'instance of': [instance of, ['P31']]}, [where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 141.0s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.69s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.09s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 172.66s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: And where is the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.27s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 28.45s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P407': 2, 'P31': 12, 'P1465': 2, 'P364': 2, 'P1464': 4, 'P495': 3, 'P17': 4, 'P50': 1, 'P1013': 2, 'P1792': 1, 'P1441': 2, 'P131': 5, 'P585': 3, 'P1082': 3, 'P2868': 2, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P136': 3, 'P373': 2, 'P577': 1, 'P291': 1, 'P282': 1, 'P921': 1, 'P138': 1, 'P910': 1, 'P47': 1, 'P856': 1}\n",
      "-> paths_keywords: (['author', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'book', 'united states of america', 'the author'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'Author': [author, ['P50']]}, [where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 42\n",
      "->Computing possible paths \tRunning time is 148.53s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 6\n",
      "->\tRunning time is 3.86s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.96s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: And where is the author from originally?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: And where is the author from originally \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: And where the author from originally\n",
      "-> q_themes: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "-> q_themes_enhanced: [('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.04s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (author, ['P50'])]\n",
      "----> q_themes in context: ([(the author, ['Q21451533', 'Q51159453']), (author, ['Q482980', 'P50'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the author', 'author', 'Author']\n",
      "---> Meaningful keywords enhanced by previous context: ['the author', 'author', 'Author', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the author, author, Author, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(author, ['P50']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the author, ['Q21451533', 'Q51159453'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 28.16s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P407': 2, 'P31': 12, 'P1465': 2, 'P364': 2, 'P1464': 4, 'P495': 3, 'P17': 4, 'P50': 1, 'P1013': 2, 'P1792': 1, 'P1441': 2, 'P131': 5, 'P585': 3, 'P1082': 3, 'P2868': 2, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P136': 3, 'P373': 2, 'P577': 1, 'P291': 1, 'P282': 1, 'P921': 1, 'P138': 1, 'P910': 1, 'P47': 1, 'P856': 1}\n",
      "-> paths_keywords: (['author', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'book', 'united states of america', 'the author'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'Author': [author, ['P50']]}, [where])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 42\n",
      "->Computing possible paths \tRunning time is 148.89s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 6\n",
      "->\tRunning time is 3.62s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 1.97s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 191.52s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex  \\\n",
      "318             534    2       False   \n",
      "\n",
      "                                     question answer domain qanswer  \\\n",
      "318  And where is the author from originally?    Q60  books   False   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr convex  \\\n",
      "318         44.35         0.0    False           0.18          0.0  False   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "318       344.39        0.0   False        380.45        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "318        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-319-ic534-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 535/2240 -> 3/5 -> Convex=True: (Q60) And where is the author from originally?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q7766941\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q79904\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q183883\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "319             534    2        True   \n",
      "\n",
      "                                     question answer domain   qanswer  \\\n",
      "319  And where is the author from originally?    Q60  books  Q7766941   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  convex  \\\n",
      "319           0.2         0.0    False           0.23          0.0  Q79904   \n",
      "\n",
      "     convex_time  convex_rr  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "319         0.26        0.0  Q183883          0.54        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "319        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-320-ic534-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 04:51:23.212637\n",
      "\t>>> Processing 535/2240 -> 4/5 -> Convex=False: (1951-01-01T00:00:00Z) When was the book published?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When was the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "-> q_predicates \tRunning time is 4.04s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 17.61s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 4.27s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (published, ['P577', 'P1433']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 18.35s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When was the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "-> q_predicates \tRunning time is 4.2s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'The Catcher in the Rye', 'J. D. Salinger']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.39s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P50': 15755, 'P478': 1, 'P854': 1, 'P1343': 2, 'P958': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P577': 2, 'P2031': 1, 'P569': 1, 'P570': 1, 'P571': 1, 'P1013': 1, 'P31': 9, 'P180': 1, 'P1104': 2, 'P1441': 2, 'P953': 1, 'P407': 1, 'P166': 1, 'P123': 1, 'P373': 1, 'P276': 1, 'P1476': 1, 'P1289': 1, 'P973': 1, 'P170': 1, 'P110': 1, 'P195': 1, 'P217': 1, 'P136': 1}\n",
      "-> paths_keywords: (['book', 'the book', 'the catcher in the rye', 'j. d. salinger'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 148.05s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.84s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 4.24s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.08s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P50': 15755, 'P478': 1, 'P854': 1, 'P1343': 2, 'P958': 1, 'P580': 1, 'P582': 1, 'P26': 1, 'P577': 2, 'P2031': 1, 'P569': 1, 'P570': 1, 'P571': 1, 'P1013': 1, 'P31': 9, 'P180': 1, 'P1104': 2, 'P1441': 2, 'P953': 1, 'P407': 1, 'P166': 1, 'P123': 1, 'P373': 1, 'P276': 1, 'P973': 1, 'P1289': 1, 'P170': 1, 'P1476': 1, 'P110': 1, 'P195': 1, 'P217': 1, 'P136': 1}\n",
      "-> paths_keywords: (['book', 'the book', 'the catcher in the rye', 'j. d. salinger'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 149.24s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.6s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 180.87s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: When was the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "-> q_predicates \tRunning time is 4.13s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (published, ['P577', 'P1433'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q11515178', 'Q421300', 'Q16860229']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(Book, ['Q11515178', 'Q421300', 'Q16860229']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 29.07s\n",
      "-->  11 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 10 edges\n",
      "-> predicates_dict: {'P407': 3, 'P31': 16, 'P1465': 2, 'P364': 2, 'P1464': 4, 'P495': 2, 'P17': 4, 'P585': 3, 'P1082': 3, 'P577': 3, 'P291': 1, 'P1013': 2, 'P1792': 1, 'P1441': 2, 'P131': 6, 'P1104': 2, 'P2868': 2, 'P19': 5, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P166': 1, 'P373': 3, 'P276': 3, 'P50': 1, 'P180': 1, 'P856': 2, 'P136': 1, 'P282': 1, 'P910': 1}\n",
      "-> paths_keywords: (['book', 'the book', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'united states of america'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 108.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.8s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 5.83s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: When was the book published?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: When was the book published \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: When the book published\n",
      "> Time related question detected\n",
      "-> q_themes: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (published, ['P577', 'P1433']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 4.28s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (published, ['P577', 'P1433']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(the book, ['Q3794440']), (Book, ['Q571', 'Q421300']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the book', 'Book', 'The Book', 'book']\n",
      "---> Meaningful keywords enhanced by previous context: ['the book', 'Book', 'The Book', 'book', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [the book, Book, The Book, book, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q11515178', 'Q421300', 'Q16860229']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(Book, ['Q11515178', 'Q421300', 'Q16860229']), (The Book, ['Q11250715', 'Q10695431']), (book, ['Q997698']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 30.72s\n",
      "-->  11 nodes and 10 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 11 nodes and 10 edges\n",
      "-> predicates_dict: {'P407': 3, 'P31': 16, 'P1465': 2, 'P364': 2, 'P1464': 4, 'P495': 2, 'P17': 4, 'P1013': 2, 'P180': 1, 'P585': 3, 'P1082': 3, 'P577': 3, 'P50': 2, 'P291': 1, 'P1792': 1, 'P1441': 2, 'P131': 6, 'P1104': 2, 'P2868': 2, 'P19': 5, 'P1476': 2, 'P953': 1, 'P123': 1, 'P421': 2, 'P166': 1, 'P373': 3, 'P276': 3, 'P282': 1, 'P110': 1, 'P856': 2, 'P136': 2, 'P921': 1, 'P910': 1, 'P138': 1, 'P47': 1}\n",
      "-> paths_keywords: (['book', 'the book', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'united states of america'], {}, [When])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 110\n",
      "->Computing possible paths \tRunning time is 111.14s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 16\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 6.0s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 160.04s\n",
      "\n",
      "df_graphqa False\n",
      "df_graphqa_rr 0\n",
      "    conversation_id turn plus_convex                      question  \\\n",
      "320             534    3       False  When was the book published?   \n",
      "\n",
      "                   answer domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "320  1951-01-01T00:00:00Z  books   False         44.76         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr graphqa  \\\n",
      "320           0.71          0.0  False       358.03        0.0   False   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "320         312.6        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "320          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-321-ic534-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 535/2240 -> 4/5 -> Convex=True: (1951-01-01T00:00:00Z) When was the book published?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q2977500\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 1951-07-16T00:00:00Z\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1998-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                      question  \\\n",
      "321             534    3        True  When was the book published?   \n",
      "\n",
      "                   answer domain   qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "321  1951-01-01T00:00:00Z  books  Q2977500          0.32         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr                convex  convex_time  convex_rr  \\\n",
      "321           0.74          0.0  1951-07-16T00:00:00Z         0.27        0.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "321  1998-01-01T00:00:00Z          0.55        False        False   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "321        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-322-ic534-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:03:21.244113\n",
      "\t>>> Processing 535/2240 -> 5/5 -> Convex=False: (Q720235) What's the main character's name?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What's the main character's name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the main character name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the main character name\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the main character name, Character Name, Name Character, The Main Character Name, main character name, the main Character Name])\n",
      "-> q_themes_enhanced: [('main character', ['Q50937280']), ('main', ['Q3278265']), ('The Main', ['Q24025978']), ('The Name', ['Q12592731']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 9.47s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the, Character, Name, The, main])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [what, character, name, What, Character, Name, main character, main, The Main, The Name, Main, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (J. D. Salinger, ['Q79904', 'Q47509501']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 44.55s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What's the main character's name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the main character name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the main character name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the main character name, Character Name, Name Character, The Main Character Name, main character name, the main Character Name])\n",
      "-> q_themes_enhanced: [('main character', ['Q50937280']), ('main', ['Q3278265']), ('The Main', ['Q24025978']), ('The Name', ['Q12592731']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 9.47s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the, Character, Name, The, main])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [what, character, name, What, Character, Name, main character, main, The Main, The Name, Main, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (J. D. Salinger, ['Q79904', 'Q47509501']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 57.3s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What's the main character's name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the main character name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the main character name\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the main character name, Character Name, Name Character, The Main Character Name, main character name, the main Character Name])\n",
      "-> q_themes_enhanced: [('main character', ['Q50937280']), ('main', ['Q3278265']), ('The Main', ['Q24025978']), ('The Name', ['Q12592731']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 9.6s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [Character, Name, main])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main', 'The Catcher in the Rye', 'J. D. Salinger']\n",
      "meaningful_names_no_previous_answer [what, character, name, What, Character, Name, main character, main, The Main, The Name, Main, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 47.23s\n",
      "-->  12 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 12 nodes and 16 edges\n",
      "-> predicates_dict: {'P50': 15755, 'P155': 6, 'P156': 4, 'P279': 9, 'P1535': 1, 'P180': 2, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P1545': 4, 'P735': 2, 'P921': 1, 'P910': 2, 'P674': 1, 'P407': 2, 'P106': 3, 'P2868': 3, 'P31': 689, 'P360': 1, 'P1441': 2, 'P518': 1, 'P186': 1, 'P953': 1, 'P138': 1, 'P4908': 1, 'P527': 2, 'P571': 2, 'P373': 1, 'P131': 3, 'P179': 1, 'P569': 1, 'P136': 3, 'P580': 2, 'P582': 1, 'P361': 1, 'P123': 1, 'P800': 2, 'P26': 1, 'P577': 3, 'P1435': 1, 'P495': 1, 'P973': 1, 'P607': 1, 'P1476': 2, 'P2438': 1, 'P69': 1, 'P840': 1, 'P170': 2, 'P264': 2, 'P642': 1, 'P111': 1, 'P27': 2, 'P195': 2, 'P217': 2, 'P276': 2, 'P21': 1, 'P166': 1, 'P625': 1}\n",
      "-> paths_keywords: (['character', 'name', 'what', 'the catcher in the rye', 'j. d. salinger'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'characters': [characters, ['P674']], 'name': [name, ['P2561']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 166.01s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What's the main character's name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the main character name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the main character name\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the main character name, Character Name, Name Character, The Main Character Name, main character name, the main Character Name])\n",
      "-> q_themes_enhanced: [('main character', ['Q50937280']), ('main', ['Q3278265']), ('The Main', ['Q24025978']), ('The Name', ['Q12592731']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 9.54s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [Character, Name, main])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main', 'The Catcher in the Rye', 'J. D. Salinger']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [what, character, name, What, Character, Name, main character, main, The Main, The Name, Main, The Catcher in the Rye, J. D. Salinger]\n",
      "----> Meaningful keywords casted as theme ([(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501'])], [])\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (J. D. Salinger, ['Q79904', 'Q47509501']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 44.84s\n",
      "-->  12 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 12 nodes and 16 edges\n",
      "-> predicates_dict: {'P50': 15755, 'P155': 6, 'P156': 4, 'P478': 1, 'P854': 3, 'P1343': 4, 'P958': 1, 'P1545': 4, 'P735': 2, 'P279': 9, 'P1535': 1, 'P180': 2, 'P921': 1, 'P910': 2, 'P674': 1, 'P407': 2, 'P106': 3, 'P2868': 3, 'P31': 689, 'P360': 1, 'P1441': 2, 'P518': 1, 'P186': 1, 'P953': 1, 'P138': 1, 'P4908': 1, 'P527': 2, 'P571': 2, 'P373': 1, 'P131': 3, 'P179': 1, 'P569': 1, 'P136': 3, 'P580': 2, 'P361': 1, 'P26': 1, 'P582': 1, 'P800': 2, 'P123': 1, 'P577': 3, 'P1435': 1, 'P495': 1, 'P973': 1, 'P607': 1, 'P1476': 2, 'P2438': 1, 'P69': 1, 'P840': 1, 'P170': 2, 'P264': 2, 'P642': 1, 'P111': 1, 'P27': 2, 'P195': 2, 'P217': 2, 'P276': 2, 'P21': 1, 'P166': 1, 'P625': 1}\n",
      "-> paths_keywords: (['character', 'name', 'what', 'the catcher in the rye', 'j. d. salinger'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'characters': [characters, ['P674']], 'name': [name, ['P2561']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 166.82s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.83s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.15s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 228.64s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What's the main character's name?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the main character name \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the main character name\n",
      "-> q_themes: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [the main character name, Character Name, Name Character, The Main Character Name, main character name, the main Character Name])\n",
      "-> q_themes_enhanced: [('main character', ['Q50937280']), ('main', ['Q3278265']), ('The Main', ['Q24025978']), ('The Name', ['Q12592731']), ('Main', ['Q10575454'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 9.6s\n",
      "--> Predicates enhanced by previous context: [(language of work or name, ['P407']), (be, ['P31']), (name, ['P735', 'P1448']), (main, ['P921', 'P301']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(what, ['Q20656446', 'Q28036789']), (character, ['Q3241972', 'Q1792372']), (name, ['Q82799', 'P2561']), (What, ['Q22073920']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817'])], [Character, Name, main])\n",
      "--> Potential meaningful keywords for the sentence: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main']\n",
      "---> Meaningful keywords enhanced by previous context: ['what', 'character', 'name', 'What', 'Character', 'Name', 'main character', 'main', 'The Main', 'The Name', 'Main', 'The Catcher in the Rye', 'The Catcher', 'Rye', 'English', 'Book', '', '', 'United States of America']\n",
      "meaningful_names_no_previous_answer [what, character, name, What, Character, Name, main character, main, The Main, The Name, Main, The Catcher in the Rye, The Catcher, Rye, English, Book, United States of America]\n",
      "----> Meaningful keywords casted as theme ([(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019'])], [])\n",
      "q_focused_parts: [(character, ['Q3241972', 'Q1792372']), (name, ['P2561']), (What, ['Q22073920', 'Q28036789']), (Character, ['Q1062911', 'Q1880113']), (Name, ['Q11236330', 'Q13873817']), (The Catcher in the Rye, ['Q16689546', 'Q3520222', 'Q183883']), (The Catcher, ['Q7721701']), (Rye, ['Q1379757', 'Q1020800', 'Q1228965']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (United States of America, ['Q30', 'Q19971019']), (what, ['Q20656446', 'Q28036789'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.81s\n",
      "-->  17 nodes and 20 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 20 edges\n",
      "-> predicates_dict: {'P407': 3, 'P31': 697, 'P1465': 2, 'P364': 2, 'P1464': 4, 'P495': 4, 'P17': 5, 'P155': 6, 'P156': 4, 'P279': 9, 'P1535': 1, 'P180': 2, 'P921': 2, 'P910': 4, 'P674': 1, 'P1013': 2, 'P571': 1, 'P734': 3, 'P856': 2, 'P360': 1, 'P1441': 2, 'P2868': 5, 'P1792': 1, 'P518': 1, 'P186': 1, 'P131': 8, 'P1810': 2, 'P361': 1, 'P585': 3, 'P1082': 3, 'P1545': 2, 'P179': 1, 'P1476': 3, 'P27': 1, 'P953': 1, 'P642': 1, 'P111': 1, 'P138': 2, 'P123': 1, 'P4908': 1, 'P527': 2, 'P577': 3, 'P421': 2, 'P195': 1, 'P217': 1, 'P276': 1, 'P373': 4, 'P580': 1, 'P1435': 1, 'P569': 1, 'P264': 2, 'P291': 1, 'P2438': 1, 'P840': 2, 'P21': 1, 'P166': 1, 'P136': 5, 'P170': 1, 'P94': 1, 'P50': 1, 'P625': 4, 'P106': 1}\n",
      "-> paths_keywords: (['character', 'name', 'what', 'the catcher in the rye', 'the catcher', 'rye', 'english', 'book', 'united states of america'], {'language of work or name': [language of work or name, ['P407']], 'instance of': [instance of, ['P31']], 'given name': [given name, ['P735']], 'official name': [official name, ['P1448']], 'main subject': [main subject, ['P921']], \"category's main topic\": [category main topic, ['P301']], 'characters': [characters, ['P674']], 'name': [name, ['P2561']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 320\n",
      "->Computing possible paths \tRunning time is 50.65s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 258\n",
      "->\tRunning time is 3.66s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q720235', 2.9291704269742023]]\n",
      "->Computing hypothesises \tRunning time is 74.51s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 4.23s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q720235', 'P674', 'Q183883', 'P840', 'Q30', 'P495', 'Q7721701', 'P364', 'Q1860', 'P407', 'Q13873817']\n",
      "->\tTotal Running time is 200.7s\n",
      "\n",
      "df_graphqa Q720235\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 535 - 5 -> graphqa Q720235\n",
      "\n",
      "PARTIAL_CORRECT 535 - 5 -> graphqa in answers ['Q720235']\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "322             534    4       False  What's the main character's name?   \n",
      "\n",
      "      answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "322  Q720235  books   False        121.25         0.0    False            0.8   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr  graphqa  graphqa_time  \\\n",
      "322          0.0  False       456.27        0.0  Q720235        201.11   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "322         True         True         True         True           True   \n",
      "\n",
      "     graphqa_rr  \n",
      "322         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-323-ic534-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 535/2240 -> 5/5 -> Convex=True: (Q720235) What's the main character's name?                                  \n",
      "qAnswer extended by Convex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_qanswer Q18057751\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q647875\n",
      "df_convex_rr 0.6666666666666666\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q720235\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 535 - 5 -> graphqa Q720235\n",
      "\n",
      "PARTIAL_CORRECT 535 - 5 -> graphqa in answers ['Q720235', 'Q647875', '1']\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "323             534    4        True  What's the main character's name?   \n",
      "\n",
      "      answer domain    qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "323  Q720235  books  Q18057751          0.46         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr   convex  convex_time  convex_rr  graphqa  \\\n",
      "323           0.64          0.0  Q647875         0.37   0.666667  Q720235   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "323          0.72         True         True         True         True   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "323           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-324-ic534-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:16:22.903962\n",
      "\t>>> Processing 536/2240 -> 1/5 -> Convex=False: (Q2321734) What type of show is it?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q11016\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q482994\n",
      "df_convex_rr 0.0\n",
      "\n",
      "Asking GraphQA\n",
      "User input: What type of show is it?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What type of show is it \n",
      "-> q_themes: ([(show, ['Q15116915']), (it, ['Q6091500']), (It, ['Q1366386', 'Q1131225']), (Type, ['Q7860628', 'Q2463013']), (Show, ['Q2934264', 'Q16316220']), (type, ['Q1325930', 'Q21146257'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: type\n",
      "behold: get_most_similar started with: show\n",
      "-> q_predicates: [(be, ['P31']), (type, ['P427']), (show, [])]\n",
      "-> q_predicates \tRunning time is 4.61s\n",
      "--> Potential meaningful keywords for the sentence: ['show', 'it', 'It', 'Type', 'Show', 'type']\n",
      "q_focused_parts: [(type, ['Q1325930', 'Q21146257'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.14s\n",
      "-->  204 nodes and 200 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 204 nodes and 200 edges\n",
      "-> predicates_dict: {'P1013': 1, 'P279': 8, 'P1810': 1, 'P4900': 1, 'P360': 1, 'P1441': 2, 'P144': 1, 'P1877': 1, 'P123': 1, 'P1433': 1, 'P407': 1, 'P973': 1, 'P364': 2, 'P31': 55, 'P1113': 1, 'P166': 1, 'P4810': 4, 'P17': 2, 'P577': 2, 'P462': 3, 'P453': 1, 'P161': 2, 'P1552': 1, 'P921': 1, 'P495': 3, 'P136': 1, 'P910': 1}\n",
      "-> paths_keywords: (['type', 'show', 'it'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 230\n",
      "->Computing possible paths \tRunning time is 36.91s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 200\n",
      "->\tRunning time is 3.62s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q188', 4.802325131351434], ['Q8097', 4.647884973173791], ['Q7823918', 2.451206500791307], ['Q7893862', 2.329943589770029], ['Q27231694', 2.325712661178996], ['Q27934226', 2.232197285228967], ['Q24256689', 2.1544035233741243], ['Q16962068', 2.0773256382761165], ['Q20857849', 1.83843085990713], ['Q3255049', 1.8146543238060895], ['Q11424', 1.3603437193346042], ['Q48836201', 1.3071645876098912], ['Q1860', 0.9995433910753452]]\n",
      "->Computing hypothesises \tRunning time is 42.86s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 1\n",
      "->\tRunning time is 10.05s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['Q188', 'P364', 'Q1366386', 'P31', 'Q11424', 'P31', 'Q16316220', 'P462', 'Q22006653']\n",
      "->\tTotal Running time is 120.83s\n",
      "\n",
      "df_graphqa Q188\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                  question    answer  \\\n",
      "324             535    0       False  What type of show is it?  Q2321734   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "324  tv_series  Q11016          0.66         0.0    False           0.19   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "324          0.0  Q482994         1.24        0.0    Q188         121.1   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "324        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "324         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-325-ic535-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:18:26.117343\n",
      "\t>>> Processing 536/2240 -> 2/5 -> Convex=False: (John Nolan) What is the name of Nathan Fillion character?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What is the name of Nathan Fillion character?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of Nathan Fillion character \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of Nathan Fillion character\n",
      "-> q_themes: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan Fillion character, is the name of Nathan, Nathan Fillion Character, nathan fillion character])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 8.6s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan, is, nathan])\n",
      "--> Potential meaningful keywords for the sentence: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name', 'Technology']\n",
      "meaningful_names_no_previous_answer [Nathan Fillion, the name, character, Character, The Name, name, Technology]\n",
      "----> Meaningful keywords casted as theme ([(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (the name, ['Q50929476', 'Q25217641'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 46.5s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What is the name of Nathan Fillion character?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of Nathan Fillion character \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the name of Nathan Fillion character\n",
      "-> q_themes: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan Fillion character, is the name of Nathan, Nathan Fillion Character, nathan fillion character])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 8.36s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan, is, nathan])\n",
      "--> Potential meaningful keywords for the sentence: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name', 'Technology']\n",
      "meaningful_names_no_previous_answer [Nathan Fillion, the name, character, Character, The Name, name, Technology]\n",
      "----> Meaningful keywords casted as theme ([(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (the name, ['Q50929476', 'Q25217641'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 33.02s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What is the name of Nathan Fillion character?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of Nathan Fillion character \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of Nathan Fillion character\n",
      "-> q_themes: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan Fillion character, is the name of Nathan, Nathan Fillion Character, nathan fillion character])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 8.87s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan, is, nathan])\n",
      "--> Potential meaningful keywords for the sentence: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [Nathan Fillion, the name, character, Character, The Name, name, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (the name, ['Q50929476', 'Q25217641'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.46s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 23368, 'P155': 4, 'P156': 4, 'P735': 1, 'P279': 5, 'P1535': 1, 'P180': 2, 'P800': 1, 'P734': 1, 'P856': 1, 'P407': 2, 'P19': 1, 'P1476': 2, 'P3744': 1, 'P2002': 1, 'P360': 1, 'P569': 1, 'P577': 6, 'P175': 3, 'P725': 3, 'P106': 5, 'P264': 2, 'P69': 1, 'P527': 2, 'P27': 1, 'P1433': 1, 'P136': 2, 'P21': 1, 'P50': 1}\n",
      "-> paths_keywords: (['nathan fillion', 'character', 'the name', 'name', 'is it in', 'album'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 148.81s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.63s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.07s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What is the name of Nathan Fillion character?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of Nathan Fillion character \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What instance of the name of Nathan Fillion character\n",
      "-> q_themes: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan Fillion character, is the name of Nathan, Nathan Fillion Character, nathan fillion character])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 8.34s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "----> q_themes in context: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan, is, nathan])\n",
      "--> Potential meaningful keywords for the sentence: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [Nathan Fillion, the name, character, Character, The Name, name, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (the name, ['Q50929476', 'Q25217641'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 31.99s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 23368, 'P155': 4, 'P156': 4, 'P279': 5, 'P1535': 1, 'P180': 2, 'P735': 1, 'P800': 1, 'P734': 1, 'P856': 1, 'P407': 2, 'P19': 1, 'P1476': 2, 'P3744': 1, 'P2002': 1, 'P360': 1, 'P569': 1, 'P577': 6, 'P175': 3, 'P725': 3, 'P106': 5, 'P264': 2, 'P69': 1, 'P527': 2, 'P27': 1, 'P1433': 1, 'P136': 2, 'P21': 1, 'P50': 1}\n",
      "-> paths_keywords: (['nathan fillion', 'character', 'the name', 'name', 'is it in', 'album', 'instance'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> len(path_nodes): 72\n",
      "->Computing possible paths \tRunning time is 136.06s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 14\n",
      "->\tRunning time is 3.82s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 3.03s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 187.78s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What is the name of Nathan Fillion character?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of Nathan Fillion character \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of Nathan Fillion character\n",
      "-> q_themes: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan Fillion character, is the name of Nathan, Nathan Fillion Character, nathan fillion character])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674'])]\n",
      "-> q_predicates \tRunning time is 8.78s\n",
      "--> Predicates enhanced by previous context: [(original language of work, ['P364']), (be, ['P31']), (name, ['P735', 'P1448']), (character, ['P674']), (color, ['P462'])]\n",
      "----> q_themes in context: ([(Nathan Fillion, ['Q342549']), (the name, ['Q50929476', 'Q25217641']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q12592731']), (name, ['Q82799', 'P2561'])], [Nathan, is, nathan])\n",
      "--> Potential meaningful keywords for the sentence: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['Nathan Fillion', 'the name', 'character', 'Character', 'The Name', 'name', 'It', 'It', 'German', 'Show', 'film', 'color']\n",
      "meaningful_names_no_previous_answer [Nathan Fillion, the name, character, Character, The Name, name, It, It, German, Show, film, color]\n",
      "----> Meaningful keywords casted as theme ([(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (film, ['Q11424']), (color, ['P462', 'Q22006653', 'Q1075'])], [])\n",
      "q_focused_parts: [(Nathan Fillion, ['Q342549']), (character, ['Q3241972', 'Q1792372']), (Character, ['Q1062911', 'Q1880113']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (name, ['P2561']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (film, ['Q11424']), (color, ['P462', 'Q22006653', 'Q1075']), (the name, ['Q50929476', 'Q25217641'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 55.76s\n",
      "-->  79 nodes and 80 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 79 nodes and 80 edges\n",
      "-> predicates_dict: {'P364': 4, 'P31': 961, 'P462': 13, 'P155': 4, 'P156': 3, 'P279': 7, 'P1535': 1, 'P180': 2, 'P735': 1, 'P407': 2, 'P453': 1, 'P161': 4, 'P800': 1, 'P734': 1, 'P856': 1, 'P101': 1, 'P1441': 2, 'P361': 3, 'P1480': 1, 'P1810': 1, 'P4900': 1, 'P131': 1, 'P1705': 2, 'P136': 6, 'P360': 1, 'P1476': 5, 'P144': 1, 'P642': 2, 'P577': 6, 'P421': 4, 'P19': 1, 'P1877': 1, 'P527': 3, 'P166': 2, 'P27': 1, 'P725': 3, 'P106': 5, 'P569': 1, 'P138': 3, 'P264': 2, 'P3744': 1, 'P2002': 1, 'P495': 3, 'P17': 3, 'P175': 3, 'P1113': 1, 'P1433': 1, 'P840': 1, 'P69': 1, 'P1552': 1, 'P449': 1, 'P5008': 1, 'P21': 2, 'P50': 2, 'P910': 2, 'P366': 1, 'P625': 1}\n",
      "-> paths_keywords: (['nathan fillion', 'character', 'the name', 'name', 'it', 'german', 'show', 'film', 'color'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 1136\n",
      "->Computing possible paths \tRunning time is 67.55s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 986\n",
      "->\tRunning time is 4.04s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q8097', 12.770786243116255], ['Q838368', 5.711461197717881], ['Q30', 4.1046063897186595], ['Q183', 4.025797467464849], ['Q1860', 3.459274292971697], ['Q668', 2.127660653869783], ['Q506240', 1.4529529668166963], ['Q48836201', 1.2213423644713142], ['Q5398426', 0.8915706086584705], ['Q1259759', 0.7581296553881463]]\n",
      "->Computing hypothesises \tRunning time is 133.4s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 9.49s\n",
      "--> len(cleared_golden_paths): 3\n",
      "---> First path: ['Q8097', 'P364', 'Q16316220', 'P462', 'Q22006653']\n",
      "->\tTotal Running time is 282.31s\n",
      "\n",
      "df_graphqa Q8097\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "325             535    1       False   \n",
      "\n",
      "                                          question      answer     domain  \\\n",
      "325  What is the name of Nathan Fillion character?  John Nolan  tv_series   \n",
      "\n",
      "    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "325   False         96.99         0.0    False           0.84          0.0   \n",
      "\n",
      "    convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "325  False       381.36        0.0   Q8097        282.58        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "325        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-326-ic535-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 536/2240 -> 2/5 -> Convex=True: (John Nolan) What is the name of Nathan Fillion character?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q3117350\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q1264273\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa షో@te\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex  \\\n",
      "326             535    1        True   \n",
      "\n",
      "                                          question      answer     domain  \\\n",
      "326  What is the name of Nathan Fillion character?  John Nolan  tv_series   \n",
      "\n",
      "      qanswer  qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  \\\n",
      "326  Q3117350          1.54         0.0    False           2.72          0.0   \n",
      "\n",
      "       convex  convex_time  convex_rr graphqa  graphqa_time graphqa_top2  \\\n",
      "326  Q1264273         0.03        0.0   షో@te           0.4        False   \n",
      "\n",
      "    graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "326        False        False        False          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-327-ic535-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:31:12.624217\n",
      "\t>>> Processing 536/2240 -> 3/5 -> Convex=False: (Q169889) What network is it on?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What network is it on?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What network is it on \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What network is Technology on\n",
      "-> q_themes: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: network\n",
      "-> q_predicates: [(be, ['P31']), (network, [])]\n",
      "-> q_predicates \tRunning time is 3.5s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (network, [])]\n",
      "----> q_themes in context: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['network', 'Network']\n",
      "---> Meaningful keywords enhanced by previous context: ['network', 'Network', 'Technology']\n",
      "meaningful_names_no_previous_answer [network, Network, Technology]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Meaningful keywords casted as theme ([(Network, ['Q17115560', 'Q17071307']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Network, ['Q17115560', 'Q17071307']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (network, ['Q7000691', 'Q572165'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.29s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What network is it on?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What network is it on \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What network Technology on\n",
      "-> q_themes: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: network\n",
      "-> q_predicates: [(be, ['P31']), (network, [])]\n",
      "-> q_predicates \tRunning time is 3.17s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (network, [])]\n",
      "----> q_themes in context: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['network', 'Network']\n",
      "---> Meaningful keywords enhanced by previous context: ['network', 'Network', 'Technology']\n",
      "meaningful_names_no_previous_answer [network, Network, Technology]\n",
      "----> Meaningful keywords casted as theme ([(Network, ['Q17115560', 'Q17071307']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Network, ['Q17115560', 'Q17071307']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (network, ['Q7000691', 'Q572165'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.42s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What network is it on?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What network is it on \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What network is Is It In on\n",
      "-> q_themes: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: network\n",
      "-> q_predicates: [(be, ['P31']), (network, [])]\n",
      "-> q_predicates \tRunning time is 3.6s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (network, [])]\n",
      "----> q_themes in context: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['network', 'Network']\n",
      "---> Meaningful keywords enhanced by previous context: ['network', 'Network', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [network, Network, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Network, ['Q17115560', 'Q17071307']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Network, ['Q17115560', 'Q17071307']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (network, ['Q7000691', 'Q572165'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.45s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P31': 22688, 'P102': 2, 'P571': 1, 'P495': 1, 'P585': 1, 'P2124': 1, 'P155': 2, 'P156': 2, 'P577': 3, 'P175': 2, 'P159': 1, 'P2437': 1}\n",
      "-> paths_keywords: (['network', 'is it in', 'album', 'in'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 127.77s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.04s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What network is it on?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What network is it on \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What network Is It In on\n",
      "-> q_themes: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: network\n",
      "-> q_predicates: [(be, ['P31']), (network, [])]\n",
      "-> q_predicates \tRunning time is 3.59s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (network, [])]\n",
      "----> q_themes in context: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['network', 'Network']\n",
      "---> Meaningful keywords enhanced by previous context: ['network', 'Network', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [network, Network, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Network, ['Q17115560', 'Q17071307']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Network, ['Q17115560', 'Q17071307']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (network, ['Q7000691', 'Q572165'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 12.79s\n",
      "-->  5 nodes and 4 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 5 nodes and 4 edges\n",
      "-> predicates_dict: {'P31': 22688, 'P102': 2, 'P571': 1, 'P495': 1, 'P585': 1, 'P2124': 1, 'P155': 2, 'P156': 2, 'P577': 3, 'P175': 2, 'P159': 1, 'P2437': 1}\n",
      "-> paths_keywords: (['network', 'is it in', 'album', 'is'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 128.24s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.79s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 152.06s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What network is it on?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What network is it on \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What network is Telugu language on\n",
      "-> q_themes: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: network\n",
      "-> q_predicates: [(be, ['P31']), (network, [])]\n",
      "-> q_predicates \tRunning time is 3.65s\n",
      "--> Predicates enhanced by previous context: [(color, ['P462']), (be, ['P31']), (network, []), (original language of work, ['P364'])]\n",
      "----> q_themes in context: ([(network, ['Q7000691', 'Q572165']), (Network, ['Q17115560', 'Q17071307'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['network', 'Network']\n",
      "---> Meaningful keywords enhanced by previous context: ['network', 'Network', 'Show', 'color', 'Telugu language', 'It', 'It', 'German', 'film']\n",
      "meaningful_names_no_previous_answer [network, Network, Show, color, Telugu language, It, It, German, film]\n",
      "----> Meaningful keywords casted as theme ([(Network, ['Q17115560', 'Q17071307']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (color, ['P462', 'Q22006653', 'Q1075']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(Network, ['Q17115560', 'Q17071307']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (color, ['P462', 'Q22006653', 'Q1075']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424']), (network, ['Q7000691', 'Q572165'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 34.46s\n",
      "-->  56 nodes and 56 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 56 nodes and 56 edges\n",
      "-> predicates_dict: {'P462': 13, 'P364': 7, 'P31': 281, 'P102': 2, 'P571': 1, 'P101': 1, 'P1441': 2, 'P361': 1, 'P1480': 1, 'P1810': 1, 'P4900': 1, 'P131': 1, 'P1705': 2, 'P136': 2, 'P495': 2, 'P144': 1, 'P585': 1, 'P2124': 1, 'P642': 2, 'P279': 3, 'P577': 3, 'P421': 4, 'P166': 2, 'P1877': 1, 'P582': 1, 'P580': 1, 'P155': 2, 'P17': 3, 'P175': 2, 'P453': 1, 'P449': 1, 'P161': 2, 'P156': 1, 'P5008': 1, 'P1552': 1, 'P625': 1, 'P1204': 1, 'P2437': 1, 'P264': 1, 'P159': 1}\n",
      "-> paths_keywords: (['network', 'show', 'color', 'telugu language', 'it', 'german', 'film', 'language'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 108\n",
      "->Computing possible paths \tRunning time is 14.55s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 62\n",
      "->\tRunning time is 3.57s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q1860', 4.68404665253512], ['Q48836201', 1.3309171229686194]]\n",
      "->Computing hypothesises \tRunning time is 28.75s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 8\n",
      "->\tRunning time is 4.18s\n",
      "--> len(cleared_golden_paths): 4\n",
      "---> First path: ['Q1860', 'P364', 'Q1131225', 'P462', 'Q22006653']\n",
      "->\tTotal Running time is 92.92s\n",
      "\n",
      "df_graphqa Q1860\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                question   answer  \\\n",
      "327             535    2       False  What network is it on?  Q169889   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "327  tv_series   False         31.83         0.0    False           0.23   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "327          0.0  False       300.08        0.0   Q1860         93.19   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "327        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "327         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-328-ic535-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 536/2240 -> 3/5 -> Convex=True: (Q169889) What network is it on?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q904595\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q17014588\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 2002-01-01T00:00:00Z\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                question   answer  \\\n",
      "328             535    2        True  What network is it on?  Q169889   \n",
      "\n",
      "        domain  qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "328  tv_series  Q904595          0.45         0.0    False           0.23   \n",
      "\n",
      "     platypus_rr     convex  convex_time  convex_rr               graphqa  \\\n",
      "328          0.0  Q17014588          0.2        0.0  2002-01-01T00:00:00Z   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "328          0.13        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "328          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-329-ic535-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:38:19.016839\n",
      "\t>>> Processing 536/2240 -> 4/5 -> Convex=False: (Q4492730) What is the name of the director?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What is the name of the director?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the director \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of the director\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 5.53s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name', 'Technology']\n",
      "meaningful_names_no_previous_answer [the name, the director, director, Director, The Name, The Director, name, Technology]\n",
      "----> Meaningful keywords casted as theme ([(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 52.45s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What is the name of the director?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the director \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the name of the director\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 5.25s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name', 'Technology']\n",
      "meaningful_names_no_previous_answer [the name, the director, director, Director, The Name, The Director, name, Technology]\n",
      "----> Meaningful keywords casted as theme ([(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795']), (the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 50.1s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What is the name of the director?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the director \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of the director\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 5.41s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [the name, the director, director, Director, The Name, The Director, name, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 49.07s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P31': 22702, 'P800': 1, 'P155': 4, 'P156': 4, 'P642': 1, 'P175': 6, 'P407': 2, 'P571': 1, 'P1476': 2, 'P1441': 2, 'P569': 1, 'P577': 5, 'P279': 4, 'P2521': 3, 'P2388': 3, 'P264': 1, 'P27': 1, 'P1433': 1, 'P50': 2, 'P195': 1, 'P1545': 2, 'P217': 1, 'P179': 1, 'P170': 1, 'P106': 1, 'P973': 1, 'P4908': 1, 'P21': 2}\n",
      "-> paths_keywords: (['director', 'the name', 'the director', 'name', 'is it in', 'album'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 146.24s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.55s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What is the name of the director?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the director \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the name of the director\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 5.34s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name']\n",
      "---> Meaningful keywords enhanced by previous context: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [the name, the director, director, Director, The Name, The Director, name, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408']), (the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 49.65s\n",
      "-->  7 nodes and 6 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 7 nodes and 6 edges\n",
      "-> predicates_dict: {'P31': 22702, 'P800': 1, 'P155': 4, 'P156': 4, 'P642': 1, 'P175': 6, 'P407': 2, 'P571': 1, 'P1476': 2, 'P1441': 2, 'P569': 1, 'P577': 5, 'P279': 4, 'P2521': 3, 'P2388': 3, 'P264': 1, 'P27': 1, 'P1433': 1, 'P50': 2, 'P195': 1, 'P217': 1, 'P1545': 2, 'P179': 1, 'P170': 1, 'P106': 1, 'P973': 1, 'P4908': 1, 'P21': 2}\n",
      "-> paths_keywords: (['director', 'the name', 'the director', 'name', 'is it in', 'album'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 148.16s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.71s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 210.56s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What is the name of the director?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What is the name of the director \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What is the name of the director\n",
      "-> q_themes: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448'])]\n",
      "-> q_predicates \tRunning time is 5.3s\n",
      "--> Predicates enhanced by previous context: [(color, ['P462']), (be, ['P31']), (director, ['P57', 'P1037']), (name, ['P735', 'P1448']), (original language of work, ['P364'])]\n",
      "----> q_themes in context: ([(the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600']), (director, ['P57', 'Q1162163']), (Director, ['Q1047422', 'Q23760617']), (The Name, ['Q19094658', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246']), (name, ['Q82799', 'P2561'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['the name', 'the director', 'director', 'Director', 'The Name', 'The Director', 'name', 'Show', 'color', 'It', 'English', 'It', 'It', 'Telugu language', 'It', 'German', 'film']\n",
      "meaningful_names_no_previous_answer [the name, the director, director, Director, The Name, The Director, name, Show, color, It, English, It, It, Telugu language, It, German, film]\n",
      "----> Meaningful keywords casted as theme ([(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(director, ['P57', 'Q1162163']), (Director, ['Q23760617', 'Q1047422']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (The Director, ['Q42531725', 'Q26883246', 'Q50078600']), (name, ['P2561']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424']), (the name, ['Q50929476', 'Q25217641']), (the director, ['Q50078600'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 76.93s\n",
      "-->  89 nodes and 90 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 89 nodes and 90 edges\n",
      "-> predicates_dict: {'P462': 13, 'P364': 10, 'P1441': 5, 'P144': 2, 'P31': 297, 'P57': 3, 'P407': 2, 'P800': 1, 'P155': 4, 'P156': 3, 'P571': 1, 'P101': 1, 'P175': 4, 'P361': 1, 'P344': 2, 'P1480': 1, 'P1810': 1, 'P4900': 1, 'P131': 2, 'P1705': 2, 'P136': 3, 'P1476': 5, 'P642': 3, 'P279': 6, 'P577': 5, 'P421': 4, 'P1877': 1, 'P166': 2, 'P27': 1, 'P1040': 1, 'P569': 1, 'P138': 3, 'P495': 3, 'P973': 1, 'P17': 4, 'P2521': 3, 'P453': 1, 'P161': 2, 'P2388': 3, 'P1545': 2, 'P4908': 1, 'P1433': 1, 'P264': 1, 'P1552': 1, 'P449': 1, 'P195': 1, 'P217': 1, 'P50': 3, 'P3321': 2, 'P179': 1, 'P170': 1, 'P5008': 1, 'P106': 1, 'P123': 1, 'P910': 2, 'P625': 2, 'P21': 3, 'P373': 1}\n",
      "-> paths_keywords: (['director', 'the name', 'the director', 'name', 'show', 'color', 'it', 'english', 'telugu language', 'german', 'film'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 272\n",
      "->Computing possible paths \tRunning time is 18.16s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 238\n",
      "->\tRunning time is 3.88s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q574983', 28.712426209015725], ['Q107683', 28.324985166171402], ['Q5512372', 7.832279075950056], ['Q17144179', 1.2950671221117942], ['Q1510189', 0.007938215075594501]]\n",
      "->Computing hypothesises \tRunning time is 101.47s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 4\n",
      "->\tRunning time is 4.56s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q574983', 'P57', 'Q1131225', 'P364', 'Q1860', 'P407', 'Q19094658']\n",
      "->\tTotal Running time is 214.13s\n",
      "\n",
      "df_graphqa Q574983\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "329             535    3       False  What is the name of the director?   \n",
      "\n",
      "       answer     domain qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "329  Q4492730  tv_series   False        113.81         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr convex  convex_time  convex_rr  graphqa  \\\n",
      "329           0.98          0.0  False       415.59        0.0  Q574983   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "329         214.4        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "329          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-330-ic535-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 536/2240 -> 4/5 -> Convex=True: (Q4492730) What is the name of the director?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer OFTC@en\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q430699\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q5512372\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "330             535    3        True  What is the name of the director?   \n",
      "\n",
      "       answer     domain  qanswer  qanswer_time  qanswer_rr platypus  \\\n",
      "330  Q4492730  tv_series  OFTC@en          0.61         0.0    False   \n",
      "\n",
      "     platypus_time  platypus_rr   convex  convex_time  convex_rr   graphqa  \\\n",
      "330           0.83          0.0  Q430699          0.1        0.0  Q5512372   \n",
      "\n",
      "     graphqa_time graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5  \\\n",
      "330          0.19        False        False        False        False   \n",
      "\n",
      "    graphqa_topall  graphqa_rr  \n",
      "330          False         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-331-ic535-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 05:50:45.577563\n",
      "\t>>> Processing 536/2240 -> 5/5 -> Convex=False: (Q2067839) What actress plays Lucy Chen?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n",
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741'])]\n",
      "-> q_predicates \tRunning time is 5.47s\n",
      "--> Predicates enhanced by previous context: [(plays, ['P741'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'Technology']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, Technology]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 19.86s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: actress\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741']), (actress, ['P175', 'P161'])]\n",
      "-> q_predicates \tRunning time is 5.57s\n",
      "--> Predicates enhanced by previous context: [(plays, ['P741']), (actress, ['P175', 'P161'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'Technology']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, Technology]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Technology, ['Q27725455', 'Q4456888', 'Q48797795'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.99s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n",
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741'])]\n",
      "-> q_predicates \tRunning time is 5.61s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (plays, ['P741'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 21.24s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 22700, 'P361': 2, 'P373': 1, 'P136': 1, 'P407': 1, 'P495': 1, 'P131': 1, 'P1013': 1, 'P155': 2, 'P156': 2, 'P577': 4, 'P175': 6, 'P123': 1, 'P910': 2, 'P364': 1, 'P527': 3, 'P421': 1, 'P279': 1, 'P86': 1, 'P462': 1, 'P138': 1, 'P17': 1, 'P442': 1}\n",
      "-> paths_keywords: (['chen', 'actress', 'is it in', 'album'], {'instance of': [instance of, ['P31']], 'playing hand': [playing hand, ['P741']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 134.19s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.84s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.06s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n",
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: actress\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741']), (actress, ['P175', 'P161'])]\n",
      "-> q_predicates \tRunning time is 5.37s\n",
      "--> Predicates enhanced by previous context: [(instance of, ['P31']), (plays, ['P741']), (actress, ['P175', 'P161'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'Is It In', 'Album']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, Is It In, Album]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (Is It In, ['Q17014588']), (Album, ['Q11957254', 'Q11850638', 'Q10404408'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 20.29s\n",
      "-->  9 nodes and 8 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 9 nodes and 8 edges\n",
      "-> predicates_dict: {'P31': 22700, 'P1013': 1, 'P175': 6, 'P161': 1, 'P361': 2, 'P373': 1, 'P136': 1, 'P407': 1, 'P495': 1, 'P131': 1, 'P155': 2, 'P156': 2, 'P577': 4, 'P123': 1, 'P910': 2, 'P86': 1, 'P527': 3, 'P364': 1, 'P58': 1, 'P421': 1, 'P279': 1, 'P57': 1, 'P138': 1, 'P462': 1, 'P264': 1, 'P50': 1, 'P1448': 1, 'P17': 1, 'P442': 1, 'P180': 3, 'P150': 1}\n",
      "-> paths_keywords: (['chen', 'actress', 'is it in', 'album'], {'instance of': [instance of, ['P31']], 'playing hand': [playing hand, ['P741']], 'performer': [performer, ['P175']], 'cast member': [cast member, ['P161']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 139.52s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.56s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.1s\n",
      "--> End of loop\n",
      "->\tTotal Running time is 172.47s\n",
      "\n",
      "df_convex False\n",
      "df_convex_rr 0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n",
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741'])]\n",
      "-> q_predicates \tRunning time is 5.66s\n",
      "--> Predicates enhanced by previous context: [(color, ['P462']), (plays, ['P741']), (director, ['P57']), (original language of work, ['P364']), (language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'color', 'It', 'English', 'It', 'It', 'The Name', 'Tommy Lee Wallace', 'Show', 'Telugu language', 'It', 'German', 'film']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, color, It, English, It, It, The Name, Tommy Lee Wallace, Show, Telugu language, It, German, film]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Tommy Lee Wallace, ['Q574983']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Tommy Lee Wallace, ['Q574983']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 47.13s\n",
      "-->  14 nodes and 14 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 14 nodes and 14 edges\n",
      "-> predicates_dict: {'P462': 14, 'P364': 11, 'P1441': 2, 'P144': 2, 'P57': 22, 'P407': 4, 'P31': 28, 'P106': 4, 'P800': 1, 'P1013': 1, 'P735': 1, 'P373': 2, 'P136': 4, 'P101': 1, 'P361': 3, 'P131': 3, 'P344': 2, 'P291': 1, 'P1480': 1, 'P1810': 1, 'P1705': 2, 'P4900': 1, 'P1476': 1, 'P642': 2, 'P279': 3, 'P27': 2, 'P577': 4, 'P421': 5, 'P19': 1, 'P123': 2, 'P166': 2, 'P1040': 2, 'P910': 3, 'P17': 5, 'P175': 4, 'P1877': 1, 'P453': 1, 'P161': 5, 'P1433': 1, 'P58': 1, 'P155': 2, 'P156': 1, 'P527': 4, 'P50': 4, 'P138': 4, 'P1552': 1, 'P21': 2, 'P86': 3, 'P1448': 1, 'P2437': 1, 'P625': 2, 'P264': 1, 'P442': 1, 'P304': 1, 'P478': 1, 'P1343': 1}\n",
      "-> paths_keywords: (['chen', 'actress', 'color', 'it', 'english', 'the name', 'tommy lee wallace', 'show', 'telugu language', 'german', 'film'], {'color': [color, ['P462']], 'playing hand': [playing hand, ['P741']], 'director': [director, ['P57']], 'original language of work': [original language of work, ['P364']], 'language of work or name': [language of work or name, ['P407']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 0\n",
      "->Computing possible paths \tRunning time is 220.84s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 0\n",
      "->\tRunning time is 3.53s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: []\n",
      "->Computing hypothesises \tRunning time is 0.13s\n",
      "-> Looping on aggressive mode...\n",
      "\n",
      "Looped in aggressive mode with: What actress plays Lucy Chen?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What actress plays Lucy Chen \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What director actress plays Lucy Chen\n",
      "-> q_themes: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress plays Lucy])\n",
      "-> q_themes_enhanced: [('Lucy', ['Q10320388']), ('play', ['Q1150958']), ('Plays', ['Q29346837']), ('Play', ['Q16253032'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: actress\n",
      "behold: get_most_similar started with: play\n",
      "-> q_predicates: [(plays, ['P741']), (actress, ['P175', 'P161'])]\n",
      "-> q_predicates \tRunning time is 5.82s\n",
      "--> Predicates enhanced by previous context: [(color, ['P462']), (plays, ['P741']), (actress, ['P175', 'P161']), (director, ['P57']), (original language of work, ['P364']), (language of work or name, ['P407'])]\n",
      "----> q_themes in context: ([(Chen, ['Q804988', 'Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q15260681', 'Q11188894'])], [actress])\n",
      "--> Potential meaningful keywords for the sentence: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play']\n",
      "---> Meaningful keywords enhanced by previous context: ['Chen', 'actress', 'Actress', 'Lucy', 'play', 'Plays', 'Play', 'color', 'It', 'English', 'It', 'It', 'The Name', 'Tommy Lee Wallace', 'Show', 'Telugu language', 'It', 'German', 'film']\n",
      "meaningful_names_no_previous_answer [Chen, actress, Actress, Lucy, play, Plays, Play, color, It, English, It, It, The Name, Tommy Lee Wallace, Show, Telugu language, It, German, film]\n",
      "----> Meaningful keywords casted as theme ([(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Tommy Lee Wallace, ['Q574983']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])], [])\n",
      "q_focused_parts: [(Chen, ['Q13920537']), (actress, ['Q21169216', 'Q10942718']), (Actress, ['Q11188894', 'Q15260681']), (color, ['P462', 'Q22006653', 'Q1075']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (English, ['Q1219933', 'Q12261586', 'Q11616958']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (The Name, ['Q19094658', 'Q25217641', 'Q12592731']), (Tommy Lee Wallace, ['Q574983']), (Show, ['Q1931144', 'Q16316220', 'Q12000244']), (Telugu language, ['Q8097']), (It, ['Q1366386', 'Q16386412', 'Q1131225']), (German, ['Q188', 'Q13039329', 'Q12750187']), (film, ['Q11424'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.34s\n",
      "-->  15 nodes and 16 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 15 nodes and 16 edges\n",
      "-> predicates_dict: {'P462': 14, 'P364': 11, 'P1441': 2, 'P144': 2, 'P57': 22, 'P407': 4, 'P31': 28, 'P1013': 1, 'P175': 4, 'P161': 38, 'P453': 1, 'P106': 4, 'P800': 1, 'P735': 1, 'P373': 2, 'P136': 4, 'P101': 1, 'P361': 3, 'P131': 3, 'P344': 2, 'P291': 1, 'P1480': 1, 'P1810': 1, 'P1705': 2, 'P1476': 1, 'P642': 2, 'P279': 4, 'P4900': 1, 'P27': 2, 'P577': 4, 'P19': 1, 'P421': 5, 'P123': 2, 'P166': 2, 'P1040': 2, 'P910': 4, 'P17': 7, 'P1877': 1, 'P1433': 1, 'P58': 7, 'P86': 3, 'P527': 4, 'P155': 2, 'P156': 1, 'P162': 1, 'P50': 4, 'P138': 4, 'P1552': 1, 'P21': 2, 'P1448': 1, 'P2437': 1, 'P625': 2, 'P569': 1, 'P264': 1, 'P442': 1, 'P180': 3, 'P304': 1, 'P478': 1, 'P1343': 1, 'P5008': 1, 'P150': 1}\n",
      "-> paths_keywords: (['chen', 'actress', 'color', 'it', 'english', 'the name', 'tommy lee wallace', 'show', 'telugu language', 'german', 'film'], {'color': [color, ['P462']], 'playing hand': [playing hand, ['P741']], 'performer': [performer, ['P175']], 'cast member': [cast member, ['P161']], 'director': [director, ['P57']], 'original language of work': [original language of work, ['P364']], 'language of work or name': [language of work or name, ['P407']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 146\n",
      "->Computing possible paths \tRunning time is 91.19s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 78\n",
      "->\tRunning time is 3.82s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q16253032', 3.644778827268579]]\n",
      "->Computing hypothesises \tRunning time is 54.56s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 0\n",
      "->\tRunning time is 4.0s\n",
      "--> len(cleared_golden_paths): 0\n",
      "->\tTotal Running time is 217.15s\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_graphqa Q16253032\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                       question    answer  \\\n",
      "331             535    4       False  What actress plays Lucy Chen?  Q2067839   \n",
      "\n",
      "        domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "331  tv_series   False         52.36         0.0    False           0.37   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "331          0.0  False       338.09        0.0  Q16253032        495.81   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "331        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "331         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-332-ic535-iq4-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 536/2240 -> 5/5 -> Convex=True: (Q2067839) What actress plays Lucy Chen?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q29791216\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q3266007\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q10800557\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                       question    answer  \\\n",
      "332             535    4        True  What actress plays Lucy Chen?  Q2067839   \n",
      "\n",
      "        domain    qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "332  tv_series  Q29791216          0.81         0.0    False           0.36   \n",
      "\n",
      "     platypus_rr    convex  convex_time  convex_rr    graphqa  graphqa_time  \\\n",
      "332          0.0  Q3266007        96.27        0.0  Q10800557          0.65   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "332        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "332         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-333-ic535-iq4-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 06:07:10.350316\n",
      "\t>>> Processing 537/2240 -> 1/5 -> Convex=False: (Q34660) Who is the author of the Harry Potter series?                                  \n",
      "Asking qAnswer\n",
      "df_qanswer Q34660\n",
      "df_qanswer_rr 1.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Asking Convex\n",
      "df_convex Q34660\n",
      "df_convex_rr 1.0\n",
      "\n",
      "CORRECT 537 - 1 -> qAnswer Q34660\n",
      "\n",
      "CORRECT 537 - 1 -> Convex Q34660\n",
      "\n",
      "Asking GraphQA\n",
      "User input: Who is the author of the Harry Potter series?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Who is the author of the Harry Potter series \n",
      "-> q_themes: ([(Harry Potter, ['Q8337', 'Q3244512']), (the author, ['Q21451533', 'Q51159453']), (series, ['Q3025161', 'Q170198']), (author, ['Q482980', 'P50'])], [the Harry Potter series, is the author of the Harry, The Harry Potter Series, the harry potter series, the Harry Potter Series])\n",
      "-> q_themes_enhanced: [('Harry Potter series', ['Q8337']), ('potter', ['Q3400050']), ('The Potter', ['Q5982619']), ('Author', ['P50'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(be, ['P31']), (author, ['P50']), (series, ['P179', 'P1545'])]\n",
      "-> q_predicates \tRunning time is 10.43s\n",
      "--> Potential meaningful keywords for the sentence: ['Harry Potter', 'the author', 'series', 'author', 'Harry Potter series', 'potter', 'The Potter', 'Author']\n",
      "q_focused_parts: [(series, ['Q170198', 'P179']), (Harry Potter, ['Q216930', 'Q1809924', 'Q17146193'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 64.06s\n",
      "-->  219 nodes and 224 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 179 nodes and 182 edges\n",
      "-> predicates_dict: {'P179': 11, 'P1545': 4, 'P105': 3, 'P50': 1, 'P138': 2, 'P735': 2, 'P4908': 1, 'P39': 2, 'P155': 2, 'P156': 2, 'P1113': 1, 'P31': 23, 'P805': 2, 'P1343': 2, 'P1441': 6, 'P585': 1, 'P2868': 4, 'P582': 2, 'P20': 1, 'P570': 1, 'P3744': 1, 'P407': 2, 'P3984': 1, 'P571': 1, 'P131': 1, 'P3831': 2, 'P674': 5, 'P1308': 2, 'P3989': 1, 'P463': 1, 'P425': 1, 'P123': 1, 'P580': 2, 'P136': 2, 'P170': 1, 'P108': 1, 'P1039': 2, 'P1038': 2, 'P1881': 2, 'P642': 1, 'P641': 1, 'P910': 1, 'P361': 2, 'P373': 1, 'P1282': 1, 'P106': 1}\n",
      "-> paths_keywords: (['series', 'harry potter', 'author', 'the harry potter series', 'the author', 'henry potter'], {'instance of': [instance of, ['P31']], 'author': [author, ['P50']], 'series': [series, ['P179']], 'series ordinal': [series ordinal, ['P1545']], 'Author': [author, ['P50']]}, [Who])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 685\n",
      "->Computing possible paths \tRunning time is 31.51s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 968\n",
      "->\tRunning time is 3.89s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q34660', 19.10633626318907], ['Q80817', 5.158398765478125], ['Q46887', 4.955008263875056], ['Q47598', 4.368413535354593], ['Q20711488', 3.3759706738770054], ['Q43361', 3.1163549883496384], ['Q46751', 3.0109522195552887], ['Q46758', 2.4574431102643963]]\n",
      "->Computing hypothesises \tRunning time is 44.63s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 64\n",
      "->\tRunning time is 49.21s\n",
      "--> len(cleared_golden_paths): 34\n",
      "---> First path: ['Q80817', 'P179', 'Q8337', 'P50', 'Q34660', 'P170', 'Q3244512', 'P31', 'Q15298259']\n",
      "->\tTotal Running time is 207.6s\n",
      "\n",
      "df_graphqa Q34660\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 537 - 1 -> graphqa Q34660\n",
      "\n",
      "PARTIAL_CORRECT 537 - 1 -> graphqa in answers ['Q34660', 'Q80817', 'Q46887', 'Q47598', 'Q20711488', 'Q43361', 'Q46751', 'Q46758']\n",
      "    conversation_id turn plus_convex  \\\n",
      "333             536    0       False   \n",
      "\n",
      "                                          question  answer domain qanswer  \\\n",
      "333  Who is the author of the Harry Potter series?  Q34660  books  Q34660   \n",
      "\n",
      "     qanswer_time  qanswer_rr platypus  platypus_time  platypus_rr  convex  \\\n",
      "333          0.79         1.0    False           0.54          0.0  Q34660   \n",
      "\n",
      "     convex_time  convex_rr graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "333         2.13        1.0  Q34660        207.86         True         True   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "333         True         True           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-334-ic536-iq0-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 06:10:41.713093\n",
      "\t>>> Processing 537/2240 -> 2/5 -> Convex=False: (1997-01-01T00:00:00Z) What was the year of publication for the first book?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What was the year of publication for the first book?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the date of publication for the first book \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the date of publication for the first book\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book date])\n",
      "-> q_themes_enhanced: [('Date', ['Q10467097'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (first, ['P577']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 9.06s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date', 'J. K. Rowling']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meaningful_names_no_previous_answer [first, publication, date, book, Book, Publication, first book, Date, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (J. K. Rowling, ['Q34660']), (book, ['Q571', 'Q421300']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 35.65s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What was the year of publication for the first book?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the date of publication for the first book \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What the date of publication for the first book\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book date])\n",
      "-> q_themes_enhanced: [('Date', ['Q10467097'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (first, ['P577']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 8.98s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [first, publication, date, book, Book, Publication, first book, Date, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (J. K. Rowling, ['Q34660']), (book, ['Q571', 'Q421300']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 35.42s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What was the year of publication for the first book?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What was the date of publication for the first book \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the date of publication for the first book\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book date])\n",
      "-> q_themes_enhanced: [('Date', ['Q10467097'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (first, ['P577']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 9.71s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (date, ['P837']), (publication, ['P577'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date', 'Harry Potter', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [first, publication, date, book, Book, Publication, first book, Date, Harry Potter, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (book, ['Q571', 'Q421300']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 58.51s\n",
      "-->  17 nodes and 22 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 17 nodes and 22 edges\n",
      "-> predicates_dict: {'P50': 16758, 'P106': 1, 'P582': 3, 'P157': 1, 'P585': 5, 'P2868': 3, 'P20': 1, 'P1686': 3, 'P1411': 3, 'P1932': 3, 'P569': 3, 'P570': 2, 'P577': 2, 'P580': 3, 'P2031': 1, 'P1672': 1, 'P180': 1, 'P186': 1, 'P31': 16, 'P571': 1, 'P291': 1, 'P69': 2, 'P812': 1, 'P279': 7, 'P1013': 5, 'P2408': 1, 'P19': 1, 'P1476': 1, 'P805': 1, 'P1343': 1, 'P1104': 1, 'P3245': 1, 'P3250': 2, 'P1441': 9, 'P642': 4, 'P407': 5, 'P443': 1, 'P3744': 2, 'P3984': 1, 'P123': 1, 'P1113': 1, 'P1557': 2, 'P735': 1, 'P3831': 1, 'P674': 1, 'P1477': 1, 'P747': 1, 'P958': 1, 'P92': 1, 'P921': 1, 'P170': 1, 'P1881': 1, 'P856': 1, 'P136': 2, 'P58': 1, 'P1114': 1, 'P344': 1, 'P1552': 1, 'P1709': 1, 'P641': 1, 'P736': 2, 'P282': 1, 'P453': 3, 'P161': 3, 'P2002': 1, 'P1344': 1, 'P793': 1, 'P734': 1, 'P2096': 1, 'P373': 1, 'P527': 2, 'P1545': 1}\n",
      "-> paths_keywords: (['first', 'publication', 'date', 'book', 'harry potter', 'j. k. rowling', 'first book'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']], 'date of publication': [date of publication, ['P577']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 108\n",
      "->Computing possible paths \tRunning time is 17.13s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 96\n",
      "->\tRunning time is 3.64s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q215972', 0.4929079908427412], ['1997-01-01T00:00:00Z', 0.35892668004032896]]\n",
      "->Computing hypothesises \tRunning time is 78.23s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 2\n",
      "->\tRunning time is 4.09s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['1997-01-01T00:00:00Z', 'P577', 'Q8337', 'P50', 'Q34660']\n",
      "->\tTotal Running time is 175.21s\n",
      "\n",
      "df_convex 1997-01-01T00:00:00Z\n",
      "df_convex_rr 1.0\n",
      "\n",
      "CORRECT 537 - 2 -> Convex 1997-01-01T00:00:00Z\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What was the year of publication for the first book?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What was the date of publication for the first book \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What was the date of publication for the first book\n",
      "> Time related question detected\n",
      "-> q_themes: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book date])\n",
      "-> q_themes_enhanced: [('Date', ['Q10467097'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "-> q_predicates: [(be, ['P31']), (date, ['P837']), (publication, ['P577']), (first, ['P577']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 9.02s\n",
      "--> Predicates enhanced by previous context: [(series, ['P179']), (be, ['P31']), (date, ['P837']), (publication, ['P577']), (book, ['P50']), (creator, ['P170'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (publication, ['Q732577', 'Q15852766']), (date, ['Q1652093', 'Q3016931']), (book, ['Q571', 'Q421300']), (Book, ['Q11515178', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (first book, ['Q1419297'])], [Book])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'publication', 'date', 'book', 'Book', 'Publication', 'first book', 'Date', 'Harry Potter', 'Harry Potter', 'Harry Potter and the Order of the Phoenix', 'J. K. Rowling', 'wizard in the Harry Potter universe']\n",
      "meaningful_names_no_previous_answer [first, publication, date, book, Book, Publication, first book, Date, Harry Potter, Harry Potter, Harry Potter and the Order of the Phoenix, J. K. Rowling, wizard in the Harry Potter universe]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (J. K. Rowling, ['Q34660']), (wizard in the Harry Potter universe, ['Q15298259'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (publication, ['Q15852766']), (date, ['Q1652093', 'Q3016931']), (Book, ['Q11515178', 'Q421300', 'Q16860229']), (Publication, ['Q51523527', 'Q15728967']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (J. K. Rowling, ['Q34660']), (wizard in the Harry Potter universe, ['Q15298259']), (book, ['Q571', 'Q421300']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 91.24s\n",
      "-->  125 nodes and 170 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 125 nodes and 170 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 125 nodes or 170 edges was above the limit of 100\n",
      "-> predicates_dict: {'P179': 29, 'P50': 28, 'P1441': 16, 'P674': 5, 'P31': 310, 'P170': 59, 'P642': 4, 'P1013': 5, 'P106': 1, 'P582': 3, 'P157': 1, 'P585': 6, 'P1411': 4, 'P1686': 2, 'P1545': 5, 'P155': 3, 'P156': 2, 'P569': 3, 'P2868': 1, 'P570': 2, 'P577': 6, 'P580': 4, 'P291': 2, 'P2031': 1, 'P1672': 1, 'P180': 1, 'P1932': 3, 'P571': 1, 'P20': 1, 'P69': 2, 'P2755': 1, 'P812': 1, 'P279': 12, 'P2408': 3, 'P3245': 1, 'P3250': 1, 'P360': 2, 'P1476': 1, 'P1343': 1, 'P805': 1, 'P138': 1, 'P735': 3, 'P1104': 1, 'P407': 4, 'P443': 1, 'P3744': 1, 'P3984': 1, 'P1877': 1, 'P1557': 2, 'P1113': 1, 'P747': 1, 'P1040': 1, 'P110': 1, 'P958': 1, 'P92': 1, 'P162': 3, 'P282': 1, 'P58': 1, 'P1080': 1, 'P1709': 1, 'P1114': 1, 'P1552': 1, 'P1412': 2, 'P736': 2, 'P453': 4, 'P161': 4, 'P3831': 2, 'P527': 2, 'P2096': 1, 'P793': 1, 'P175': 1, 'P734': 2}\n",
      "-> paths_keywords: (['first', 'publication', 'date', 'book', 'harry potter', 'j. k. rowling', 'first book'], {'series': [series, ['P179']], 'instance of': [instance of, ['P31']], 'day in year for periodic occurrence': [day in date for periodic occurrence, ['P837']], 'date of publication': [date of publication, ['P577']], 'author': [author, ['P50']], 'creator': [creator, ['P170']]}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 3904\n",
      "->Computing possible paths \tRunning time is 18.36s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 7808\n",
      "->\tRunning time is 11.88s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q102235', 1.912739692531818], ['1997-01-01T00:00:00Z', 0.5052608020525637], ['1998-05-02T00:00:00Z', 0.4562581472168756]]\n",
      "->Computing hypothesises \tRunning time is 166.01s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 1\n",
      "->\tRunning time is 143.4s\n",
      "--> len(cleared_golden_paths): 1\n",
      "---> First path: ['1998-05-02T00:00:00Z', 'P582', 'Q3244512', 'P31', 'Q15298259', 'P1441', 'Q8337', 'P179', 'Q80817', 'P1545', '5']\n",
      "->\tTotal Running time is 534.34s\n",
      "\n",
      "df_graphqa 1998-05-02T00:00:00Z\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "PARTIAL_CORRECT 537 - 2 -> graphqa in answers ['1998-05-02T00:00:00Z', '1997-01-01T00:00:00Z']\n",
      "    conversation_id turn plus_convex  \\\n",
      "334             536    1       False   \n",
      "\n",
      "                                              question                answer  \\\n",
      "334  What was the year of publication for the first...  1997-01-01T00:00:00Z   \n",
      "\n",
      "    domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "334  books   False         89.57         0.0    False            2.4   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr  \\\n",
      "334          0.0  1997-01-01T00:00:00Z       175.46        1.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "334  1998-05-02T00:00:00Z        534.62         True         True   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "334         True         True           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-335-ic536-iq1-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 537/2240 -> 2/5 -> Convex=True: (1997-01-01T00:00:00Z) What was the year of publication for the first book?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q1148668\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex 1997-01-01T00:00:00Z\n",
      "df_convex_rr 1.0\n",
      "\n",
      "CORRECT 537 - 2 -> Convex 1997-01-01T00:00:00Z\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa 1997-01-01T00:00:00Z\n",
      "df_graphqa_rr 1.0\n",
      "\n",
      "CORRECT 537 - 2 -> graphqa 1997-01-01T00:00:00Z\n",
      "\n",
      "PARTIAL_CORRECT 537 - 2 -> graphqa in answers ['1997-01-01T00:00:00Z', '2003-06-21T00:00:00Z']\n",
      "    conversation_id turn plus_convex  \\\n",
      "335             536    1        True   \n",
      "\n",
      "                                              question                answer  \\\n",
      "335  What was the year of publication for the first...  1997-01-01T00:00:00Z   \n",
      "\n",
      "    domain   qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "335  books  Q1148668          0.77         0.0    False           2.35   \n",
      "\n",
      "     platypus_rr                convex  convex_time  convex_rr  \\\n",
      "335          0.0  1997-01-01T00:00:00Z         1.45        1.0   \n",
      "\n",
      "                  graphqa  graphqa_time graphqa_top2 graphqa_top3  \\\n",
      "335  1997-01-01T00:00:00Z          2.27         True         True   \n",
      "\n",
      "    graphqa_top4 graphqa_top5 graphqa_topall  graphqa_rr  \n",
      "335         True         True           True         1.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-336-ic536-iq1-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 06:24:10.641777\n",
      "\t>>> Processing 537/2240 -> 3/5 -> Convex=False: (Q43361) The first book was called what?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: The first book was called what?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: The first book was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: The first book was called what\n",
      "-> q_themes: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 4.41s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (called, ['P474'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'what', 'What', 'first book']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'what', 'What', 'first book', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [first, what, What, first book, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (J. K. Rowling, ['Q34660']), (what, ['Q20656446', 'Q28036789']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.03s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: The first book was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: The first book was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: The first book called what\n",
      "-> q_themes: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474']), (first, ['P577']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 4.64s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (called, ['P474']), (first, ['P577']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'what', 'What', 'first book']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'what', 'What', 'first book', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [first, what, What, first book, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (J. K. Rowling, ['Q34660']), (what, ['Q20656446', 'Q28036789']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 23.95s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: The first book was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: The first book was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: The first book was called what\n",
      "-> q_themes: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 4.6s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (called, ['P474']), (date of publication, ['P577'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'what', 'What', 'first book']\n",
      "---> Meaningful keywords enhanced by previous context: ['first', 'what', 'What', 'first book', 'Harry Potter', 'J. K. Rowling', 'Harry Potter', '1997-01-01T00:00:00Z']\n",
      "meaningful_names_no_previous_answer [first, what, What, first book, Harry Potter, J. K. Rowling, Harry Potter, 1997 - 01 01T00:00:00Z]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (what, ['Q20656446', 'Q28036789']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 50.06s\n",
      "-->  42 nodes and 54 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 42 nodes and 54 edges\n",
      "-> predicates_dict: {'P50': 16757, 'P585': 10, 'P2031': 1, 'P577': 4, 'P674': 3, 'P642': 6, 'P1441': 12, 'P170': 3, 'P106': 3, 'P569': 3, 'P2868': 4, 'P582': 3, 'P570': 2, 'P571': 1, 'P157': 1, 'P20': 1, 'P580': 2, 'P31': 12, 'P69': 2, 'P812': 1, 'P1476': 1, 'P805': 1, 'P1343': 1, 'P19': 1, 'P3744': 1, 'P279': 2, 'P407': 3, 'P3984': 1, 'P495': 1, 'P166': 3, 'P518': 1, 'P186': 1, 'P1686': 6, 'P1411': 6, 'P463': 1, 'P138': 8, 'P1545': 2, 'P735': 3, 'P27': 3, 'P1559': 2, 'P3831': 2, 'P364': 1, 'P123': 1, 'P1557': 2, 'P1113': 1, 'P527': 6, 'P136': 3, 'P195': 1, 'P217': 1, 'P276': 1, 'P108': 1, 'P1881': 1, 'P58': 1, 'P1039': 2, 'P1038': 2, 'P344': 1, 'P641': 1, 'P453': 3, 'P161': 3, 'P1114': 1, 'P747': 1, 'P734': 1, 'P1552': 1, 'P2096': 1, 'P21': 1}\n",
      "-> paths_keywords: (['first', 'what', 'harry potter', 'j. k. rowling', 'first book'], {}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 562\n",
      "->Computing possible paths \tRunning time is 10.68s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 562\n",
      "->\tRunning time is 3.81s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q145', 3.4431474784241356], ['Q43361', 2.6285969023669344], ['Q215972', 0.7887108181825304], ['1997-01-01T00:00:00Z', 0.7715180262121736]]\n",
      "->Computing hypothesises \tRunning time is 67.48s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 6\n",
      "->\tRunning time is 7.23s\n",
      "--> len(cleared_golden_paths): 2\n",
      "---> First path: ['Q145', 'P27', 'Q34660', 'P585', '1997-01-01T00:00:00Z', 'P577', 'Q8337', 'P1441', 'Q3244512']\n",
      "->\tTotal Running time is 147.58s\n",
      "\n",
      "df_convex Q145\n",
      "df_convex_rr 0.5\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: The first book was called what?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: The first book was called what \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: The first book was called what\n",
      "-> q_themes: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: call\n",
      "-> q_predicates: [(be, ['P31']), (called, ['P474'])]\n",
      "-> q_predicates \tRunning time is 4.83s\n",
      "--> Predicates enhanced by previous context: [(series, ['P179']), (be, ['P31']), (called, ['P474']), (end date, ['P582']), (present in work, ['P1441']), (series ordinal, ['P1545'])]\n",
      "----> q_themes in context: ([(first, ['Q19269277']), (what, ['Q20656446', 'Q28036789']), (What, ['Q22073920']), (first book, ['Q1419297'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['first', 'what', 'What', 'first book']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Meaningful keywords enhanced by previous context: ['first', 'what', 'What', 'first book', 'Harry Potter', 'Harry Potter', 'Harry Potter and the Order of the Phoenix', 'wizard in the Harry Potter universe', '1998-05-02T00:00:00Z', 'Harry Potter and the Order of the Phoenix', 'Harry Potter', '5', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [first, what, What, first book, Harry Potter, Harry Potter, Harry Potter and the Order of the Phoenix, wizard in the Harry Potter universe, 1998 - 05 02T00:00:00Z, Harry Potter and the Order of the Phoenix, Harry Potter, 5, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (wizard in the Harry Potter universe, ['Q15298259']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(first, ['Q19269277']), (What, ['Q22073920', 'Q28036789']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (wizard in the Harry Potter universe, ['Q15298259']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (J. K. Rowling, ['Q34660']), (what, ['Q20656446', 'Q28036789']), (first book, ['Q1419297'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 82.44s\n",
      "-->  259 nodes and 366 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 259 nodes and 366 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 259 nodes or 366 edges was above the limit of 100\n",
      "-> predicates_dict: {'P179': 29, 'P1441': 611, 'P674': 6, 'P31': 309, 'P642': 3, 'P582': 4, 'P1545': 7, 'P570': 3, 'P453': 4, 'P50': 1, 'P170': 1, 'P155': 6, 'P156': 3, 'P157': 1, 'P2868': 2, 'P20': 1, 'P69': 2, 'P279': 2, 'P138': 8, 'P735': 4, 'P580': 3, 'P2755': 1, 'P812': 1, 'P1113': 1, 'P585': 11, 'P1411': 10, 'P1686': 7, 'P1922': 1, 'P569': 1, 'P364': 1, 'P577': 7, 'P291': 1, 'P800': 2, 'P3744': 2, 'P407': 5, 'P3984': 1, 'P518': 1, 'P186': 1, 'P3650': 1, 'P571': 1, 'P360': 2, 'P1476': 1, 'P805': 1, 'P1343': 1, 'P361': 2, 'P1557': 2, 'P463': 1, 'P495': 3, 'P1877': 1, 'P195': 1, 'P217': 1, 'P276': 1, 'P27': 3, 'P136': 4, 'P166': 2, 'P527': 3, 'P406': 1, 'P161': 2, 'P3132': 1, 'P1881': 1, 'P1039': 1, 'P1038': 1, 'P1080': 1, 'P108': 1, 'P264': 1, 'P747': 1, 'P1114': 1, 'P1552': 1, 'P971': 2, 'P1971': 1, 'P3831': 1, 'P2002': 1, 'P734': 1}\n",
      "-> paths_keywords: (['first', 'what', 'harry potter', '5', 'j. k. rowling', 'first book'], {}, [what])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 30.24s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 15960\n",
      "->\tRunning time is 44.5s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q176132', 28.73218346865038], ['Q173998', 28.702137433024216], ['Q174009', 28.681647310551217], ['Q187923', 28.672675962411446], ['Q179641', 28.66093966579314], ['Q176772', 28.654440085779814], ['Q712548', 28.64760835980941], ['Q190282', 28.625170359939045], ['Q177439', 28.618605743048096], ['Q192179', 28.593084435253033], ['Q161687', 13.613141507351155], ['Q102448', 11.003518313968353], ['Q80817', 7.386084377135761], ['Q102225', 6.899667255939699], ['Q102235', 5.910307350889795], ['Q15298259', 3.5264602726872925], ['Q9010722', 2.045145044596331], ['Q754837', 1.9499641764970486], ['Q3257000', 1.9281505723201677], ['Q3745681', 1.7258658862100906], ['Q1860', 1.4600635623988898], ['Q15553735', 1.2031521007825114], ['Q3744404', 0.9700327213603949], ['Q3256600', 0.2937244737536537], ['Q3224418', -0.13276230903129416], ['Q2838011', -0.36113025457676806], ['Q3278363', -0.6187001338360903], ['Q1057918', -0.7884284657015922]]\n",
      "->Computing hypothesises \tRunning time is 1078.43s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 0\n",
      "->\tRunning time is 29.22s\n",
      "--> len(cleared_golden_paths): 0\n",
      "->\tTotal Running time is 1353.72s\n",
      "\n",
      "df_graphqa Q176132\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question  answer  \\\n",
      "336             536    2       False  The first book was called what?  Q43361   \n",
      "\n",
      "    domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "336  books   False          56.5         0.0    False           0.65   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr  graphqa  graphqa_time  \\\n",
      "336          0.0   Q145       147.84        0.5  Q176132       1354.05   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "336        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "336         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-337-ic536-iq2-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 537/2240 -> 3/5 -> Convex=True: (Q43361) The first book was called what?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q571\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q8337\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q571\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                         question  answer  \\\n",
      "337             536    2        True  The first book was called what?  Q43361   \n",
      "\n",
      "    domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "337  books    Q571          0.54         0.0    False           0.64   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "337          0.0  Q8337         0.94        0.0    Q571          1.68   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "337        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "337         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-338-ic536-iq2-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 06:50:13.527200\n",
      "\t>>> Processing 537/2240 -> 4/5 -> Convex=False: (Q21) What country was the book set in?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: What country was the book set in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What country was the book set in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What country was the book set in\n",
      "-> q_themes: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: set\n",
      "-> q_predicates: [(be, ['P31']), (set, ['P4809']), (country, [])]\n",
      "-> q_predicates \tRunning time is 5.47s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (set, ['P4809']), (country, [])]\n",
      "----> q_themes in context: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['country', 'the book', 'Country']\n",
      "---> Meaningful keywords enhanced by previous context: ['country', 'the book', 'Country', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [country, the book, Country, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (J. K. Rowling, ['Q34660']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 53.6s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: What country was the book set in?\n",
      "--> Auto correcting question in progress...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Auto corrected q_nlp: What country was the book set in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: What country the book set in\n",
      "-> q_themes: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "behold: get_most_similar started with: set\n",
      "-> q_predicates: [(be, ['P31']), (set, ['P4809']), (country, ['P17', 'P3005']), (book, ['P50'])]\n",
      "-> q_predicates \tRunning time is 5.4s\n",
      "--> Predicates enhanced by previous context: [(be, ['P31']), (set, ['P4809']), (country, ['P17', 'P3005']), (book, ['P50'])]\n",
      "----> q_themes in context: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['country', 'the book', 'Country']\n",
      "---> Meaningful keywords enhanced by previous context: ['country', 'the book', 'Country', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [country, the book, Country, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (J. K. Rowling, ['Q34660']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 54.95s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: What country was the book set in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What country was the book set in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What country was the book set in\n",
      "-> q_themes: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: set\n",
      "-> q_predicates: [(be, ['P31']), (set, ['P4809']), (country, [])]\n",
      "-> q_predicates \tRunning time is 5.48s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (be, ['P31']), (set, ['P4809']), (country, []), (country of citizenship, ['P27']), (point in time, ['P585']), (date of publication, ['P577']), (present in work, ['P1441'])]\n",
      "----> q_themes in context: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['country', 'the book', 'Country']\n",
      "---> Meaningful keywords enhanced by previous context: ['country', 'the book', 'Country', 'Harry Potter', 'J. K. Rowling', 'Harry Potter', '1997-01-01T00:00:00Z', 'Harry Potter', 'United Kingdom']\n",
      "meaningful_names_no_previous_answer [country, the book, Country, Harry Potter, J. K. Rowling, Harry Potter, 1997 - 01 01T00:00:00Z, Harry Potter, United Kingdom]\n",
      "----> Meaningful keywords casted as theme ([(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145'])], [])\n",
      "q_focused_parts: [(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 98.54s\n",
      "-->  131 nodes and 170 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 131 nodes and 170 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 131 nodes or 170 edges was above the limit of 100\n",
      "-> predicates_dict: {'P50': 16757, 'P585': 16, 'P2031': 2, 'P577': 5, 'P674': 3, 'P642': 5, 'P1441': 602, 'P170': 2, 'P495': 4, 'P27': 6, 'P138': 8, 'P453': 4, 'P106': 3, 'P17': 2, 'P1282': 1, 'P1963': 3, 'P1686': 11, 'P1411': 9, 'P291': 1, 'P569': 4, 'P364': 1, 'P582': 3, 'P157': 1, 'P2868': 3, 'P20': 1, 'P800': 2, 'P69': 2, 'P3744': 1, 'P407': 3, 'P3984': 1, 'P166': 15, 'P580': 2, 'P812': 1, 'P2408': 1, 'P2453': 1, 'P805': 2, 'P1476': 1, 'P1343': 1, 'P463': 1, 'P31': 217, 'P360': 2, 'P361': 2, 'P136': 1, 'P527': 2, 'P108': 1, 'P735': 1, 'P3831': 2, 'P813': 1, 'P973': 1, 'P1709': 1, 'P1113': 1, 'P2452': 2, 'P161': 2, 'P1039': 2, 'P1038': 2, 'P1877': 2, 'P1881': 1, 'P734': 1, 'P58': 1, 'P921': 1, 'P570': 1, 'P5008': 1, 'P2096': 1}\n",
      "-> paths_keywords: (['country', 'harry potter', 'j. k. rowling', 'united kingdom', 'the book', 'set'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 27.89s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 13088\n",
      "->\tRunning time is 26.58s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q176132', 36.175591278328966], ['Q173998', 36.10967294872373], ['Q102235', 2.4648970544998225], ['Q15299049', 2.1159826995104787], ['Q215972', 1.1398146021705466], ['1997-01-01T00:00:00Z', 0.8399791350895821], ['Q10298203', 0.4560835503502346]]\n",
      "->Computing hypothesises \tRunning time is 183.31s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 48\n",
      "->\tRunning time is 101.41s\n",
      "--> len(cleared_golden_paths): 23\n",
      "---> First path: ['Q176132', 'P1441', 'Q8337', 'P577', '1997-01-01T00:00:00Z', 'P585', 'Q34660', 'P27', 'Q145', 'P495', 'Q216930']\n",
      "->\tTotal Running time is 533.81s\n",
      "\n",
      "df_convex Q176132\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: What country was the book set in?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: What country was the book set in \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: What country was the book set in\n",
      "-> q_themes: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "-> q_themes_enhanced: []\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: set\n",
      "-> q_predicates: [(be, ['P31']), (set, ['P4809']), (country, [])]\n",
      "-> q_predicates \tRunning time is 5.09s\n",
      "--> Predicates enhanced by previous context: [(killed by, ['P157']), (be, ['P31']), (set, ['P4809']), (country, [])]\n",
      "----> q_themes in context: ([(country, ['Q6256', 'P17']), (the book, ['Q3794440']), (Country, ['Q11070708', 'Q1754454'])], [])\n",
      "--> Potential meaningful keywords for the sentence: ['country', 'the book', 'Country']\n",
      "---> Meaningful keywords enhanced by previous context: ['country', 'the book', 'Country', 'Harry Potter', 'Harry Potter', 'Harry Potter', 'Lord Voldemort', 'Harry Potter and the Order of the Phoenix', 'wizard in the Harry Potter universe', '1998-05-02T00:00:00Z', 'Harry Potter and the Order of the Phoenix', '5', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [country, the book, Country, Harry Potter, Harry Potter, Harry Potter, Lord Voldemort, Harry Potter and the Order of the Phoenix, wizard in the Harry Potter universe, 1998 - 05 02T00:00:00Z, Harry Potter and the Order of the Phoenix, 5, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Lord Voldemort, ['Q176132']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (wizard in the Harry Potter universe, ['Q15298259']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(country, ['P17', 'Q6256']), (Country, ['Q11070708', 'Q1754454']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Lord Voldemort, ['Q176132']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (wizard in the Harry Potter universe, ['Q15298259']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (J. K. Rowling, ['Q34660']), (the book, ['Q3794440'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 90.39s\n",
      "-->  85 nodes and 116 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 85 nodes and 116 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 85 nodes or 116 edges was above the limit of 100\n",
      "-> predicates_dict: {'P157': 17, 'P1441': 268, 'P179': 12, 'P674': 3, 'P31': 509, 'P642': 3, 'P582': 3, 'P1545': 4, 'P570': 2, 'P453': 4, 'P50': 1, 'P170': 1, 'P509': 1, 'P17': 1, 'P1282': 1, 'P1963': 3, 'P495': 4, 'P27': 4, 'P155': 3, 'P156': 5, 'P360': 2, 'P2453': 1, 'P805': 2, 'P1411': 7, 'P1476': 1, 'P1343': 1, 'P585': 8, 'P127': 1, 'P1877': 3, 'P291': 1, 'P577': 2, 'P2868': 1, 'P20': 2, 'P166': 2, 'P735': 2, 'P3831': 1, 'P175': 3, 'P463': 3, 'P364': 2, 'P813': 1, 'P973': 1, 'P1709': 1, 'P138': 1, 'P1686': 6, 'P527': 4, 'P406': 1, 'P2452': 2, 'P580': 2, 'P108': 1, 'P1552': 1, 'P1039': 3, 'P1038': 3, 'P607': 1, 'P734': 1, 'P361': 2, 'P136': 1, 'P106': 1, 'P161': 2, 'P264': 1, 'P279': 1}\n",
      "-> paths_keywords: (['country', 'harry potter', 'lord voldemort', '5', 'j. k. rowling', 'the book', 'set'], {}, [What])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 32.18s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 15962\n",
      "->\tRunning time is 30.84s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q145', 5.370453814648183], ['Q30', 4.892912297236419], ['Q102235', 4.135091804628156], ['Q161687', 3.5350277609130276], ['Q15298259', 1.8489620872756496], ['Q102225', 0.7835176142427643]]\n",
      "->Computing hypothesises \tRunning time is 232.72s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 69\n",
      "->\tRunning time is 467.24s\n",
      "--> len(cleared_golden_paths): 69\n",
      "---> First path: ['Q145', 'P27', 'Q176132', 'P1441', 'Q8337', 'P179', 'Q80817', 'P1545', '5']\n",
      "->\tTotal Running time is 948.51s\n",
      "\n",
      "df_graphqa Q145\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "338             536    3       False  What country was the book set in?   \n",
      "\n",
      "    answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "338    Q21  books   False        119.89         0.0    False           0.26   \n",
      "\n",
      "     platypus_rr   convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "338          0.0  Q176132       534.07        0.0    Q145        948.77   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "338        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "338         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-339-ic536-iq3-pcFalse.pickle.bz2\n",
      "\n",
      "\n",
      "\t>>> Processing 537/2240 -> 4/5 -> Convex=True: (Q21) What country was the book set in?                                  \n",
      "qAnswer extended by Convex\n",
      "df_qanswer Q571\n",
      "df_qanswer_rr 0.0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by Convex\n",
      "df_convex Q145\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by Convex\n",
      "df_graphqa Q8337\n",
      "df_graphqa_rr 0.0\n",
      "    conversation_id turn plus_convex                           question  \\\n",
      "339             536    3        True  What country was the book set in?   \n",
      "\n",
      "    answer domain qanswer  qanswer_time  qanswer_rr platypus  platypus_time  \\\n",
      "339    Q21  books    Q571          0.58         0.0    False           0.22   \n",
      "\n",
      "     platypus_rr convex  convex_time  convex_rr graphqa  graphqa_time  \\\n",
      "339          0.0   Q145         1.08        0.0   Q8337          1.83   \n",
      "\n",
      "    graphqa_top2 graphqa_top3 graphqa_top4 graphqa_top5 graphqa_topall  \\\n",
      "339        False        False        False        False          False   \n",
      "\n",
      "     graphqa_rr  \n",
      "339         0.0  \n",
      "Saving Dataframe Done! /data/users/romain.claret/tm/mse.tm.chatbot.base/benchmark_pickles/convex-conversations-testset-para-1/benchmarking-qanswer-platypus-convex-qagraph-340-ic536-iq3-pcTrue.pickle.bz2\n",
      "\n",
      "\n",
      "It is  2020-02-07 07:17:00.296725\n",
      "\t>>> Processing 537/2240 -> 5/5 -> Convex=False: (Q80817) Which book has the highest page count?                                  \n",
      "qAnswer extended by GraphQA\n",
      "User input: Which book has the highest page count?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which book has the highest page count \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Which book has the highest page count\n",
      "-> q_themes: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the highest page count, The Highest Page Count, highest page count, the highest Page Count])\n",
      "-> q_themes_enhanced: [('page count', ['P1104']), ('page', ['P304']), ('count', ['Q3519259']), ('high', ['Q5754843']), ('The High', ['Q24641532']), ('The Count', ['Q12345']), ('Highest', ['Q21169106']), ('Page', ['Q1022777']), ('Count', ['Q2482645']), ('High', ['Q1617718'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(has, ['P31'])]\n",
      "-> q_predicates \tRunning time is 9.06s\n",
      "--> Predicates enhanced by previous context: [(has, ['P31'])]\n",
      "----> q_themes in context: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the, The, highest])\n",
      "--> Potential meaningful keywords for the sentence: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High']\n",
      "---> Meaningful keywords enhanced by previous context: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [Book, book, page count, page, count, high, The High, The Count, Highest, Page, Count, High, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (book, ['Q997698']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (book, ['Q997698']), (J. K. Rowling, ['Q34660'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 34.61s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "Looped in aggressive mode with: Which book has the highest page count?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which book has the highest page count \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> Replacing verbs in context..\n",
      "-> New q_nlp: Which book has the highest page count\n",
      "-> q_themes: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the highest page count, The Highest Page Count, highest page count, the highest Page Count])\n",
      "-> q_themes_enhanced: [('page count', ['P1104']), ('page', ['P304']), ('count', ['Q3519259']), ('high', ['Q5754843']), ('The High', ['Q24641532']), ('The Count', ['Q12345']), ('Highest', ['Q21169106']), ('Page', ['Q1022777']), ('Count', ['Q2482645']), ('High', ['Q1617718'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "behold: get_most_similar started with: book\n",
      "behold: get_most_similar started with: count\n",
      "-> q_predicates: [(has, ['P31']), (book, ['P50']), (highest, ['P610', 'P4214']), (page, ['P304', 'P301']), (count, [])]\n",
      "-> q_predicates \tRunning time is 9.03s\n",
      "--> Predicates enhanced by previous context: [(has, ['P31']), (book, ['P50']), (highest, ['P610', 'P4214']), (page, ['P304', 'P301']), (count, [])]\n",
      "----> q_themes in context: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the, The, highest])\n",
      "--> Potential meaningful keywords for the sentence: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High']\n",
      "---> Meaningful keywords enhanced by previous context: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [Book, book, page count, page, count, high, The High, The Count, Highest, Page, Count, High, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (book, ['Q997698']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (book, ['Q997698']), (J. K. Rowling, ['Q34660'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "->New graph \tRunning time is 41.64s\n",
      "-->  0 nodes and 0 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 0 nodes and 0 edges\n",
      "---> Loop detected, returning the graph in the current state\n",
      "---> No nodes, cancelling this run\n",
      "\n",
      "df_qanswer False\n",
      "df_qanswer_rr 0\n",
      "\n",
      "Asking Platypus\n",
      "df_platypus False\n",
      "df_platypus_rr 0.0\n",
      "\n",
      "Convex extended by GraphQA\n",
      "User input: Which book has the highest page count?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which book has the highest page count \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Which book has the highest page count\n",
      "-> q_themes: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the highest page count, The Highest Page Count, highest page count, the highest Page Count])\n",
      "-> q_themes_enhanced: [('page count', ['P1104']), ('page', ['P304']), ('count', ['Q3519259']), ('high', ['Q5754843']), ('The High', ['Q24641532']), ('The Count', ['Q12345']), ('Highest', ['Q21169106']), ('Page', ['Q1022777']), ('Count', ['Q2482645']), ('High', ['Q1617718'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(has, ['P31'])]\n",
      "-> q_predicates \tRunning time is 8.53s\n",
      "--> Predicates enhanced by previous context: [(author, ['P50']), (has, ['P31']), (present in work, ['P1441']), (date of publication, ['P577']), (point in time, ['P585']), (country of citizenship, ['P27']), (country of origin, ['P495'])]\n",
      "----> q_themes in context: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the, The, highest])\n",
      "--> Potential meaningful keywords for the sentence: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High']\n",
      "---> Meaningful keywords enhanced by previous context: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High', 'Harry Potter', 'J. K. Rowling', 'Harry Potter', '1997-01-01T00:00:00Z', 'Harry Potter', 'United Kingdom', 'Lord Voldemort']\n",
      "meaningful_names_no_previous_answer [Book, book, page count, page, count, high, The High, The Count, Highest, Page, Count, High, Harry Potter, J. K. Rowling, Harry Potter, 1997 - 01 01T00:00:00Z, Harry Potter, United Kingdom, Lord Voldemort]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (book, ['Q997698']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145']), (Lord Voldemort, ['Q176132'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (book, ['Q997698']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (J. K. Rowling, ['Q34660']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145']), (Lord Voldemort, ['Q176132'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n",
      "->New graph \tRunning time is 71.76s\n",
      "-->  147 nodes and 196 edges\n",
      "--> Removing meaningless subgraphs\n",
      "--> New graph of: 147 nodes and 196 edges\n",
      "---> Rebuilding the graph with k_deep 2 ... Previously: 147 nodes or 196 edges was above the limit of 100\n",
      "-> predicates_dict: {'P50': 16757, 'P585': 16, 'P2031': 2, 'P577': 6, 'P674': 5, 'P642': 8, 'P1441': 852, 'P170': 4, 'P495': 4, 'P27': 7, 'P138': 9, 'P453': 4, 'P157': 3, 'P131': 2, 'P106': 3, 'P1686': 11, 'P1411': 8, 'P527': 6, 'P569': 4, 'P3744': 2, 'P2002': 1, 'P407': 3, 'P3984': 1, 'P17': 3, 'P1971': 1, 'P31': 20, 'P571': 1, 'P1113': 1, 'P518': 1, 'P364': 2, 'P582': 2, 'P2868': 4, 'P20': 2, 'P69': 2, 'P580': 3, 'P108': 2, 'P1013': 1, 'P800': 2, 'P166': 15, 'P1881': 3, 'P570': 2, 'P180': 1, 'P812': 1, 'P361': 1, 'P3831': 3, 'P175': 3, 'P4862': 1, 'P463': 2, 'P1476': 2, 'P805': 1, 'P1343': 1, 'P155': 1, 'P156': 1, 'P509': 1, 'P136': 1, 'P1424': 1, 'P373': 1, 'P1877': 2, 'P607': 1, 'P856': 2, 'P1040': 1, 'P735': 1, 'P161': 2, 'P1039': 1, 'P1038': 1, 'P935': 1, 'P58': 1, 'P625': 1, 'P2096': 1}\n",
      "-> paths_keywords: (['book', 'harry potter', 'j. k. rowling', 'united kingdom', 'lord voldemort'], {'author': [author, ['P50']], 'instance of': [instance of, ['P31']], 'present in work': [present in work, ['P1441']], 'date of publication': [date of publication, ['P577']], 'point in time': [point in time, ['P585']], 'country of citizenship': [country of citizenship, ['P27']], 'country of origin': [country of origin, ['P495']], 'page count': [number of pages, ['P1104']], 'page': [page, ['P304']], 'number of pages': [number of pages, ['P1104']]}, [Which])\n",
      "-> Computing possible paths... (could be long)\n",
      "--> len(path_nodes): 8000\n",
      "->Computing possible paths \tRunning time is 33.04s\n",
      "-> Filtering paths... (could be long)\n",
      "--> len(paths_nodes_filtered): 15960\n",
      "->\tRunning time is 35.07s\n",
      "-> Computing hypothesises...\n",
      "--> hypothesises: [['Q173998', 36.571729366791146], ['Q20711488', 3.584478542019486], ['Q15298259', 2.8098684642330687], ['Q102235', 2.197389751691998], ['Q15299049', 1.818947199412837], ['Q215972', 0.9238940088093271], ['1997-01-01T00:00:00Z', 0.5087468369859398], ['Q10298203', 0.07947159514577783], ['Q6012217', -1.0692202252646061]]\n",
      "->Computing hypothesises \tRunning time is 641.81s\n",
      "-> Computing golden paths...\n",
      "--> len(golden_paths): 79\n",
      "->\tRunning time is 77.0s\n",
      "--> len(cleared_golden_paths): 45\n",
      "---> First path: ['Q173998', 'P1441', 'Q216930', 'P495', 'Q145', 'P27', 'Q3244512', 'P170', 'Q34660', 'P585', '1997-01-01T00:00:00Z']\n",
      "->\tTotal Running time is 946.85s\n",
      "\n",
      "df_convex Q173998\n",
      "df_convex_rr 0.0\n",
      "\n",
      "GraphQA extended by GraphQA\n",
      "User input: Which book has the highest page count?\n",
      "--> Auto correcting question in progress...\n",
      "-> Auto corrected q_nlp: Which book has the highest page count \n",
      "> Processing in conversational context..\n",
      "-> Replacing pronouns from context..\n",
      "-> New q_nlp: Which book has the highest page count\n",
      "-> q_themes: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [the highest page count, The Highest Page Count, highest page count, the highest Page Count])\n",
      "-> q_themes_enhanced: [('page count', ['P1104']), ('page', ['P304']), ('count', ['Q3519259']), ('high', ['Q5754843']), ('The High', ['Q24641532']), ('The Count', ['Q12345']), ('Highest', ['Q21169106']), ('Page', ['Q1022777']), ('Count', ['Q2482645']), ('High', ['Q1617718'])]\n",
      "--> Calculating predicates... (could be long.. depends on uncached unpure predicates)\n",
      "-> q_predicates: [(has, ['P31'])]\n",
      "-> q_predicates \tRunning time is 8.28s\n",
      "--> Predicates enhanced by previous context: [(killed by, ['P157']), (has, ['P31']), (country of citizenship, ['P27']), (present in work, ['P1441']), (series, ['P179']), (series ordinal, ['P1545'])]\n",
      "----> q_themes in context: ([(Book, ['Q571', 'Q421300']), (book, ['Q997698'])], [The, highest])\n",
      "--> Potential meaningful keywords for the sentence: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High']\n",
      "---> Meaningful keywords enhanced by previous context: ['Book', 'book', 'page count', 'page', 'count', 'high', 'The High', 'The Count', 'Highest', 'Page', 'Count', 'High', 'Harry Potter', 'Harry Potter', 'Harry Potter', 'Lord Voldemort', 'Harry Potter and the Order of the Phoenix', 'Harry Potter and the Order of the Phoenix', '5', 'United Kingdom', 'wizard in the Harry Potter universe', '1998-05-02T00:00:00Z', 'J. K. Rowling']\n",
      "meaningful_names_no_previous_answer [Book, book, page count, page, count, high, The High, The Count, Highest, Page, Count, High, Harry Potter, Harry Potter, Harry Potter, Lord Voldemort, Harry Potter and the Order of the Phoenix, Harry Potter and the Order of the Phoenix, 5, United Kingdom, wizard in the Harry Potter universe, 1998 - 05 02T00:00:00Z, J. K. Rowling]\n",
      "----> Meaningful keywords casted as theme ([(Book, ['Q421300']), (book, ['Q997698']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Lord Voldemort, ['Q176132']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145']), (wizard in the Harry Potter universe, ['Q15298259']), (J. K. Rowling, ['Q34660'])], [])\n",
      "q_focused_parts: [(Book, ['Q421300']), (book, ['Q997698']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Harry Potter, ['Q3244512', 'Q216930', 'Q17146193']), (Lord Voldemort, ['Q176132']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (Harry Potter and the Order of the Phoenix, ['Q1148993', 'Q102235', 'Q2102791']), (5, ['Q10351972', 'Q11188008', 'Q10976211']), (United Kingdom, ['Q225249', 'Q20530126', 'Q145']), (wizard in the Harry Potter universe, ['Q15298259']), (J. K. Rowling, ['Q34660'])]\n",
      "-> Building the graph with k_deep 3 ... (could be long)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 12] Cannot allocate memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5cfd420ee8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 graphqa_answer, graphqa_graph = ask_graphqa(question, verbose=True, timer=True, banning_str=banning_str,\n\u001b[1;32m    222\u001b[0m                                          \u001b[0manswer_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraphqa_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraphqa_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                                          use_convex=use_convex)\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgraphqa_answer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mgraphqa_answer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-b91dccfc5f02>\u001b[0m in \u001b[0;36mask_graphqa\u001b[0;34m(question, verbose, timer, show_graph, cores, banning_str, answer_context, context_graph, use_convex, turn)\u001b[0m\n\u001b[1;32m     30\u001b[0m         result = graphqa.answer_question(\n\u001b[1;32m     31\u001b[0m             \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbanning_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbanning_str\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             previous_answer=answer_context, previous_graph=context_graph)\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tm/mse.tm.chatbot.base/tmqa35.py\u001b[0m in \u001b[0;36manswer_question\u001b[0;34m(question, verbose, aggressive, looped, deep_k, deep_k_step, deep_k_max, graph_size_min, graph_size_target, graph_size_max, paths_filter_max, paths_max, timer, g_paths, show_graph, cores, banning_str, reload_cache, answer_sentence, previous_answer, previous_graph, graph_size_target_context, deep_match, k_context, in_context, k_deep_followup, k_deep_context_graph, context_themes, previous_answers, max_deepness, g_autocorrect)\u001b[0m\n\u001b[1;32m   5435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5436\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_k_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_k_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5437\u001b[0;31m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_nlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_themes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_themes_enhanced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_predicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_sensitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sensitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprevious_answer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprevious_answer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maggressive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggressive\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk_deep_followup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk_deep_followup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_deepness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_deepness\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5439\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"->New graph \\tRunning time is {}s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtimer_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tm/mse.tm.chatbot.base/tmqa35.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(nlp, themes, themes_enhanced, predicates, deep_k, time_sensitive, cores, context_graph, previous_answer, aggressive, k_deep_followup, max_deepness)\u001b[0m\n\u001b[1;32m   2233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2235\u001b[0;31m     \u001b[0minit_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_extend_by_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheme_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_sentitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sensitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2236\u001b[0m     \u001b[0;31m#print(\"init_clusters\",len(init_clusters))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m     \u001b[0minit_clusters_enhanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_extend_by_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheme_enhanced_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicates_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeep_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_sentitive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_sensitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tm/mse.tm.chatbot.base/tmqa35.py\u001b[0m in \u001b[0;36mcluster_extend_by_words\u001b[0;34m(cluster_root_ids, extending_words, top_k, time_sentitive, cores)\u001b[0m\n\u001b[1;32m   2040\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2042\u001b[0;31m         \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2043\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m         \u001b[0min_mp_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qa/lib/python3.7/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qa/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qa/lib/python3.7/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qa/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/qa/lib/python3.7/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory"
     ]
    }
   ],
   "source": [
    "### Evaluate\n",
    "banning_str = False\n",
    "show_graph = False\n",
    "\n",
    "start_time = time.time()\n",
    "conversations_len = len(conversations)\n",
    "\n",
    "for i_c, conversation in enumerate(conversations):\n",
    "    questions = [turn['question'] for turn in conversation['questions']]\n",
    "    answers = [graphqa.wikidata_url_to_wikidata_id(turn['answer']) for turn in conversation['questions']]\n",
    "    domain = conversation['domain']\n",
    "    questions_len = len(questions)\n",
    "    \n",
    "    qanswer_answer, qanswer_graph = False,False\n",
    "    platypus_answer, platypus_graph = False,False\n",
    "    convex_answer, convex_graph = False,False\n",
    "    graphqa_answer, graphqa_graph = False,False\n",
    "\n",
    "    qanswer_answer_convex, qanswer_graph_convex = False,False\n",
    "    platypus_answer_convex, platypus_graph_convex = False,False\n",
    "    convex_answer_convex, convex_graph_convex = False,False\n",
    "    graphqa_answer_convex, graphqa_graph_convex = False,False\n",
    "    \n",
    "    #break\n",
    "    if i_c+1 < 523:\n",
    "        continue\n",
    "        \n",
    "    for i_q,question in enumerate(questions):\n",
    "        if i_q+1 <0:\n",
    "            continue\n",
    "            \n",
    "        print(\"It is \", datetime.now())\n",
    "                \n",
    "        for use_convex in [False,True]:\n",
    "\n",
    "            answer = answers[i_q]\n",
    "            print(\"\\r\\t>>> Processing {}/{} -> {}/{} -> Convex={}: ({}) {}\".format(i_c+1,conversations_len,i_q+1,questions_len,use_convex,answer,question), \n",
    "                  end='                                  ')\n",
    "            #time.sleep(1)\n",
    "\n",
    "            #ASK QANSWER\n",
    "            start_time = time.time()            \n",
    "            if qanswer_graph and not use_convex:\n",
    "                print(\"\\nqAnswer extended by GraphQA\")\n",
    "                qanswer_answer, qanswer_graph = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=qanswer_answer, context_graph=qanswer_graph,\n",
    "                                         use_convex=use_convex)\n",
    "                if qanswer_answer: \n",
    "                    df_qanswer_rr = get_rr(qanswer_answer[0], answer)\n",
    "                    if qanswer_answer[0]: df_qanswer = qanswer_answer[0][0]\n",
    "                    else: df_qanswer = False\n",
    "                else: \n",
    "                    df_qanswer = False\n",
    "                    df_qanswer_rr = 0\n",
    "\n",
    "            elif qanswer_graph_convex and use_convex:\n",
    "                print(\"\\nqAnswer extended by Convex\")\n",
    "                qanswer_answer_convex, qanswer_graph_convex = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=qanswer_answer_convex, context_graph=qanswer_graph_convex,\n",
    "                                         use_convex=use_convex, turn=i_q+1)\n",
    "                if qanswer_answer_convex:\n",
    "                    df_qanswer_rr = get_rr(qanswer_answer_convex[0], answer)\n",
    "                    if qanswer_answer_convex[0]: df_qanswer = qanswer_answer_convex[0][0]\n",
    "                    else: df_qanswer = False\n",
    "                else: \n",
    "                    df_qanswer = False\n",
    "                    df_qanswer_rr = 0\n",
    "\n",
    "            else:\n",
    "                print(\"\\nAsking qAnswer\")\n",
    "                qanswer_answer, qanswer_graph = ask_qanswer(question)\n",
    "                if qanswer_answer: \n",
    "                    qanswer_answer=[[qanswer_answer],[]]\n",
    "                    qanswer_graph=nx.Graph()\n",
    "                    qanswer_graph.add_node(qanswer_answer[0][0], name=graphqa.get_wd_label(qanswer_answer[0][0]), type='entity', turn=i_q+1, weight=1, qa=True)\n",
    "                else: \n",
    "                    qanswer_answer=[[],[]]\n",
    "                    qanswer_graph=nx.Graph()\n",
    "                if qanswer_answer:\n",
    "                    df_qanswer_rr = get_rr(qanswer_answer[0], answer)\n",
    "                    if qanswer_answer[0]: df_qanswer = qanswer_answer[0][0]\n",
    "                    else: df_qanswer = False\n",
    "                else: \n",
    "                    df_qanswer = False\n",
    "                    df_qanswer_rr = 0\n",
    "                if show_graph: graphqa.plot_graph(qanswer_graph, \"file_name_context_graph\", \"Context_Graph_title\")\n",
    "                \n",
    "                qanswer_answer_convex = qanswer_answer.copy()\n",
    "                qanswer_graph_convex = qanswer_graph.copy()\n",
    "            \n",
    "            print(\"df_qanswer\",df_qanswer) \n",
    "            print(\"df_qanswer_rr\",df_qanswer_rr)\n",
    "            \n",
    "            df_qanswer_time = round(time.time()-start_time,2)\n",
    "            \n",
    "            ## ASK PLATYPUS\n",
    "            start_time = time.time()\n",
    "            if platypus_graph and not use_convex:\n",
    "                print(\"\\nPlatypus extended by GraphQA\")\n",
    "                platypus_answer, platypus_graph = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=platypus_answer, context_graph=platypus_graph,\n",
    "                                         use_convex=use_convex)\n",
    "                if platypus_answer: \n",
    "                    df_platypus_rr = get_rr(platypus_answer[0], answer)\n",
    "                    if platypus_answer[0]: platypus_answer[0][0]: df_platypus = platypus_answer[0][0]\n",
    "                    else: df_platypus = False\n",
    "                else: \n",
    "                    df_platypus_rr = 0\n",
    "                    df_platypus = False\n",
    "\n",
    "            elif platypus_graph_convex and use_convex:\n",
    "                print(\"\\nPlatypus extended by Convex\")\n",
    "                platypus_answer_convex, platypus_graph_convex = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=platypus_answer_convex, context_graph=platypus_graph_convex,\n",
    "                                         use_convex=use_convex, turn=i_q+1)\n",
    "                if platypus_answer_convex: \n",
    "                    df_platypus_rr = get_rr(platypus_answer_convex[0], answer)\n",
    "                    if platypus_answer_convex[0]: df_platypus = platypus_answer_convex[0][0]\n",
    "                    else: df_platypus = False\n",
    "                else: \n",
    "                    df_platypus_rr = 0\n",
    "                    df_platypus = False\n",
    "\n",
    "            else:\n",
    "                print(\"\\nAsking Platypus\")\n",
    "                platypus_answer, platypus_graph = ask_platypus(question)\n",
    "                if platypus_answer: \n",
    "                    platypus_answer=[[platypus_answer],[]]\n",
    "                    platypus_graph=nx.Graph()\n",
    "                    platypus_graph.add_node(platypus_answer[0][0], name=graphqa.get_wd_label(platypus_answer[0][0]), type='entity', turn=i_q+1, weight=1, qa=True)\n",
    "                else: \n",
    "                    platypus_answer=[[],[]]\n",
    "                    platypus_graph=nx.Graph()\n",
    "                if platypus_answer:\n",
    "                    df_platypus_rr = get_rr(platypus_answer[0], answer)\n",
    "                    if platypus_answer[0]: df_platypus = platypus_answer[0][0]\n",
    "                    else: df_platypus = False\n",
    "                else: \n",
    "                    df_platypus_rr = 0\n",
    "                    df_platypus = False\n",
    "                if show_graph: graphqa.plot_graph(platypus_graph, \"file_name_context_graph\", \"Context_Graph_title\")\n",
    "                \n",
    "                platypus_answer_convex = platypus_answer.copy()\n",
    "                platypus_graph_convex = platypus_graph.copy()\n",
    "            \n",
    "            print(\"df_platypus\",df_platypus) \n",
    "            print(\"df_platypus_rr\",df_platypus_rr)\n",
    "            \n",
    "            df_platypus_time = round(time.time()-start_time,2)\n",
    "            \n",
    "            \n",
    "            ## ASK CONVEX\n",
    "            start_time = time.time()\n",
    "            if convex_graph and not use_convex:\n",
    "                print(\"\\nConvex extended by GraphQA\")\n",
    "                convex_answer, convex_graph = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=convex_answer, context_graph=convex_graph,\n",
    "                                         use_convex=use_convex)\n",
    "                if convex_answer:\n",
    "                    df_convex_rr = get_rr(convex_answer[0], answer)\n",
    "                    if convex_answer[0]: df_convex = convex_answer[0][0]\n",
    "                    else: df_convex = False\n",
    "                else: \n",
    "                    df_convex_rr = 0\n",
    "                    df_convex = False\n",
    "                    \n",
    "            elif convex_graph_convex and use_convex:\n",
    "                print(\"\\nConvex extended by Convex\")\n",
    "                convex_answer_convex, convex_graph_convex = ask_graphqa(question, verbose=True, timer=True, show_graph=show_graph, banning_str=banning_str,\n",
    "                                         answer_context=convex_answer_convex, context_graph=convex_graph_convex,\n",
    "                                         use_convex=use_convex, turn=i_q+1)\n",
    "                if convex_answer_convex:\n",
    "                    df_convex_rr = get_rr(convex_answer_convex[0], answer)\n",
    "                    if convex_answer_convex[0]: df_convex = convex_answer_convex[0][0]\n",
    "                    else: df_convex = False\n",
    "                else: \n",
    "                    df_convex = False\n",
    "                    df_convex_rr = 0\n",
    "                    \n",
    "            else:\n",
    "                print(\"\\nAsking Convex\")\n",
    "                convex_answer, convex_graph = ask_convex(question)\n",
    "                #([['Q766106'], ['Q76', 'P25', 'Q766106']],<networkx.classes.graph.Graph at 0x7f94423d1f90>)\n",
    "                if not convex_answer: \n",
    "                    convex_answer=[[],[]]\n",
    "                    convex_graph=nx.Graph()\n",
    "                if convex_answer:\n",
    "                    df_convex_rr = get_rr(convex_answer[0], answer)\n",
    "                    if convex_answer[0]: df_convex = convex_answer[0][0]\n",
    "                    else: ddf_convex = False\n",
    "                else: \n",
    "                    df_convex = False\n",
    "                    df_convex_rr = 0\n",
    "                if show_graph: graphqa.plot_graph(convex_graph, \"file_name_context_graph\", \"Context_Graph_title\")\n",
    "                convex_answer_convex = convex_answer.copy()\n",
    "                convex_graph_convex = convex_graph.copy()\n",
    "                \n",
    "            print(\"df_convex\",df_convex) \n",
    "            print(\"df_convex_rr\",df_convex_rr)\n",
    "            \n",
    "            df_convex_time = round(time.time()-start_time,2)\n",
    "                \n",
    "                \n",
    "            \n",
    "\n",
    "            print(\"\\nCORRECT\",i_c+1,\"-\",i_q+1, \"-> qAnswer\", df_qanswer) if df_qanswer == answer else False\n",
    "            print(\"\\nCORRECT\",i_c+1,\"-\",i_q+1, \"-> Platypus\", df_platypus) if df_platypus == answer else False\n",
    "            print(\"\\nCORRECT\",i_c+1,\"-\",i_q+1, \"-> Convex\", df_convex) if df_convex == answer else False\n",
    "\n",
    "            df_graphqa = False\n",
    "            df_graphqa_top2 = False\n",
    "            df_graphqa_top3 = False\n",
    "            df_graphqa_top4 = False\n",
    "            df_graphqa_top5 = False\n",
    "            df_graphqa_topall = False\n",
    "            df_graphqa_rr = 0\n",
    "            \n",
    "            start_time = time.time()\n",
    "            if graphqa_graph and not use_convex:\n",
    "                print(\"\\nGraphQA extended by GraphQA\")\n",
    "                graphqa_answer, graphqa_graph = ask_graphqa(question, verbose=True, timer=True, banning_str=banning_str,\n",
    "                                         answer_context=graphqa_answer, context_graph=graphqa_graph,\n",
    "                                         use_convex=use_convex)\n",
    "                if graphqa_answer:\n",
    "                    if graphqa_answer[0]:\n",
    "                        df_graphqa_rr = get_rr(graphqa_answer[0], answer)\n",
    "                        if graphqa_answer[0][0]: df_graphqa = graphqa_answer[0][0]\n",
    "                        if answer in graphqa_answer[0][:2]: df_graphqa_top2 = True\n",
    "                        if answer in graphqa_answer[0][:3]: df_graphqa_top3 = True\n",
    "                        if answer in graphqa_answer[0][:4]: df_graphqa_top4 = True\n",
    "                        if answer in graphqa_answer[0][:5]: df_graphqa_top5 = True\n",
    "                        if answer in graphqa_answer[0]: df_graphqa_topall = True\n",
    "                \n",
    "            elif graphqa_graph and use_convex:\n",
    "                print(\"\\nGraphQA extended by Convex\")\n",
    "                graphqa_answer_convex, graphqa_graph_convex = ask_graphqa(question, verbose=True, timer=True, banning_str=banning_str,\n",
    "                                         answer_context=graphqa_answer_convex, context_graph=graphqa_graph_convex,\n",
    "                                         use_convex=use_convex, turn=i_q+1)\n",
    "                if graphqa_answer_convex:\n",
    "                    if graphqa_answer_convex[0]:\n",
    "                        df_graphqa_rr = get_rr(graphqa_answer_convex[0], answer)\n",
    "                        if graphqa_answer_convex[0][0]: df_graphqa = graphqa_answer_convex[0][0]\n",
    "                        if answer in graphqa_answer_convex[0][:2]: df_graphqa_top2 = True\n",
    "                        if answer in graphqa_answer_convex[0][:3]: df_graphqa_top3 = True\n",
    "                        if answer in graphqa_answer_convex[0][:4]: df_graphqa_top4 = True\n",
    "                        if answer in graphqa_answer_convex[0][:5]: df_graphqa_top5 = True\n",
    "                        if answer in graphqa_answer_convex[0]: df_graphqa_topall = True\n",
    "                \n",
    "            else:\n",
    "                print(\"\\nAsking GraphQA\")\n",
    "                graphqa_answer, graphqa_graph = ask_graphqa(question, verbose=True, timer=True, banning_str=banning_str,\n",
    "                                         answer_context=graphqa_answer, context_graph=graphqa_graph,\n",
    "                                         use_convex=False)\n",
    "                if not graphqa_answer: \n",
    "                    graphqa_answer=[[],[]]\n",
    "                    graphqa_graph=nx.Graph()\n",
    "                else:\n",
    "                    graphqa_answer_convex = graphqa_answer.copy()\n",
    "                    graphqa_graph_convex = graphqa_graph.copy()\n",
    "                \n",
    "                if graphqa_answer:\n",
    "                    if graphqa_answer[0]:\n",
    "                        df_graphqa_rr = get_rr(graphqa_answer[0], answer)\n",
    "                        if graphqa_answer[0][0]: df_graphqa = graphqa_answer[0][0]\n",
    "                        if answer in graphqa_answer[0][:2]: df_graphqa_top2 = True\n",
    "                        if answer in graphqa_answer[0][:3]: df_graphqa_top3 = True\n",
    "                        if answer in graphqa_answer[0][:4]: df_graphqa_top4 = True\n",
    "                        if answer in graphqa_answer[0][:5]: df_graphqa_top5 = True\n",
    "                        if answer in graphqa_answer[0]: df_graphqa_topall = True\n",
    "                            \n",
    "            print(\"df_graphqa\",df_graphqa) \n",
    "            print(\"df_graphqa_rr\",df_graphqa_rr)\n",
    "                \n",
    "\n",
    "            df_graphqa_time = round(time.time()-start_time,2)\n",
    "\n",
    "            df = df.append({\n",
    "                'conversation_id':i_c,'turn':i_q,\"plus_convex\":use_convex,\n",
    "                'question':question, 'answer':answer,'domain':domain,\n",
    "                'qanswer':df_qanswer,'qanswer_time':df_qanswer_time, 'qanswer_rr':df_qanswer_rr,\n",
    "                'platypus':df_platypus,'platypus_time':df_platypus_time, 'platypus_rr':df_platypus_rr,\n",
    "                'convex':df_convex,'convex_time':df_convex_time, 'convex_rr':df_convex_rr,\n",
    "                'graphqa':df_graphqa, 'graphqa_time':df_graphqa_time, 'graphqa_top2':df_graphqa_top2,\n",
    "                \"graphqa_top3\":df_graphqa_top3,\"graphqa_top4\":df_graphqa_top4, \"graphqa_top5\":df_graphqa_top5,\n",
    "                \"graphqa_topall\":df_graphqa_topall, \"graphqa_rr\":df_graphqa_rr},\n",
    "               ignore_index=True)\n",
    "\n",
    "            print(\"\\nCORRECT\",i_c+1,\"-\",i_q+1, \"-> graphqa\", df_graphqa) if str(df_graphqa) == str(answer) else False\n",
    "            if use_convex: print(\"\\nPARTIAL_CORRECT\",i_c+1,\"-\",i_q+1, \"-> graphqa in answers\", graphqa_answer_convex[0]) if df_graphqa_topall == True else False\n",
    "            else: print(\"\\nPARTIAL_CORRECT\",i_c+1,\"-\",i_q+1, \"-> graphqa in answers\", graphqa_answer[0]) if df_graphqa_topall == True else False\n",
    "\n",
    "            print(df.tail(1))\n",
    "\n",
    "            pickle_data(df, \"benchmarking-qanswer-platypus-convex-qagraph-\"+str(len(df))+\"-ic\"+str(i_c)+\"-iq\"+str(i_q)+\"-pc\"+str(use_convex))\n",
    "\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            if i_q == 0: \n",
    "                break\n",
    "\n",
    "        #if i_q >= 1:      \n",
    "            #break\n",
    "    \n",
    "    #break\n",
    "\n",
    "print(\"->\\tRunning time is {}s\".format(round(time.time()-start_time,2)))\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.tail(1).index,inplace=True) # drop last n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "print(df_copy[df_copy.graphqa == df_copy.answer][\"graphqa_rr\"]) \n",
    "df_copy.loc[df_copy[\"graphqa\"] == df_copy[\"answer\"], 'graphqa_rr'] = 1\n",
    "print(df_copy[df_copy.graphqa == df_copy.answer][\"graphqa_rr\"]) \n",
    "\n",
    "print(df_copy[df_copy.convex == df_copy.answer][\"convex_rr\"]) \n",
    "df_copy.loc[df_copy[\"convex\"] == df_copy[\"answer\"], 'convex_rr'] = 1  \n",
    "print(df_copy[df_copy.convex == df_copy.answer][\"convex_rr\"]) \n",
    "\n",
    "print(df_copy)  \n",
    "df = df_copy # made at from 0 to 278, len of 279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING\n",
    "#pickle_data(df_loaded, \"benchmarking-qanswer-platypus-convex-tm1-from-0-to-\"+str(len(df_loaded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING\n",
    "#df_loaded = pd.read_pickle(\"/data/users/romain.claret/tm/wikidata-simplequestions/benchmark_pickles/benchmarking-qanswer-platypus-convex-tm1-from-0-to-9961.pickle.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['qanswer'][34] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df_loaded['tm2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded.rename({'mine':'tm1'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded['tm1_top4'] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded = df_loaded[['question','source','qanswer','platypus','convex','tm1','tm1_time','tm1_top2','tm1_top3','tm1_top4','tm1_top5','tm1_topall']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded_len = len(df_loaded)\n",
    "#for i, question in enumerate(df_loaded['question']):\n",
    "#    if i >= 0:\n",
    "#    #if i >= 497:\n",
    "#        source = str(df_loaded['source'][i])\n",
    "#        print(str(i)+\"/\"+str(df_loaded_len),question,\"-> source:\",source)\n",
    "#        \n",
    "#        start_time = time.time()\n",
    "#        result_tmqa_1 = ask_tmqa_1(question, verbose=True)\n",
    "#        \n",
    "#        if result_tmqa_1:\n",
    "#            df_loaded['tm1'][i] = result_tmqa_1[0]\n",
    "#            if source in result_tmqa_1[:2]:\n",
    "#                df_loaded['tm1_top2'][i] = True\n",
    "#            if source in result_tmqa_1[:3]:\n",
    "#                df_loaded['tm1_top3'][i] = True\n",
    "#            if source in result_tmqa_1[:4]:\n",
    "#                df_loaded['tm1_top4'][i] = True\n",
    "#            if source in result_tmqa_1[:5]:\n",
    "#                df_loaded['tm1_top5'][i] = True\n",
    "#            if source in result_tmqa_1:\n",
    "#                df_loaded['tm1_topall'][i] = True\n",
    "#        else:\n",
    "#            df_loaded['tm1'][i] = False\n",
    "#        end_time = time.time()\n",
    "#        df_loaded['tm1_time'][i] = round(end_time-start_time,2)\n",
    "#        print(\"->\\tRunning time is {}s\".format(round(end_time-start_time,2)))\n",
    "#        print(str(str(df_loaded['tm1'][i])==str(source)),\"---> result_tmqa_1:\",str(result_tmqa_1)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_loaded.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_loaded.copy()\n",
    "#df = df.replace(\"\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_backup = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_row = 496\n",
    "#df_len = len(df)\n",
    "#df_qanswer_max = df[(df.index<=max_row) & (df.qanswer == df.source)]\n",
    "#df_qanswer_max_len = len(df_qanswer_max)\n",
    "#\n",
    "#df_platypus_max = df[(df.index<=max_row) & (df.platypus == df.source)]\n",
    "#df_platypus_max_len = len(df_platypus_max)\n",
    "#\n",
    "#df_convex_max = df[(df.index<=max_row) & (df.convex == df.source)]\n",
    "#df_convex_max_len = len(df_convex_max)\n",
    "#\n",
    "#df_tm1_max = df[(df.index<=max_row) & (df.tm1 == df.source)]\n",
    "#df_tm1_max_len = len(df_tm1_max)\n",
    "#\n",
    "#df_tm1_max_top2 = df[(df.index<=max_row) & (df.tm1_top2 == True)]\n",
    "#df_tm1_max_top2_len = len(df_tm1_max_top2)\n",
    "#\n",
    "#df_tm1_max_top3 = df[(df.index<=max_row) & (df.tm1_top3 == True)]\n",
    "#df_tm1_max_top3_len = len(df_tm1_max_top3)\n",
    "#\n",
    "#df_tm1_max_top4 = df[(df.index<=max_row) & (df.tm1_top4 == True)]\n",
    "#df_tm1_max_top4_len = len(df_tm1_max_top4)\n",
    "#\n",
    "#df_tm1_max_top5 = df[(df.index<=max_row) & (df.tm1_top5 == True)]\n",
    "#df_tm1_max_top5_len = len(df_tm1_max_top5)\n",
    "#\n",
    "#df_tm1_max_topall = df[(df.index<=max_row) & (df.tm1_topall == True)]\n",
    "#df_tm1_max_topall_len = len(df_tm1_max_topall)\n",
    "#\n",
    "#print(\"qanswer:\", df_qanswer_max_len,df_qanswer_max_len/max_row)\n",
    "#print(\"platypus:\", df_platypus_max_len, df_platypus_max_len/max_row)\n",
    "#print(\"convex:\", df_convex_max_len, df_convex_max_len/max_row)\n",
    "#print(\"tm1:\", df_tm1_max_len, df_tm1_max_len/max_row)\n",
    "#print(\"tm1_top2:\", df_tm1_max_top2_len, df_tm1_max_top2_len/max_row)\n",
    "#print(\"tm1_top3:\", df_tm1_max_top3_len, df_tm1_max_top3_len/max_row)\n",
    "#print(\"tm1_top4:\", df_tm1_max_top4_len, df_tm1_max_top4_len/max_row)\n",
    "#print(\"tm1_top5:\", df_tm1_max_top5_len, df_tm1_max_top5_len/max_row)\n",
    "#print(\"tm1_topall:\", df_tm1_max_topall_len, df_tm1_max_topall_len/max_row)\n",
    "#\n",
    "#df[ & (df.qanswer == df.source)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"qanswer:\",len(df[df.qanswer == df.source]),len(df[df.qanswer == df.source])/len(df))\n",
    "#print(\"platypus:\",len(df[df.platypus == df.source]),len(df[df.platypus == df.source])/len(df))\n",
    "#print(\"convex:\",len(df[df.convex == df.source]),len(df[df.convex == df.source])/len(df))\n",
    "#print(\"tm1:\",len(df[df.tm1 == df.source]),len(df[df.tm1 == df.source])/len(df))\n",
    "#print(\"tm1_top2:\",len(df[df.tm1_top2 == True]),len(df[df.tm1_top2 == True])/len(df))\n",
    "#print(\"tm1_top3:\",len(df[df.tm1_top3 == True]),len(df[df.tm1_top3 == True])/len(df))\n",
    "#print(\"tm1_top4:\",len(df[df.tm1_top4 == True]),len(df[df.tm1_top4 == True])/len(df))\n",
    "#print(\"tm1_top5:\",len(df[df.tm1_top5 == True]),len(df[df.tm1_top5 == True])/len(df))\n",
    "#print(\"tm1_topall:\",len(df[df.tm1_topall == True]),len(df[df.tm1_topall == True])/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tm1_top2 = df.tm1_top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qa]",
   "language": "python",
   "name": "conda-env-qa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
